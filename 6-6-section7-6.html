<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="6.6 Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x) | Intermediate Statistics with R" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="gpeterson406/Greenwood_Book" />

<meta name="author" content="Mark C Greenwood" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="6.6 Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x) | Intermediate Statistics with R">

<title>6.6 Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x) | Intermediate Statistics with R</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#cover">Cover</a></li>
<li class="has-sub"><a href="acknowledgments.html#acknowledgments">Acknowledgments</a><ul>
<li><a href="0-1-section1-5.html#section1-5"><span class="toc-section-number">0.1</span> Summary of important R code</a></li>
</ul></li>
<li class="has-sub"><a href="1-chapter2.html#chapter2"><span class="toc-section-number">1</span> (R)e-Introduction to statistics</a><ul>
<li><a href="1-1-section2-1.html#section2-1"><span class="toc-section-number">1.1</span> Histograms, boxplots, and density curves</a></li>
<li><a href="1-2-section2-2.html#section2-2"><span class="toc-section-number">1.2</span> Pirate-plots</a></li>
<li><a href="1-3-section2-3.html#section2-3"><span class="toc-section-number">1.3</span> Models, hypotheses, and permutations for the two sample mean situation</a></li>
<li><a href="1-4-section2-4.html#section2-4"><span class="toc-section-number">1.4</span> Permutation testing for the two sample mean situation</a></li>
<li><a href="1-5-section2-5.html#section2-5"><span class="toc-section-number">1.5</span> Hypothesis testing (general)</a></li>
<li><a href="1-6-section2-6.html#section2-6"><span class="toc-section-number">1.6</span> Connecting randomization (nonparametric) and parametric tests</a></li>
<li><a href="1-7-section2-7.html#section2-7"><span class="toc-section-number">1.7</span> Second example of permutation tests</a></li>
<li><a href="1-8-section2-8.html#section2-8"><span class="toc-section-number">1.8</span> Reproducibility Crisis: Moving beyond p &lt; 0.05, publication bias, and multiple testing issues</a></li>
<li><a href="1-9-section2-9.html#section2-9"><span class="toc-section-number">1.9</span> Confidence intervals and bootstrapping</a></li>
<li><a href="1-10-section2-10.html#section2-10"><span class="toc-section-number">1.10</span> Bootstrap confidence intervals for difference in GPAs</a></li>
<li><a href="1-11-section2-11.html#section2-11"><span class="toc-section-number">1.11</span> Chapter summary</a></li>
<li><a href="1-12-section2-12.html#section2-12"><span class="toc-section-number">1.12</span> Summary of important R code</a></li>
<li><a href="1-13-section2-13.html#section2-13"><span class="toc-section-number">1.13</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="2-chapter3.html#chapter3"><span class="toc-section-number">2</span> One-Way ANOVA</a><ul>
<li><a href="2-1-section3-1.html#section3-1"><span class="toc-section-number">2.1</span> Situation</a></li>
<li><a href="2-2-section3-2.html#section3-2"><span class="toc-section-number">2.2</span> Linear model for One-Way ANOVA (cell-means and reference-coding)</a></li>
<li><a href="2-3-section3-3.html#section3-3"><span class="toc-section-number">2.3</span> One-Way ANOVA Sums of Squares, Mean Squares, and F-test</a></li>
<li><a href="2-4-section3-4.html#section3-4"><span class="toc-section-number">2.4</span> ANOVA model diagnostics including QQ-plots</a></li>
<li><a href="2-5-section3-5.html#section3-5"><span class="toc-section-number">2.5</span> Guinea pig tooth growth One-Way ANOVA example</a></li>
<li><a href="2-6-section3-6.html#section3-6"><span class="toc-section-number">2.6</span> Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display</a></li>
<li><a href="2-7-section3-7.html#section3-7"><span class="toc-section-number">2.7</span> Pair-wise comparisons for the Overtake data</a></li>
<li><a href="2-8-section3-8.html#section3-8"><span class="toc-section-number">2.8</span> Chapter summary</a></li>
<li><a href="2-9-section3-9.html#section3-9"><span class="toc-section-number">2.9</span> Summary of important R code</a></li>
<li><a href="2-10-section3-10.html#section3-10"><span class="toc-section-number">2.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="3-chapter4.html#chapter4"><span class="toc-section-number">3</span> Two-Way ANOVA</a><ul>
<li><a href="3-1-section4-1.html#section4-1"><span class="toc-section-number">3.1</span> Situation</a></li>
<li><a href="3-2-section4-2.html#section4-2"><span class="toc-section-number">3.2</span> Designing a two-way experiment and visualizing results</a></li>
<li><a href="3-3-section4-3.html#section4-3"><span class="toc-section-number">3.3</span> Two-Way ANOVA models and hypothesis tests</a></li>
<li><a href="3-4-section4-4.html#section4-4"><span class="toc-section-number">3.4</span> Guinea pig tooth growth analysis with Two-Way ANOVA</a></li>
<li><a href="3-5-section4-5.html#section4-5"><span class="toc-section-number">3.5</span> Observational study example: The Psychology of Debt</a></li>
<li><a href="3-6-section4-6.html#section4-6"><span class="toc-section-number">3.6</span> Pushing Two-Way ANOVA to the limit: Un-replicated designs and Estimability</a></li>
<li><a href="3-7-section4-7.html#section4-7"><span class="toc-section-number">3.7</span> Chapter summary</a></li>
<li><a href="3-8-section4-8.html#section4-8"><span class="toc-section-number">3.8</span> Summary of important R code</a></li>
<li><a href="3-9-section4-9.html#section4-9"><span class="toc-section-number">3.9</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="4-chapter5.html#chapter5"><span class="toc-section-number">4</span> Chi-square tests</a><ul>
<li><a href="4-1-section5-1.html#section5-1"><span class="toc-section-number">4.1</span> Situation, contingency tables, and tableplots</a></li>
<li><a href="4-2-section5-2.html#section5-2"><span class="toc-section-number">4.2</span> Homogeneity test hypotheses</a></li>
<li><a href="4-3-section5-3.html#section5-3"><span class="toc-section-number">4.3</span> Independence test hypotheses</a></li>
<li><a href="4-4-section5-4.html#section5-4"><span class="toc-section-number">4.4</span> Models for R by C tables</a></li>
<li><a href="4-5-section5-5.html#section5-5"><span class="toc-section-number">4.5</span> Permutation tests for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="4-6-section5-6.html#section5-6"><span class="toc-section-number">4.6</span> Chi-square distribution for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="4-7-section5-7.html#section5-7"><span class="toc-section-number">4.7</span> Examining residuals for the source of differences</a></li>
<li><a href="4-8-section5-8.html#section5-8"><span class="toc-section-number">4.8</span> General protocol for <span class="math inline">\(X^2\)</span> tests</a></li>
<li><a href="4-9-section5-9.html#section5-9"><span class="toc-section-number">4.9</span> Political party and voting results: Complete analysis</a></li>
<li><a href="4-10-section5-10.html#section5-10"><span class="toc-section-number">4.10</span> Is cheating and lying related in students?</a></li>
<li><a href="4-11-section5-11.html#section5-11"><span class="toc-section-number">4.11</span> Analyzing a stratified random sample of California schools</a></li>
<li><a href="4-12-section5-12.html#section5-12"><span class="toc-section-number">4.12</span> Chapter summary</a></li>
<li><a href="4-13-section5-13.html#section5-13"><span class="toc-section-number">4.13</span> Summary of important R commands</a></li>
<li><a href="4-14-section5-14.html#section5-14"><span class="toc-section-number">4.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="5-chapter6.html#chapter6"><span class="toc-section-number">5</span> Correlation and Simple Linear Regression</a><ul>
<li><a href="5-1-section6-1.html#section6-1"><span class="toc-section-number">5.1</span> Relationships between two quantitative variables</a></li>
<li><a href="5-2-section6-2.html#section6-2"><span class="toc-section-number">5.2</span> Estimating the correlation coefficient</a></li>
<li><a href="5-3-section6-3.html#section6-3"><span class="toc-section-number">5.3</span> Relationships between variables by groups</a></li>
<li><a href="5-4-section6-4.html#section6-4"><span class="toc-section-number">5.4</span> Inference for the correlation coefficient</a></li>
<li><a href="5-5-section6-5.html#section6-5"><span class="toc-section-number">5.5</span> Are tree diameters related to tree heights?</a></li>
<li><a href="5-6-section6-6.html#section6-6"><span class="toc-section-number">5.6</span> Describing relationships with a regression model</a></li>
<li><a href="5-7-section6-7.html#section6-7"><span class="toc-section-number">5.7</span> Least Squares Estimation</a></li>
<li><a href="5-8-section6-8.html#section6-8"><span class="toc-section-number">5.8</span> Measuring the strength of regressions: R<sup>2</sup></a></li>
<li><a href="5-9-section6-9.html#section6-9"><span class="toc-section-number">5.9</span> Outliers: leverage and influence</a></li>
<li><a href="5-10-section6-10.html#section6-10"><span class="toc-section-number">5.10</span> Residual diagnostics – setting the stage for inference</a></li>
<li><a href="5-11-section6-11.html#section6-11"><span class="toc-section-number">5.11</span> Old Faithful discharge and waiting times</a></li>
<li><a href="5-12-section6-12.html#section6-12"><span class="toc-section-number">5.12</span> Chapter summary</a></li>
<li><a href="5-13-section6-13.html#section6-13"><span class="toc-section-number">5.13</span> Summary of important R code</a></li>
<li><a href="5-14-section6-14.html#section6-14"><span class="toc-section-number">5.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="6-chapter7.html#chapter7"><span class="toc-section-number">6</span> Simple linear regression inference</a><ul>
<li><a href="6-1-section7-1.html#section7-1"><span class="toc-section-number">6.1</span> Model</a></li>
<li><a href="6-2-section7-2.html#section7-2"><span class="toc-section-number">6.2</span> Confidence interval and hypothesis tests for the slope and intercept</a></li>
<li><a href="6-3-section7-3.html#section7-3"><span class="toc-section-number">6.3</span> Bozeman temperature trend</a></li>
<li><a href="6-4-section7-4.html#section7-4"><span class="toc-section-number">6.4</span> Randomization-based inferences for the slope coefficient</a></li>
<li><a href="6-5-section7-5.html#section7-5"><span class="toc-section-number">6.5</span> Transformations part I: Linearizing relationships</a></li>
<li><a href="6-6-section7-6.html#section7-6"><span class="toc-section-number">6.6</span> Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x)</a></li>
<li><a href="6-7-section7-7.html#section7-7"><span class="toc-section-number">6.7</span> Confidence interval for the mean and prediction intervals for a new observation</a></li>
<li><a href="6-8-section7-8.html#section7-8"><span class="toc-section-number">6.8</span> Chapter summary</a></li>
<li><a href="6-9-section7-9.html#section7-9"><span class="toc-section-number">6.9</span> Summary of important R code</a></li>
<li><a href="6-10-section7-10.html#section7-10"><span class="toc-section-number">6.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="7-chapter8.html#chapter8"><span class="toc-section-number">7</span> Multiple linear regression</a><ul>
<li><a href="7-1-section8-1.html#section8-1"><span class="toc-section-number">7.1</span> Going from SLR to MLR</a></li>
<li><a href="7-2-section8-2.html#section8-2"><span class="toc-section-number">7.2</span> Validity conditions in MLR</a></li>
<li><a href="7-3-section8-3.html#section8-3"><span class="toc-section-number">7.3</span> Interpretation of MLR terms</a></li>
<li><a href="7-4-section8-4.html#section8-4"><span class="toc-section-number">7.4</span> Comparing multiple regression models</a></li>
<li><a href="7-5-section8-5.html#section8-5"><span class="toc-section-number">7.5</span> General recommendations for MLR interpretations and VIFs</a></li>
<li><a href="7-6-section8-6.html#section8-6"><span class="toc-section-number">7.6</span> MLR inference: Parameter inferences using the t-distribution</a></li>
<li><a href="7-7-section8-7.html#section8-7"><span class="toc-section-number">7.7</span> Overall F-test in multiple linear regression</a></li>
<li><a href="7-8-section8-8.html#section8-8"><span class="toc-section-number">7.8</span> Case study: First year college GPA and SATs</a></li>
<li><a href="7-9-section8-9.html#section8-9"><span class="toc-section-number">7.9</span> Different intercepts for different groups: MLR with indicator variables</a></li>
<li><a href="7-10-section8-10.html#section8-10"><span class="toc-section-number">7.10</span> Additive MLR with more than two groups: Headache example</a></li>
<li><a href="7-11-section8-11.html#section8-11"><span class="toc-section-number">7.11</span> Different slopes and different intercepts</a></li>
<li><a href="7-12-section8-12.html#section8-12"><span class="toc-section-number">7.12</span> F-tests for MLR models with quantitative and categorical variables and interactions</a></li>
<li><a href="7-13-section8-13.html#section8-13"><span class="toc-section-number">7.13</span> AICs for model selection</a></li>
<li><a href="7-14-section8-14.html#section8-14"><span class="toc-section-number">7.14</span> Case study: Forced expiratory volume model selection using AICs</a></li>
<li><a href="7-15-section8-15.html#section8-15"><span class="toc-section-number">7.15</span> Chapter summary</a></li>
<li><a href="7-16-section8-16.html#section8-16"><span class="toc-section-number">7.16</span> Summary of important R code</a></li>
<li><a href="7-17-section8-17.html#section8-17"><span class="toc-section-number">7.17</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="8-chapter9.html#chapter9"><span class="toc-section-number">8</span> Case studies</a><ul>
<li><a href="8-1-section9-1.html#section9-1"><span class="toc-section-number">8.1</span> Overview of material covered</a></li>
<li><a href="8-2-section9-2.html#section9-2"><span class="toc-section-number">8.2</span> The impact of simulated chronic nitrogen deposition on the biomass and N2-fixation activity of two boreal feather moss–cyanobacteria associations</a></li>
<li><a href="8-3-section9-3.html#section9-3"><span class="toc-section-number">8.3</span> Ants learn to rely on more informative attributes during decision-making</a></li>
<li><a href="8-4-section9-4.html#section9-4"><span class="toc-section-number">8.4</span> Multi-variate models are essential for understanding vertebrate diversification in deep time</a></li>
<li><a href="8-5-section9-5.html#section9-5"><span class="toc-section-number">8.5</span> What do didgeridoos really do about sleepiness?</a></li>
<li><a href="8-6-section9-6.html#section9-6"><span class="toc-section-number">8.6</span> General summary</a></li>
</ul></li>
<li><a href="references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="section7-6" class="section level2">
<h2><span class="header-section-number">6.6</span> Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x)</h2>

<p>The previous attempts to linearize relationships imply a desire to be
able to fit SLR models.

The <em>log</em>-transformations, when successful,
provide the potential to validly apply our SLR model. There are then two options
for interpretations: you can either interpret the model on the
transformed scale or you can translate the SLR model on the transformed scale
back to the original scale of the variables. It ends up that
<em>log</em>-transformations have special interpretations on the original scales
depending on whether the <em>log</em> was applied to the response variable, the
explanatory variable, or both.</p>
<p><strong>Scenario 1: log(y) vs x model:</strong></p>
<p>First consider the <span class="math inline">\(\log(y) \sim x\)</span> situations where the estimated model
is of the form <span class="math inline">\(\widehat{\log(y)} = b_0 + b_1x\)</span>. When only the response is
<em>log</em>-transformed, some people call this a <strong><em>semi-log model</em></strong>.

But many
researchers will use this model without any special considerations, as
long as it provides
a situation where the SLR assumptions are reasonably well-satisfied.  To
understand the properties and eventually the interpretation of
transformed-variables models, we need to try to “reverse” our transformation.
If we exponentiate<a href="#fn106" class="footnote-ref" id="fnref106"><sup>106</sup></a> both sides of <span class="math inline">\(\log(y)=b_0 + b_1x\)</span>, we get:</p>
<div class="figure"><span id="fig:Figure7-18"></span>
<img src="07-simpleLinearRegressionInference_files/figure-html/Figure7-18-1.png" alt="(ref:fig7-18)" width="960" />
<p class="caption">
Figure 1.142: (ref:fig7-18)
</p>
</div>
<ul>
<li><p><span class="math inline">\(\exp(\log(y))=\exp(b_0 + b_1x)\)</span>, <em>which is</em></p></li>
<li><p><span class="math inline">\(y=\exp(b_0 + b_1x)\)</span>, <em>which can be re-written as</em></p></li>
<li><p><span class="math inline">\(y=\exp(b_0)\exp(b_1x)\)</span>. <em>This is based on the rules for</em> <code>exp()</code> <em>where</em>
<span class="math inline">\(\exp(a+b)=\exp(a)\exp(b)\)</span>.</p></li>
<li><p>Now consider what happens if we increase <span class="math inline">\(x\)</span> by 1 unit, going from <span class="math inline">\(x\)</span>
to <span class="math inline">\(x+1\)</span>, providing a new predicted <span class="math inline">\(y\)</span> that we can call <span class="math inline">\(y^*\)</span>:
<span class="math inline">\(y^*=\exp(b_0)\exp[b_1(x+1)]\)</span>:</p></li>
<li><p><span class="math inline">\(y^*={\color{red}{\underline{\boldsymbol{\exp(b_0)\exp(b_1x)}}}}\exp(b_1)\)</span>.
<em>Now note that the underlined, bold component was the y-value for</em> <span class="math inline">\(x\)</span>.</p></li>
<li><p><span class="math inline">\(y^* = {\color{red}{\boldsymbol{y}}}\exp(b_1)\)</span>. <em>Found by replacing</em>
<span class="math inline">\(\color{red}{\mathbf{\exp(b_0)\exp(b_1x)}}\)</span> <em>with</em> <span class="math inline">\(\color{red}{\mathbf{y}}\)</span>,
<em>the value for</em> <span class="math inline">\(x\)</span>.</p></li>
</ul>
<p>So the difference in fitted values between <span class="math inline">\(x\)</span> and <span class="math inline">\(x+1\)</span> is to multiply the
result for <span class="math inline">\(x\)</span> (that was predicting <span class="math inline">\(\color{red}{\mathbf{y}}\)</span>) by
<span class="math inline">\(\exp(b_1)\)</span> to get to the predicted result for <span class="math inline">\(x+1\)</span> (called <span class="math inline">\(y^*\)</span>).
We can then use this result to form our <span class="math inline">\(\mathit{\boldsymbol{\log(y)\sim x}}\)</span>
<strong><em>slope interpretation</em></strong>:

for a 1 unit increase in <span class="math inline">\(x\)</span>, we observe a multiplicative change of
<span class="math inline">\(\mathbf{exp(b_1)}\)</span> in the response. When we compute a mean on logged variables
that are symmetrically distributed (this should occur if our transformation was
successful) and then exponentiate the results, the proper interpretation is
that the changes are happening in the <strong>median</strong> of the original responses.
This is the only time in the course that we will switch our inferences to
medians instead of means, and we don’t do this because
we want to, we do it because it is result of modeling on the <span class="math inline">\(\log(y)\)</span> scale,
if successful.</p>
<p>When we are working with regression equations, slopes can either be positive or
negative and our interpretations change based on this result to either result
in growth (<span class="math inline">\(b_1&gt;0\)</span>) or decay (<span class="math inline">\(b_1&lt;0\)</span>) in the responses as the explanatory
variable is increased. As an example, consider <span class="math inline">\(b_1=0.4\)</span> and
<span class="math inline">\(\exp(b_1)=\exp(0.4)=1.492\)</span>. There are a couple of ways to interpret
this on the original scale of the response variable <span class="math inline">\(y\)</span>:</p>
<p>For <span class="math inline">\(\mathbf{b_1&gt;0}\)</span>:</p>
<ol style="list-style-type: decimal">
<li><p>For a 1 unit increase in <span class="math inline">\(x\)</span>, the median of <span class="math inline">\(y\)</span> is estimated to change by 1.492 times.</p></li>
<li><p>We can convert this into a <strong>percentage increase</strong> by subtracting 1
from <span class="math inline">\(\exp(0.4)\)</span>, <span class="math inline">\(1.492-1.0=0.492\)</span> and multiplying the result by 100,
<span class="math inline">\(0.492*100=49.2\%\)</span>. This is interpreted as: For a 1 unit increase in <span class="math inline">\(x\)</span>,
the median of <span class="math inline">\(y\)</span> is estimated to increase by 49.2%.</p></li>
</ol>
<div class="sourceCode" id="cb638"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb638-1" title="1"><span class="kw">exp</span>(<span class="fl">0.4</span>)</a></code></pre></div>
<pre><code>## [1] 1.491825</code></pre>
<p>For <span class="math inline">\(\mathbf{b_1&lt;0}\)</span>, the change on the <em>log</em>-scale is negative and that
implies on the original scale that the curve decays to 0. For example,
consider <span class="math inline">\(b_1=-0.3\)</span> and <span class="math inline">\(\exp(-0.3)=0.741\)</span>. Again,
there are two versions of the interpretation possible:</p>
<ol style="list-style-type: decimal">
<li><p>For a 1 unit increase in <span class="math inline">\(x\)</span>, the median of <span class="math inline">\(y\)</span> is estimated to change by 0.741 times.</p></li>
<li><p>For negative slope coefficients, the percentage decrease is calculated
as <span class="math inline">\((1-\exp(b_1))*100\%\)</span>. For <span class="math inline">\(\exp(-0.3)=0.741\)</span>, this is
<span class="math inline">\((1-0.741)*100=25.9\%\)</span>. This is interpreted as: For a 1 unit increase
in <span class="math inline">\(x\)</span>, the median of <span class="math inline">\(y\)</span> is estimated to decrease by 25.9%.</p></li>
</ol>
<p>We suspect that you will typically prefer interpretation #1 for both
directions but it is important to be able
think about the results in terms of <strong><em>% change of the medians</em></strong> to make
the scale of change more understandable. Some examples will help us see how
these ideas can be used in applications.</p>
<p>For the area burned data set, the estimated regression model is
<span class="math inline">\(\log(\widehat{\text{hectares}})=-69.8+1.39\cdot\text{ Temp}\)</span>. On the
original scale, this implies that the model is
<span class="math inline">\(\widehat{\text{hectares}}=\exp(-69.8)\exp(1.39\text{ Temp})\)</span>.
Figure <a href="6-6-section7-6.html#fig:Figure7-18">1.142</a> provides the <span class="math inline">\(\log(y)\)</span> scale version of
the model and the model transformed to the
original scale of measurement. On the log-hectares scale, the interpretation of
the slope is: For a 1<span class="math inline">\(^\circ F\)</span> increase in summer temperature, we
estimate a 1.39 log-hectares/1<span class="math inline">\(^\circ F\)</span> change, on average, in the log-area
burned. On the original scale: A 1<span class="math inline">\(^\circ F\)</span> increase in temperature is
related to an estimated multiplicative change in the median number of hectares burned of
<span class="math inline">\(\exp(1.39)=4.01\)</span> times higher areas. That seems like a big rate of growth but the curve does
grow rapidly as shown in panel (b), especially for values over
58<span class="math inline">\(^\circ F\)</span> where the area burned is starting to be really large. You can think
of the multiplicative change here in the following way: the median
number of hectares burned is 4 times higher at 58<span class="math inline">\(^\circ F\)</span> than at
57<span class="math inline">\(^\circ F\)</span> and the median area burned is 4 times larger at 59<span class="math inline">\(^\circ F\)</span>
than at 58<span class="math inline">\(^\circ F\)</span>… This can also be interpreted on a % change scale:
A 1<span class="math inline">\(^\circ F\)</span> increase in temperature is related
to an estimated <span class="math inline">\((4.01-1)*100 = 301\%\)</span> increase in the median number of hectares burned.</p>
<p>(ref:fig7-18) Plot of the estimated SLR (a) and implied model for the
median on the original Hectares scale (b) for the area burned vs
temperature data.</p>
<p><strong>Scenario 2: y vs log(x) model:</strong></p>
<p>When only the explanatory variable is log-transformed, it has a
different sort of
impact on the regression model interpretation.

Effectively we move the
percentage change onto the x-scale and modify the first part of our slope
interpretation when we consider the results on the original scale for <span class="math inline">\(x\)</span>. Once again,
we will consider the mathematics underlying the changes in the model and then
work on applying it to real situations. When the explanatory variable is
logged, the estimated regression model is
<span class="math inline">\(\color{red}{\boldsymbol{y=b_0+b_1\log(x)}}\)</span>. This models the relationship
between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> in terms of multiplicative changes in <span class="math inline">\(x\)</span> having an
effect on the average <span class="math inline">\(y\)</span>. To develop an interpretation on the x-scale
(not <span class="math inline">\(\log(x)\)</span>), consider the impact of doubling <span class="math inline">\(x\)</span>. This change will
take us from the point (<span class="math inline">\(x,\color{red}{\boldsymbol{y=b_0+b_1\log(x)}}\)</span>)
to the point <span class="math inline">\((2x,\boldsymbol{y^*=b_0+b_1\log(2x)})\)</span>. Now the impact of
doubling <span class="math inline">\(x\)</span> can
be simplified using the rules for logs to be:</p>
<ul>
<li><p><span class="math inline">\(\boldsymbol{y^*=b_0+b_1\log(2x)}\)</span>,</p></li>
<li><p><span class="math inline">\(\boldsymbol{y^*}={\color{red}{\underline{\boldsymbol{b_0+b_1\log(x)}}}} + b_1\log(2)\)</span>.   <em>Based on the rules for logs:</em> <span class="math inline">\(log(2x)=log(x)+log(2)\)</span>.</p></li>
<li><p><span class="math inline">\(y^* = {\color{red}{\boldsymbol{y}}}+b_1\log(2)\)</span></p></li>
<li><p>So if we double <span class="math inline">\(x\)</span>, we change the <strong>mean</strong> of <span class="math inline">\(y\)</span> by <span class="math inline">\(b_1\log(2)\)</span>.</p></li>
</ul>
<p>As before, there are couple of ways to interpret these sorts of results,
</p>
<ol style="list-style-type: decimal">
<li><p><strong><em>log-scale interpretation of log(x) only model</em></strong>: for a 1 log-unit
increase in <span class="math inline">\(x\)</span>, we estimate a <span class="math inline">\(b_1\)</span> unit change in the mean of <span class="math inline">\(y\)</span> or</p></li>
<li><p><strong><em>original scale interpretation of log(x) only model</em></strong>: for a
doubling of <span class="math inline">\(x\)</span>, we estimate a <span class="math inline">\(b_1\log(2)\)</span> change in the mean of <span class="math inline">\(y\)</span>.
Note that both interpretations are for the mean of the <span class="math inline">\(y\text{&#39;s}\)</span>
since we haven’t changed the <span class="math inline">\(y\sim\)</span> part of the model.</p></li>
</ol>
<p>(ref:fig7-19) Plot of the observations and estimated SLR model
(mortality~ log(GDP)) (top) and implied model (bottom) for the
infant mortality data.</p>
<div class="figure"><span id="fig:Figure7-19"></span>
<img src="07-simpleLinearRegressionInference_files/figure-html/Figure7-19-1.png" alt="(ref:fig7-19)" width="960" />
<p class="caption">
Figure 1.143: (ref:fig7-19)
</p>
</div>
<p>While it is not a perfect model (no model is), let’s consider the model
for <em>infant mortality</em> <span class="math inline">\(\sim\)</span> <em>log(GDP)</em> in order to practice the
interpretation using this type of model. This model was estimated to be
<span class="math inline">\(\widehat{\text{infantmortality}}=155.77-14.86\cdot\log(\text{GDP})\)</span>. The first
(simplest) interpretation of the slope coefficient is: For a 1 log-dollar
increase in GDP per capita, we estimate infant
mortality to change, on average, by -14.86 deaths/1000 live births. The
second interpretation is on the original GDP scale: For a doubling of GDP, we
estimate infant mortality to change, on average, by <span class="math inline">\(-14.86\log(2) = -10.3\)</span>
deaths/1000 live births. Or, the mean infant mortality is reduced by
10.3 deaths per 1000 live births for each doubling of
GDP. Both versions of the model are displayed in Figure <a href="6-6-section7-6.html#fig:Figure7-19">1.143</a>
– one on the scale
the SLR model was fit (panel a) and the other on the original x-scale (panel b)
that matches these last interpretations.</p>

<div class="sourceCode" id="cb640"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb640-1" title="1">ID1 &lt;-<span class="st"> </span><span class="kw">lm</span>(infantMortality<span class="op">~</span><span class="kw">log</span>(ppgdp), <span class="dt">data=</span>UN)</a>
<a class="sourceLine" id="cb640-2" title="2"><span class="kw">summary</span>(ID1)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = infantMortality ~ log(ppgdp), data = UN)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -38.239 -11.609  -2.829   8.122  82.183 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 155.7698     7.2431   21.51   &lt;2e-16
## log(ppgdp)  -14.8617     0.8468  -17.55   &lt;2e-16
## 
## Residual standard error: 18.14 on 191 degrees of freedom
##   (20 observations deleted due to missingness)
## Multiple R-squared:  0.6172, Adjusted R-squared:  0.6152 
## F-statistic:   308 on 1 and 191 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb642"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb642-1" title="1"><span class="fl">-14.86</span><span class="op">*</span><span class="kw">log</span>(<span class="dv">2</span>)</a></code></pre></div>
<pre><code>## [1] -10.30017</code></pre>
<p>It appears that our model does not fit too well and that there might be
some non-constant variance so we
should check the diagnostic plots (available in Figure <a href="6-6-section7-6.html#fig:Figure7-20">1.144</a>)
before we trust
any of those previous interpretations.</p>
<p>(ref:fig7-20) Diagnostics plots of the infant mortality model with
log(GDP).</p>
<div class="sourceCode" id="cb644"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb644-1" title="1"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb644-2" title="2"><span class="kw">plot</span>(ID1)</a></code></pre></div>
<div class="figure"><span id="fig:Figure7-20"></span>
<img src="07-simpleLinearRegressionInference_files/figure-html/Figure7-20-1.png" alt="(ref:fig7-20)" width="960" />
<p class="caption">
Figure 1.144: (ref:fig7-20)
</p>
</div>
<p>There appear to be issues with outliers and a long right tail violating
the normality assumption as it suggests a clear right skewed residual distribution. There is
curvature and non-constant variance in the results as well. There are no
influential points, but we are far from happy with this model and will be
revisiting this example with the responses also transformed. Remember that the
log-transformation of the response can potentially fix non-constant variance,
normality, and curvature issues.</p>
<p><strong>Scenario 3: log(y)~log(x) model</strong></p>
<p>A final model combines log-transformations of both <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, combining the interpretations used in the previous two situations. This model is called the
<strong><em>log-log model</em></strong> and in some fields is also called the <strong><em>power law model</em></strong>.


The power-law model is usually written as <span class="math inline">\(y = \beta_0x^{\beta_1}+\varepsilon\)</span>,
where <span class="math inline">\(y\)</span> is thought to be proportional to <span class="math inline">\(x\)</span> raised to an estimated power
of <span class="math inline">\(\beta_1\)</span> (linear if <span class="math inline">\(\beta_1=1\)</span> and quadratic if <span class="math inline">\(\beta_1=2\)</span>). It is
one of the models that has been used in Geomorphology to model the shape of
glaciated valley elevation profiles
(that classic U-shape that comes with glacier-eroded mountain valleys)<a href="#fn107" class="footnote-ref" id="fnref107"><sup>107</sup></a>. If you
ignore the error term, it is possible to estimate the power-law model using our
SLR approach. Consider the log-transformation of both sides of this equation
starting with the power-law version:</p>
<ul>
<li><p><span class="math inline">\(\log(y) = \log(\beta_0x^{\beta_1})\)</span>,</p></li>
<li><p><span class="math inline">\(\log(y) = \log(\beta_0) + \log(x^{\beta_1}).\)</span>   <em>Based on the rules
for logs:</em> <span class="math inline">\(\log(ab) = \log(a) + \log(b)\)</span>.</p></li>
<li><p><span class="math inline">\(\log(y) = \log(\beta_0) + \beta_1\log(x).\)</span>   <em>Based on the rules
for logs:</em> <span class="math inline">\(\log(x^b) = b\log(x)\)</span>.</p></li>
</ul>
<p>(ref:fig7-21) Plot of the observations and estimated SLR model
log(mortality) <span class="math inline">\(\sim\)</span> log(GDP) (left) and implied model (right) for the infant
mortality data.</p>
<div class="figure"><span id="fig:Figure7-21"></span>
<img src="07-simpleLinearRegressionInference_files/figure-html/Figure7-21-1.png" alt="(ref:fig7-21)" width="576" />
<p class="caption">
Figure 1.145: (ref:fig7-21)
</p>
</div>
<p>So other than <span class="math inline">\(\log(\beta_0)\)</span> in the model, this looks just like our
regular SLR model with <span class="math inline">\(x\)</span>
and <span class="math inline">\(y\)</span> both log-transformed. The slope coefficient for <span class="math inline">\(\log(x)\)</span> is the
power coefficient in the original power law model and determines whether
the relationship between the original <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> in <span class="math inline">\(y=\beta_0x^{\beta_1}\)</span>
is linear <span class="math inline">\((y=\beta_0x^1)\)</span> or quadratic <span class="math inline">\((y=\beta_0x^2)\)</span> or even quartic
<span class="math inline">\((y=\beta_0x^4)\)</span> in some really heavily glacier carved
U-shaped valleys. There are some issues with “ignoring the errors” in using SLR
to estimate these models <span class="citation">(Greenwood and Humphrey <a href="#ref-Greenwood2002" role="doc-biblioref">2002</a>)</span> but it is still a
pretty powerful result to be able to estimate the coefficients in
<span class="math inline">\((y=\beta_0x^{\beta_1})\)</span> using SLR.</p>
<p>We don’t typically use
the previous ideas to interpret the typical log-log regression model, instead
we combine our two previous interpretation techniques to generate our
interpretation. We need to work out the mathematics of doubling <span class="math inline">\(x\)</span> and the
changes in <span class="math inline">\(y\)</span> starting with the <span class="math inline">\(\mathit{\boldsymbol{\log(y)\sim \log(x)}}\)</span>
<strong><em>model</em></strong> that we would get out of fitting the SLR with both variables
log-transformed:</p>
<ul>
<li><p><span class="math inline">\(\log(y) = b_0 + b_1\log(x)\)</span>,</p></li>
<li><p><span class="math inline">\(y = \exp(b_0 + b_1\log(x))\)</span>.   <em>Exponentiate
both sides</em>.</p></li>
<li><p><span class="math inline">\(y = \exp(b_0)\exp(b_1\log(x))=\exp(b_0)x^{b_1}\)</span>.   <em>Rules for
exponents and logs, simplifying.</em></p></li>
</ul>
<p>Now we can consider the impacts of doubling <span class="math inline">\(x\)</span> on <span class="math inline">\(y\)</span>, going from
<span class="math inline">\((x,{\color{red}{\boldsymbol{y=\exp(b_0)x^{b_1}}}})\)</span> to <span class="math inline">\((2x,y^*)\)</span> with</p>
<ul>
<li><p><span class="math inline">\(y^* = \exp(b_0)(2x)^{b_1}\)</span>,</p></li>
<li><p><span class="math inline">\(y^* = \exp(b_0)2^{b_1}x^{b_1} = 2^{b_1}{\color{red}{\boldsymbol{\exp(b_0)x^{b_1}}}}=2^{b_1}{\color{red}{\boldsymbol{y}}}\)</span></p></li>
</ul>
<p>So doubling <span class="math inline">\(x\)</span> leads to a multiplicative change in the median of <span class="math inline">\(y\)</span>
of <span class="math inline">\(2^{b_1}\)</span>.</p>
<p>Let’s apply this idea to the GDP and infant mortality data where a
<span class="math inline">\(\log(x) \sim \log(y)\)</span> transformation
actually made the resulting relationship look like it might be close to being reasonably modeled with an SLR. The regression line in Figure <a href="6-6-section7-6.html#fig:Figure7-21">1.145</a> actually looks
pretty good on both
the estimated log-log scale (panel a) and on the original scale (panel b) as it
captures the severe nonlinearity in the relationship between the two variables.</p>

<div class="figure"><span id="fig:Figure7-22"></span>
<img src="07-simpleLinearRegressionInference_files/figure-html/Figure7-22-1.png" alt="Diagnostic plots for the log-log infant mortality model." width="960" />
<p class="caption">
Figure 1.146: Diagnostic plots for the log-log infant mortality model.
</p>
</div>
<div class="sourceCode" id="cb645"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb645-1" title="1">ID2 &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(infantMortality)<span class="op">~</span><span class="kw">log</span>(ppgdp), <span class="dt">data=</span>UN)</a>
<a class="sourceLine" id="cb645-2" title="2"><span class="kw">summary</span>(ID2)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(infantMortality) ~ log(ppgdp), data = UN)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.16789 -0.36738 -0.02351  0.24544  2.43503 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  8.10377    0.21087   38.43   &lt;2e-16
## log(ppgdp)  -0.61680    0.02465  -25.02   &lt;2e-16
## 
## Residual standard error: 0.5281 on 191 degrees of freedom
##   (20 observations deleted due to missingness)
## Multiple R-squared:  0.7662, Adjusted R-squared:  0.765 
## F-statistic: 625.9 on 1 and 191 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The estimated regression model is
<span class="math inline">\(\log(\widehat{\text{infantmortality}})=8.104-0.617\cdot\log(\text{GDP})\)</span>.
The slope coefficient can be interpreted two ways.
</p>
<ol style="list-style-type: decimal">
<li><p><strong><em>On the log-log scale:</em></strong> For a 1 log-dollar increase in <em>GDP</em>, we estimate, on average,
a change of <span class="math inline">\(-0.617\)</span> log(deaths/1000 live births) in <em>infant mortality</em>.</p></li>
<li><p><strong><em>On the original scale:</em></strong> For a doubling of <em>GDP</em>, we expect a
<span class="math inline">\(2^{b_1} = 2^{-0.617} = 0.652\)</span> multiplicative change in the estimated median <em>infant mortality</em>.
That is a 34.8%
decrease in the estimated median <em>infant mortality</em> for each doubling of <em>GDP</em>.</p></li>
</ol>
<p>The diagnostics of the log-log SLR model (Figure <a href="6-6-section7-6.html#fig:Figure7-22">1.146</a>)
show minimal evidence of violations of assumptions although the tails of
the residuals are a little heavy (more spread out than a normal distribution)
and there might still be a little pattern remaining in the residuals vs fitted values.

There are no influential points to be concerned about in this situation.</p>
<p>While we will not revisit this at all except in the case-studies
in Chapter <a href="8-chapter9.html#chapter9"><strong>??</strong></a>,
log-transformations can be applied to the response variable in ONE and TWO-WAY
ANOVA models when we are concerned about non-constant variance and
non-normality issues<a href="#fn108" class="footnote-ref" id="fnref108"><sup>108</sup></a>. The remaining methods in this chapter return to SLR and assuming
that the model is at least reasonable to consider in each situation, possibly after transformation(s). In fact, the methods in Section <a href="6-7-section7-7.html#section7-7">6.7</a>
are some of the most sensitive results to violations of the assumptions that we
will explore.</p>


</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Greenwood2002">
<p>Greenwood, Mark C., and N. F. Humphrey. 2002. “Glaciated Valley Profiles: An Application of Nonlinear Regression.” <em>Computing Science and Statistics</em> 34: 452–60.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="106">
<li id="fn106"><p>Note <code>exp(x)</code> is the same as <span class="math inline">\(e^{(x)}\)</span> but easier
to read in-line and <code>exp()</code> is the R function name to execute this calculation.<a href="6-6-section7-6.html#fnref106" class="footnote-back">↩</a></p></li>
<li id="fn107"><p>You can read my dissertation if you want my take on modeling U and V-shaped valley elevation profiles that included some discussion of these models and some related discussions in <span class="citation">Greenwood and Humphrey (<a href="#ref-Greenwood2002" role="doc-biblioref">2002</a>)</span>.<a href="6-6-section7-6.html#fnref107" class="footnote-back">↩</a></p></li>
<li id="fn108"><p>This transformation could not be applied directly to the education growth score data in Chapter <a href="4-chapter5.html#chapter5"><strong>??</strong></a> because there were negative “growth” scores.<a href="6-6-section7-6.html#fnref108" class="footnote-back">↩</a></p></li>
</ol>
</div>
<p style="text-align: center;">
<a href="6-5-section7-5.html"><button class="btn btn-default">Previous</button></a>
<a href="6-7-section7-7.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
