<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="8.4 Multi-variate models are essential for understanding vertebrate diversification in deep time | Intermediate Statistics with R" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="gpeterson406/Greenwood_Book" />

<meta name="author" content="Mark C Greenwood" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="8.4 Multi-variate models are essential for understanding vertebrate diversification in deep time | Intermediate Statistics with R">

<title>8.4 Multi-variate models are essential for understanding vertebrate diversification in deep time | Intermediate Statistics with R</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#cover">Cover</a></li>
<li class="has-sub"><a href="acknowledgments.html#acknowledgments">Acknowledgments</a><ul>
<li><a href="0-1-section1-5.html#section1-5"><span class="toc-section-number">0.1</span> Summary of important R code</a></li>
</ul></li>
<li class="has-sub"><a href="1-chapter2.html#chapter2"><span class="toc-section-number">1</span> (R)e-Introduction to statistics</a><ul>
<li><a href="1-1-section2-1.html#section2-1"><span class="toc-section-number">1.1</span> Histograms, boxplots, and density curves</a></li>
<li><a href="1-2-section2-2.html#section2-2"><span class="toc-section-number">1.2</span> Pirate-plots</a></li>
<li><a href="1-3-section2-3.html#section2-3"><span class="toc-section-number">1.3</span> Models, hypotheses, and permutations for the two sample mean situation</a></li>
<li><a href="1-4-section2-4.html#section2-4"><span class="toc-section-number">1.4</span> Permutation testing for the two sample mean situation</a></li>
<li><a href="1-5-section2-5.html#section2-5"><span class="toc-section-number">1.5</span> Hypothesis testing (general)</a></li>
<li><a href="1-6-section2-6.html#section2-6"><span class="toc-section-number">1.6</span> Connecting randomization (nonparametric) and parametric tests</a></li>
<li><a href="1-7-section2-7.html#section2-7"><span class="toc-section-number">1.7</span> Second example of permutation tests</a></li>
<li><a href="1-8-section2-8.html#section2-8"><span class="toc-section-number">1.8</span> Reproducibility Crisis: Moving beyond p &lt; 0.05, publication bias, and multiple testing issues</a></li>
<li><a href="1-9-section2-9.html#section2-9"><span class="toc-section-number">1.9</span> Confidence intervals and bootstrapping</a></li>
<li><a href="1-10-section2-10.html#section2-10"><span class="toc-section-number">1.10</span> Bootstrap confidence intervals for difference in GPAs</a></li>
<li><a href="1-11-section2-11.html#section2-11"><span class="toc-section-number">1.11</span> Chapter summary</a></li>
<li><a href="1-12-section2-12.html#section2-12"><span class="toc-section-number">1.12</span> Summary of important R code</a></li>
<li><a href="1-13-section2-13.html#section2-13"><span class="toc-section-number">1.13</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="2-chapter3.html#chapter3"><span class="toc-section-number">2</span> One-Way ANOVA</a><ul>
<li><a href="2-1-section3-1.html#section3-1"><span class="toc-section-number">2.1</span> Situation</a></li>
<li><a href="2-2-section3-2.html#section3-2"><span class="toc-section-number">2.2</span> Linear model for One-Way ANOVA (cell-means and reference-coding)</a></li>
<li><a href="2-3-section3-3.html#section3-3"><span class="toc-section-number">2.3</span> One-Way ANOVA Sums of Squares, Mean Squares, and F-test</a></li>
<li><a href="2-4-section3-4.html#section3-4"><span class="toc-section-number">2.4</span> ANOVA model diagnostics including QQ-plots</a></li>
<li><a href="2-5-section3-5.html#section3-5"><span class="toc-section-number">2.5</span> Guinea pig tooth growth One-Way ANOVA example</a></li>
<li><a href="2-6-section3-6.html#section3-6"><span class="toc-section-number">2.6</span> Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display</a></li>
<li><a href="2-7-section3-7.html#section3-7"><span class="toc-section-number">2.7</span> Pair-wise comparisons for the Overtake data</a></li>
<li><a href="2-8-section3-8.html#section3-8"><span class="toc-section-number">2.8</span> Chapter summary</a></li>
<li><a href="2-9-section3-9.html#section3-9"><span class="toc-section-number">2.9</span> Summary of important R code</a></li>
<li><a href="2-10-section3-10.html#section3-10"><span class="toc-section-number">2.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="3-chapter4.html#chapter4"><span class="toc-section-number">3</span> Two-Way ANOVA</a><ul>
<li><a href="3-1-section4-1.html#section4-1"><span class="toc-section-number">3.1</span> Situation</a></li>
<li><a href="3-2-section4-2.html#section4-2"><span class="toc-section-number">3.2</span> Designing a two-way experiment and visualizing results</a></li>
<li><a href="3-3-section4-3.html#section4-3"><span class="toc-section-number">3.3</span> Two-Way ANOVA models and hypothesis tests</a></li>
<li><a href="3-4-section4-4.html#section4-4"><span class="toc-section-number">3.4</span> Guinea pig tooth growth analysis with Two-Way ANOVA</a></li>
<li><a href="3-5-section4-5.html#section4-5"><span class="toc-section-number">3.5</span> Observational study example: The Psychology of Debt</a></li>
<li><a href="3-6-section4-6.html#section4-6"><span class="toc-section-number">3.6</span> Pushing Two-Way ANOVA to the limit: Un-replicated designs and Estimability</a></li>
<li><a href="3-7-section4-7.html#section4-7"><span class="toc-section-number">3.7</span> Chapter summary</a></li>
<li><a href="3-8-section4-8.html#section4-8"><span class="toc-section-number">3.8</span> Summary of important R code</a></li>
<li><a href="3-9-section4-9.html#section4-9"><span class="toc-section-number">3.9</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="4-chapter5.html#chapter5"><span class="toc-section-number">4</span> Chi-square tests</a><ul>
<li><a href="4-1-section5-1.html#section5-1"><span class="toc-section-number">4.1</span> Situation, contingency tables, and tableplots</a></li>
<li><a href="4-2-section5-2.html#section5-2"><span class="toc-section-number">4.2</span> Homogeneity test hypotheses</a></li>
<li><a href="4-3-section5-3.html#section5-3"><span class="toc-section-number">4.3</span> Independence test hypotheses</a></li>
<li><a href="4-4-section5-4.html#section5-4"><span class="toc-section-number">4.4</span> Models for R by C tables</a></li>
<li><a href="4-5-section5-5.html#section5-5"><span class="toc-section-number">4.5</span> Permutation tests for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="4-6-section5-6.html#section5-6"><span class="toc-section-number">4.6</span> Chi-square distribution for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="4-7-section5-7.html#section5-7"><span class="toc-section-number">4.7</span> Examining residuals for the source of differences</a></li>
<li><a href="4-8-section5-8.html#section5-8"><span class="toc-section-number">4.8</span> General protocol for <span class="math inline">\(X^2\)</span> tests</a></li>
<li><a href="4-9-section5-9.html#section5-9"><span class="toc-section-number">4.9</span> Political party and voting results: Complete analysis</a></li>
<li><a href="4-10-section5-10.html#section5-10"><span class="toc-section-number">4.10</span> Is cheating and lying related in students?</a></li>
<li><a href="4-11-section5-11.html#section5-11"><span class="toc-section-number">4.11</span> Analyzing a stratified random sample of California schools</a></li>
<li><a href="4-12-section5-12.html#section5-12"><span class="toc-section-number">4.12</span> Chapter summary</a></li>
<li><a href="4-13-section5-13.html#section5-13"><span class="toc-section-number">4.13</span> Summary of important R commands</a></li>
<li><a href="4-14-section5-14.html#section5-14"><span class="toc-section-number">4.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="5-chapter6.html#chapter6"><span class="toc-section-number">5</span> Correlation and Simple Linear Regression</a><ul>
<li><a href="5-1-section6-1.html#section6-1"><span class="toc-section-number">5.1</span> Relationships between two quantitative variables</a></li>
<li><a href="5-2-section6-2.html#section6-2"><span class="toc-section-number">5.2</span> Estimating the correlation coefficient</a></li>
<li><a href="5-3-section6-3.html#section6-3"><span class="toc-section-number">5.3</span> Relationships between variables by groups</a></li>
<li><a href="5-4-section6-4.html#section6-4"><span class="toc-section-number">5.4</span> Inference for the correlation coefficient</a></li>
<li><a href="5-5-section6-5.html#section6-5"><span class="toc-section-number">5.5</span> Are tree diameters related to tree heights?</a></li>
<li><a href="5-6-section6-6.html#section6-6"><span class="toc-section-number">5.6</span> Describing relationships with a regression model</a></li>
<li><a href="5-7-section6-7.html#section6-7"><span class="toc-section-number">5.7</span> Least Squares Estimation</a></li>
<li><a href="5-8-section6-8.html#section6-8"><span class="toc-section-number">5.8</span> Measuring the strength of regressions: R<sup>2</sup></a></li>
<li><a href="5-9-section6-9.html#section6-9"><span class="toc-section-number">5.9</span> Outliers: leverage and influence</a></li>
<li><a href="5-10-section6-10.html#section6-10"><span class="toc-section-number">5.10</span> Residual diagnostics – setting the stage for inference</a></li>
<li><a href="5-11-section6-11.html#section6-11"><span class="toc-section-number">5.11</span> Old Faithful discharge and waiting times</a></li>
<li><a href="5-12-section6-12.html#section6-12"><span class="toc-section-number">5.12</span> Chapter summary</a></li>
<li><a href="5-13-section6-13.html#section6-13"><span class="toc-section-number">5.13</span> Summary of important R code</a></li>
<li><a href="5-14-section6-14.html#section6-14"><span class="toc-section-number">5.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="6-chapter7.html#chapter7"><span class="toc-section-number">6</span> Simple linear regression inference</a><ul>
<li><a href="6-1-section7-1.html#section7-1"><span class="toc-section-number">6.1</span> Model</a></li>
<li><a href="6-2-section7-2.html#section7-2"><span class="toc-section-number">6.2</span> Confidence interval and hypothesis tests for the slope and intercept</a></li>
<li><a href="6-3-section7-3.html#section7-3"><span class="toc-section-number">6.3</span> Bozeman temperature trend</a></li>
<li><a href="6-4-section7-4.html#section7-4"><span class="toc-section-number">6.4</span> Randomization-based inferences for the slope coefficient</a></li>
<li><a href="6-5-section7-5.html#section7-5"><span class="toc-section-number">6.5</span> Transformations part I: Linearizing relationships</a></li>
<li><a href="6-6-section7-6.html#section7-6"><span class="toc-section-number">6.6</span> Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x)</a></li>
<li><a href="6-7-section7-7.html#section7-7"><span class="toc-section-number">6.7</span> Confidence interval for the mean and prediction intervals for a new observation</a></li>
<li><a href="6-8-section7-8.html#section7-8"><span class="toc-section-number">6.8</span> Chapter summary</a></li>
<li><a href="6-9-section7-9.html#section7-9"><span class="toc-section-number">6.9</span> Summary of important R code</a></li>
<li><a href="6-10-section7-10.html#section7-10"><span class="toc-section-number">6.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="7-chapter8.html#chapter8"><span class="toc-section-number">7</span> Multiple linear regression</a><ul>
<li><a href="7-1-section8-1.html#section8-1"><span class="toc-section-number">7.1</span> Going from SLR to MLR</a></li>
<li><a href="7-2-section8-2.html#section8-2"><span class="toc-section-number">7.2</span> Validity conditions in MLR</a></li>
<li><a href="7-3-section8-3.html#section8-3"><span class="toc-section-number">7.3</span> Interpretation of MLR terms</a></li>
<li><a href="7-4-section8-4.html#section8-4"><span class="toc-section-number">7.4</span> Comparing multiple regression models</a></li>
<li><a href="7-5-section8-5.html#section8-5"><span class="toc-section-number">7.5</span> General recommendations for MLR interpretations and VIFs</a></li>
<li><a href="7-6-section8-6.html#section8-6"><span class="toc-section-number">7.6</span> MLR inference: Parameter inferences using the t-distribution</a></li>
<li><a href="7-7-section8-7.html#section8-7"><span class="toc-section-number">7.7</span> Overall F-test in multiple linear regression</a></li>
<li><a href="7-8-section8-8.html#section8-8"><span class="toc-section-number">7.8</span> Case study: First year college GPA and SATs</a></li>
<li><a href="7-9-section8-9.html#section8-9"><span class="toc-section-number">7.9</span> Different intercepts for different groups: MLR with indicator variables</a></li>
<li><a href="7-10-section8-10.html#section8-10"><span class="toc-section-number">7.10</span> Additive MLR with more than two groups: Headache example</a></li>
<li><a href="7-11-section8-11.html#section8-11"><span class="toc-section-number">7.11</span> Different slopes and different intercepts</a></li>
<li><a href="7-12-section8-12.html#section8-12"><span class="toc-section-number">7.12</span> F-tests for MLR models with quantitative and categorical variables and interactions</a></li>
<li><a href="7-13-section8-13.html#section8-13"><span class="toc-section-number">7.13</span> AICs for model selection</a></li>
<li><a href="7-14-section8-14.html#section8-14"><span class="toc-section-number">7.14</span> Case study: Forced expiratory volume model selection using AICs</a></li>
<li><a href="7-15-section8-15.html#section8-15"><span class="toc-section-number">7.15</span> Chapter summary</a></li>
<li><a href="7-16-section8-16.html#section8-16"><span class="toc-section-number">7.16</span> Summary of important R code</a></li>
<li><a href="7-17-section8-17.html#section8-17"><span class="toc-section-number">7.17</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="8-chapter9.html#chapter9"><span class="toc-section-number">8</span> Case studies</a><ul>
<li><a href="8-1-section9-1.html#section9-1"><span class="toc-section-number">8.1</span> Overview of material covered</a></li>
<li><a href="8-2-section9-2.html#section9-2"><span class="toc-section-number">8.2</span> The impact of simulated chronic nitrogen deposition on the biomass and N2-fixation activity of two boreal feather moss–cyanobacteria associations</a></li>
<li><a href="8-3-section9-3.html#section9-3"><span class="toc-section-number">8.3</span> Ants learn to rely on more informative attributes during decision-making</a></li>
<li><a href="8-4-section9-4.html#section9-4"><span class="toc-section-number">8.4</span> Multi-variate models are essential for understanding vertebrate diversification in deep time</a></li>
<li><a href="8-5-section9-5.html#section9-5"><span class="toc-section-number">8.5</span> What do didgeridoos really do about sleepiness?</a></li>
<li><a href="8-6-section9-6.html#section9-6"><span class="toc-section-number">8.6</span> General summary</a></li>
</ul></li>
<li><a href="references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="section9-4" class="section level2">
<h2><span class="header-section-number">8.4</span> Multi-variate models are essential for understanding vertebrate diversification in deep time</h2>

<p><span class="citation">Benson and Mannion (<a href="#ref-Benson2012" role="doc-biblioref">2012</a>)</span> published a paleontology study that considered
modeling the diversity of <em>Sauropodomorphs</em> across <span class="math inline">\(n=26\)</span> “stage-level” time
bins. Diversity is measured by the count of the number of different species
that have been found in a particular level of fossils. Specifically, the counts
in the <em>Sauropodomorphs</em> group were obtained for stages between <em>Carnian</em> and
<em>Maastrichtian</em>, with the first three stages in the <em>Triassic</em>, the next ten in
the <em>Jurassic</em>, and the last eleven in the <em>Cretaceous</em>. They were concerned
about variation in sampling
efforts and the ability of paleontologists to find fossils across different
stages creating a false impression of the changes in biodiversity (counts of species) over time.
They first wanted to see if the species counts were related to factors such as
the count of dinosaur-bearing-formations (<em>DBF</em>) and the count of
dinosaur-bearing-collections (<em>DBC</em>) that have been identified for each period.
The thought is that if there are more formations or collections of fossils from
certain stages, the diversity might be better counted (more found of those
available to find) and those stages with less information available might be
under-counted. They also measured the length of each stage (<em>Duration</em>) but did
not consider it in their models since they want to reflect the diversity and
longer stages would likely have higher diversity.</p>
<p>Their main goal was to develop a model that would <strong>control for</strong> the effects
of sampling efforts and allow them to perform inferences for whether the
diversity was different between the <em>Triassic/Jurassic</em> (grouped together) and
considered models that included two different versions of sampling effort
variables and one for the comparisons of periods (an indicator variable
<em>TJK</em>=0 if the observation is in <em>Triassic</em> or <em>Jurassic</em> or 1 if in
<em>Cretaceous</em>).  They <em>log-e</em> transformed all their quantitative variables
because the untransformed variables created diagnostic issues including
influential points.  They explored a model just based on the <em>DBC</em>
predictor<a href="#fn144" class="footnote-ref" id="fnref144"><sup>144</sup></a> and they analyzed the residuals from that model to see if the
biodiversity was different in the <em>Cretaceous</em> or before, finding a
“p-value <strong>&gt;=</strong> 0.0001” (I think they meant &lt; 0.0001<a href="#fn145" class="footnote-ref" id="fnref145"><sup>145</sup></a>). They were comparing the MLR
models you learned to some extended regression models that incorporated a
correction for correlation in the responses over time, but we can proceed with
fitting some of their MLR models and using an AIC comparison similar to what
they used. There are some obvious flaws in their analysis and results that we
will avoid<a href="#fn146" class="footnote-ref" id="fnref146"><sup>146</sup></a>.</p>
<p>First, we start with a plot of the log-diversity vs the log-dinosaur bearing
collections by period. We can see fairly strong positive relationships between
the log amounts of collections and species found with potentially similar
slopes for the two periods but what look like different intercepts. Especially
for <em>TJK</em> level 1 (<em>Cretaceous</em> period) observations, we might need to worry
about a curving relationship. Note that a similar plot can also be made using
the formations version of the quantitative predictor variable and that the
research questions involve whether <em>DBF</em> or <em>DBC</em> are better predictor
variables.</p>

<div class="figure"><span id="fig:Figure9-10"></span>
<img src="09-caseStudies_files/figure-html/Figure9-10-1.png" alt="Scatterplot of log-biodiversity vs log-DBCs by TJK (TJK=1 for Cretaceous)." width="960" />
<p class="caption">
Figure 1.195: Scatterplot of log-biodiversity vs log-DBCs by TJK (TJK=1 for <em>Cretaceous</em>).
</p>
</div>
<p>The following results will allow us to explore models similar to theirs. One
“full” model they considered is:</p>
<p><span class="math display">\[\log{(\text{count})}_i=\beta_0 + \beta_1\cdot\log{(\text{DBC})}_i 
+ \beta_2I_{\text{TJK},i} + \varepsilon_i\]</span></p>
<p>which was compared to</p>
<p><span class="math display">\[\log{(\text{count})}_i=\beta_0 + \beta_1\cdot\log{(\text{DBF})}_i 
+ \beta_2I_{\text{TJK},i} + \varepsilon_i\]</span></p>
<p>as well as the simpler models that each suggests:</p>
<p><span class="math display">\[\begin{array}{rl}
\log{(\text{count})}_i &amp;=\beta_0 + \beta_1\cdot\log{(\text{DBC})}_i 
+ \varepsilon_i, \\
\log{(\text{count})}_i &amp;=\beta_0 + \beta_1\cdot\log{(\text{DBF})}_i
+ \varepsilon_i, \\
\log{(\text{count})}_i &amp;=\beta_0 + \beta_2I_{\text{TJK},i} 
+ \varepsilon_i, \text{ and} \\
\log{(\text{count})}_i &amp;=\beta_0 + \varepsilon_i.  \\
\end{array}\]</span></p>
<p>Both versions of the models (based on <em>DBF</em> or <em>DBC</em>) start with an MLR model
with a quantitative variable and two slopes. We can obtain some of the needed
model selection results from the first full model using:</p>
<div class="sourceCode" id="cb857"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb857-1" title="1">bd1 &lt;-<span class="st"> </span><span class="kw">lm</span>(logSpecies<span class="op">~</span>logDBCs<span class="op">+</span>TJK, <span class="dt">data=</span>bm)</a>
<a class="sourceLine" id="cb857-2" title="2"><span class="kw">require</span>(MuMIn)</a>
<a class="sourceLine" id="cb857-3" title="3"><span class="kw">options</span>(<span class="dt">na.action =</span> <span class="st">&quot;na.fail&quot;</span>)</a>
<a class="sourceLine" id="cb857-4" title="4"><span class="kw">dredge</span>(bd1, <span class="dt">rank=</span><span class="st">&quot;AIC&quot;</span>, </a>
<a class="sourceLine" id="cb857-5" title="5">       <span class="dt">extra=</span><span class="kw">c</span>(<span class="st">&quot;R^2&quot;</span>, <span class="dt">adjRsq=</span><span class="cf">function</span>(x) <span class="kw">summary</span>(x)<span class="op">$</span>adj.r.squared))</a></code></pre></div>
<pre><code>## Global model call: lm(formula = logSpecies ~ logDBCs + TJK, data = bm)
## ---
## Model selection table 
##   (Intrc)  lgDBC TJK      R^2   adjRsq df  logLik  AIC delta weight
## 4 -1.0890 0.7243   + 0.580900  0.54440  4 -12.652 33.3  0.00  0.987
## 2  0.1988 0.4283     0.369100  0.34280  3 -17.969 41.9  8.63  0.013
## 1  2.5690            0.000000  0.00000  2 -23.956 51.9 18.61  0.000
## 3  2.5300          + 0.004823 -0.03664  3 -23.893 53.8 20.48  0.000
## Models ranked by AIC(x)</code></pre>
<p>And from the second model:</p>
<div class="sourceCode" id="cb859"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb859-1" title="1">bd2 &lt;-<span class="st"> </span><span class="kw">lm</span>(logSpecies<span class="op">~</span>logDBFs<span class="op">+</span>TJK, <span class="dt">data=</span>bm)</a>
<a class="sourceLine" id="cb859-2" title="2"><span class="kw">dredge</span>(bd2, <span class="dt">rank=</span><span class="st">&quot;AIC&quot;</span>,</a>
<a class="sourceLine" id="cb859-3" title="3">       <span class="dt">extra=</span><span class="kw">c</span>(<span class="st">&quot;R^2&quot;</span>, <span class="dt">adjRsq=</span><span class="cf">function</span>(x) <span class="kw">summary</span>(x)<span class="op">$</span>adj.r.squared))</a></code></pre></div>
<pre><code>## Global model call: lm(formula = logSpecies ~ logDBFs + TJK, data = bm)
## ---
## Model selection table 
##   (Intrc)  lgDBF TJK      R^2   adjRsq df  logLik  AIC delta weight
## 4 -2.4100 1.3710   + 0.519900  0.47810  4 -14.418 36.8  0.00  0.995
## 2  0.5964 0.4882     0.209800  0.17690  3 -20.895 47.8 10.95  0.004
## 1  2.5690            0.000000  0.00000  2 -23.956 51.9 15.08  0.001
## 3  2.5300          + 0.004823 -0.03664  3 -23.893 53.8 16.95  0.000
## Models ranked by AIC(x)</code></pre>
<p>The top AIC model is
<span class="math inline">\(\log{(\text{count})}_i=\beta_0 + \beta_1\cdot\log{(\text{DBC})}_i + \beta_2I_{\text{TJK},i} + \varepsilon_i\)</span>
with an AIC of 33.3. The next best
model was <span class="math inline">\(\log{(\text{count})}_i=\beta_0 + \beta_1\cdot\log{(\text{DBF})}_i + \beta_2I_{\text{TJK},i} + \varepsilon_i\)</span>
with an AIC of 36.8, so 3.5 AIC units worse than the top model. We put these
two runs of results together in Table <a href="8-4-section9-4.html#tab:Table9-1">1.14</a>, re-computing all the
AICs based on the top model from the first full model considered.</p>

<table style="width:100%;">
<caption><span id="tab:Table9-1">Table 1.14: </span> Model comparison table.</caption>
<colgroup>
<col width="55%" />
<col width="5%" />
<col width="10%" />
<col width="4%" />
<col width="9%" />
<col width="5%" />
<col width="7%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"><strong>Model</strong>                </th>
<th align="right"><strong>R<sup>2</sup></strong></th>
<th align="right"><strong>adj R<sup>2</sup></strong> </th>
<th align="right"><strong>df</strong></th>
<th align="right"><strong>logLik</strong> </th>
<th align="right"><strong>AIC</strong></th>
<th align="right"><span class="math inline">\(\BD\)</span><strong>AIC</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(\log(\text{count})_i=\beta_0 + \beta_1\cdot\log(\text{DBC})_i + \beta_2I_{\text{TJK},i} + \varepsilon_i\)</span></td>
<td align="right">0.5809</td>
<td align="right">0.5444</td>
<td align="right">4</td>
<td align="right">-12.652</td>
<td align="right">33.3</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\log(\text{count})_i=\beta_0 + \beta_1\cdot\log(\text{DBF})_i + \beta_2I_{\text{TJK},i} + \varepsilon_i\)</span></td>
<td align="right">0.5199</td>
<td align="right">0.4781</td>
<td align="right">4</td>
<td align="right">-14.418</td>
<td align="right">36.8</td>
<td align="right">3.5</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\log(\text{count})_i=\beta_0 + \beta_1\cdot\log(\text{DBC})_i + \varepsilon_i\)</span></td>
<td align="right">0.3691</td>
<td align="right">0.3428</td>
<td align="right">3</td>
<td align="right">-17.969</td>
<td align="right">41.9</td>
<td align="right">8.6</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\log(\text{count})_i=\beta_0 + \beta_1\cdot\log(\text{DBF})_i + \varepsilon_i\)</span></td>
<td align="right">0.2098</td>
<td align="right">0.1769</td>
<td align="right">3</td>
<td align="right">-20.895</td>
<td align="right">47.8</td>
<td align="right">14.5</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\log(\text{count})_i=\beta_0 + \varepsilon_i\)</span></td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">-23.956</td>
<td align="right">51.9</td>
<td align="right">18.6</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\log(\text{count})_i=\beta_0 + \beta_2I_{\text{TJK},i} + \varepsilon_i\)</span></td>
<td align="right">0.0048</td>
<td align="right">-0.0366</td>
<td align="right">3</td>
<td align="right">-23.893</td>
<td align="right">53.8</td>
<td align="right">20.5</td>
</tr>
</tbody>
</table>
<p>Table <a href="8-4-section9-4.html#tab:Table9-1">1.14</a> suggests some interesting results. By itself, <span class="math inline">\(TJK\)</span> leads to the worst performing model on the AIC measure, ranking below a model with nothing in it
(mean-only) and 20.5 AIC units worse than the top model. But the two top models
distinctly benefit from the inclusion of <em>TJK</em>. This suggests that after
controlling for the sampling effort, either through <em>DBC</em> or <em>DBF</em>, the
differences in the stages captured by <em>TJK</em> can be more clearly observed.</p>
<p>So the top model in our (correct) results<a href="#fn147" class="footnote-ref" id="fnref147"><sup>147</sup></a> suggests that
<em>log(DBC)</em> is important as well as different intercepts for the two periods. We can interrogate
this model further but we should check the diagnostics (Figure
<a href="8-4-section9-4.html#fig:Figure9-11">1.196</a>) and consider our model
assumptions first as AICs are not valid if the model assumptions are not met.</p>

<div class="sourceCode" id="cb861"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb861-1" title="1"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="dt">oma=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">0</span>))</a>
<a class="sourceLine" id="cb861-2" title="2"><span class="kw">plot</span>(bd1)</a></code></pre></div>
<div class="figure"><span id="fig:Figure9-11"></span>
<img src="09-caseStudies_files/figure-html/Figure9-11-1.png" alt="Diagnostic plots for the top AIC model." width="960" />
<p class="caption">
Figure 1.196: Diagnostic plots for the top AIC model.
</p>
</div>
<p>The constant variance and assessment of influence do not suggest any real
problems with those assumptions. The normality assumption is possibly violated but shows lighter
tails than expected from a normal distribution and so should cause few
problems with inferences (we would be looking for an answer of “yes, there is a
violation of the normality assumption but, for a bonus point, that problem is
minor because the pattern is not the problematic type of violation
because…”). The other assumption that <strong>is violated for all our models</strong> is
that the observations are independent. Between neighboring stages in time,
there would likely be some sort of relationship in the biodiversity so
we should not assume that the observations are independent (this is a
<strong><em>time series</em></strong> of observations). The authors acknowledged this issue but
unskillfully attempted to deal with it. Because an interaction was not
considered in any of the models, there also is an assumption that the results
are parallel enough for the two groups. The scatterplot in Figure
<a href="8-4-section9-4.html#fig:Figure9-10">1.195</a> suggests that using parallel lines for the two
groups is probably reasonable but a full assessment really should also explore
that fully to verify that there is no support for an interaction.</p>
<p>Ignoring the violation of the independence assumption, we are otherwise OK to
explore the model more and see what it tells us about biodiversity of
<em>Sauropodomorphs</em>. The top model is estimated to be
<span class="math inline">\(\log{(\widehat{\text{count}})}_i=-1.089 + 0.724\cdot\log{(\text{DBC})}_i -0.75I_{\text{TJK},i}\)</span>.
This suggests that for the early observations (<em>TJK</em>=0), the model is
<span class="math inline">\(\log{(\widehat{\text{count}})}_i=-1.089 + 0.724\cdot\log{(\text{DBC})}_i\)</span>
and for the Cretaceous period (<em>TJK</em>=1), the model is
<span class="math inline">\(\log{(\widehat{\text{count}})}_i=-1.089 + -0.75+0.724\cdot\log{(\text{DBC})}_i\)</span>
which simplifies to <span class="math inline">\(\log{(\widehat{\text{count}})}_i=-1.84 + 0.724\cdot\log{(\text{DBC})}_i\)</span>. This suggests that the sampling efforts
have the same impacts on all observations and having an increase in <em>logDBCs</em>
is associated with increases in the mean <em>log-biodiversity</em>. Specifically, for
a 1 log-count increase in the <em>log-DBCs</em>, we expect, on average, to have a
0.724 log-count change in the mean log-biodiversity, after accounting for
different intercepts for the two periods considered. We could also translate
this to the original count scale but will leave it as is, because their real
question of interest involves the differences between the periods. The change
in the y-intercepts of -0.76 suggests that the Cretaceous has a lower average
log-biodiversity by 0.75 log-count, after controlling for the log-sampling
effort. This suggests that the <em>Cretaceous</em> had a lower corrected mean
log-Sauropodomorph biodiversity <span class="math inline">\(\require{enclose} (t_{23}=-3.41;\enclose{horizontalstrike}{\text{p-value}=0.0024})\)</span> than the combined
results for the Triassic and Jurassic. On the original count scale, this
suggests <span class="math inline">\(\exp(-0.76)=0.47\)</span> times (53% drop in) the median biodiversity count
per stage for Cretaceous versus the prior time period, after correcting for
log-sampling effort in each stage.</p>

<div class="sourceCode" id="cb862"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb862-1" title="1"><span class="kw">summary</span>(bd1)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = logSpecies ~ logDBCs + TJK, data = bm)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.6721 -0.3955  0.1149  0.2999  0.6158 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  -1.0887     0.6533  -1.666   0.1092
## logDBCs       0.7243     0.1288   5.622 1.01e-05
## TJK1         -0.7598     0.2229  -3.409   0.0024
## 
## Residual standard error: 0.4185 on 23 degrees of freedom
## Multiple R-squared:  0.5809, Adjusted R-squared:  0.5444 
## F-statistic: 15.94 on 2 and 23 DF,  p-value: 4.54e-05</code></pre>
<p>Their study shows some interesting contrasts between methods. They tried to use
AIC-based model selection methods across all the models but then used p-values
to really make their final conclusions. This presents a philosophical
inconsistency that bothers some more than others but should bother everyone.
One thought is whether they needed to use AICs at all since they wanted to use
p-values? The one reason they might have preferred to use AICs is that it allows
the direct comparison of</p>
<p><span class="math display">\[\log{(\text{count})}_i=\beta_0 + \beta_1\log{(\text{DBC})}_i + \beta_2I_{\text{TJK},i} + \varepsilon_i\]</span></p>
<p>to</p>
<p><span class="math display">\[\log{(\text{count})}_i=\beta_0 + \beta_1\cdot\log{(\text{DBF})}_i + \beta_2I_{\text{TJK},i} + \varepsilon_i,\]</span></p>
<p>exploring whether <em>DBC</em> or <em>DBF</em> is “better” with <em>TJK</em> in the model. There
is no hypothesis test to compare these two models because one is not <strong><em>nested</em></strong>
in the other – <strong>it is not possible to get from one model to the other by
setting one or more slope coefficients to 0 so we can’t test our way from one
model to the other one</strong>. The AICs suggest that the model with <em>DBC</em> and <em>TJK</em> is
better than the model with <em>DBF</em> and <em>TJK</em>, so that helps us make that decision.
After that step, we could rely on <span class="math inline">\(t\)</span>-tests or ANOVA <span class="math inline">\(F\)</span>-tests to decide whether
further refinement is suggested/possible for the model with <em>DBC</em> and <em>TJK</em>. This
would provide the direct inferences that they probably want and are trying to
obtain from AICs along with p-values in their paper.</p>
<p>Finally, their results would actually be more valid if they had used a set of
statistical methods designed for modeling responses that are counts of events
or things, especially those whose measurements change as a function of sampling
effort; models called <strong><em>Poisson rate models</em></strong> would be ideal for their
application. The other aspect of the biodiversity that they measured
for each stage was the duration of the stage. They never incorporated that
information and it makes sense given their interests in comparing biodiversity
across stages, not understanding why more or less biodiversity might occur. But
other researchers might want to estimate the biodiversity after also
controlling for the length of time that the stage lasted and the sampling
efforts involved in detecting the biodiversity of each stage, models that are
only a few steps away from those considered here. In general, this study
presents some of the pitfalls of attempting to use advanced statistical methods
as well as hinting at the benefits. The statistical models are the only way to
access the results of interest; inaccurate usage of statistical models can
provide inaccurate conclusions. They seemed to mostly get the right answers
despite a suite of errors in their work.</p>

</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Benson2012">
<p>Benson, Roger B. J., and Philip D. Mannion. 2012. “Multi-Variate Models Are Essential for Understanding Vertebrate Diversification in Deep Time.” <em>Biology Letters</em> 8: 127–30. <a href="https://doi.org/10.1098/rsbl.2011.0460">https://doi.org/10.1098/rsbl.2011.0460</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="144">
<li id="fn144"><p>This was not even close to their top AIC model so they made an odd
choice.<a href="8-4-section9-4.html#fnref144" class="footnote-back">↩</a></p></li>
<li id="fn145"><p>I had students read this
paper in a class and one decided that this was a reasonable way to report small
p-values – it is WRONG. We are interested in how small a p-value might be and
saying it is over a value is never useful, especially if you say it is larger than a tiny number.<a href="8-4-section9-4.html#fnref145" class="footnote-back">↩</a></p></li>
<li id="fn146"><p>All too often, I read journal articles that have under-utilized,
under-reported, mis-applied, or mis-interpreted statistical methods and
results. One of the reasons that I wanted to write this book was to help more
people move from basic statistical knowledge to correct use of intermediate
statistical methods and beginning to see the potential in more advanced
statistical methods. It has taken me many years of being a statistician just to
feel armed for battle when confronted with new applications and two stat
courses are not enough to get you there, but you have to start somewhere. You
are only maybe two or three hundred hours into your 10,000 hours required for mastery.
This book is intended get you some solid fundamentals to build on or a
few intermediate tools to use if this is your last statistics training
experience.<a href="8-4-section9-4.html#fnref146" class="footnote-back">↩</a></p></li>
<li id="fn147"><p>They also had an error in their AIC
results that is difficult to explain here but was due to an un-careful usage of
the results from the more advanced models that account for autocorrelation,
which seems to provide the proper ranking of models (<em>that they ignored</em>) but
did not provide the correct differences among models.<a href="8-4-section9-4.html#fnref147" class="footnote-back">↩</a></p></li>
</ol>
</div>
<p style="text-align: center;">
<a href="8-3-section9-3.html"><button class="btn btn-default">Previous</button></a>
<a href="8-5-section9-5.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
