<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="7.12 F-tests for MLR models with quantitative and categorical variables and interactions | Intermediate Statistics with R" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="gpeterson406/Greenwood_Book" />

<meta name="author" content="Mark C Greenwood" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="7.12 F-tests for MLR models with quantitative and categorical variables and interactions | Intermediate Statistics with R">

<title>7.12 F-tests for MLR models with quantitative and categorical variables and interactions | Intermediate Statistics with R</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#cover">Cover</a></li>
<li class="has-sub"><a href="acknowledgments.html#acknowledgments">Acknowledgments</a><ul>
<li><a href="0-1-section1-5.html#section1-5"><span class="toc-section-number">0.1</span> Summary of important R code</a></li>
</ul></li>
<li class="has-sub"><a href="1-chapter2.html#chapter2"><span class="toc-section-number">1</span> (R)e-Introduction to statistics</a><ul>
<li><a href="1-1-section2-1.html#section2-1"><span class="toc-section-number">1.1</span> Histograms, boxplots, and density curves</a></li>
<li><a href="1-2-section2-2.html#section2-2"><span class="toc-section-number">1.2</span> Pirate-plots</a></li>
<li><a href="1-3-section2-3.html#section2-3"><span class="toc-section-number">1.3</span> Models, hypotheses, and permutations for the two sample mean situation</a></li>
<li><a href="1-4-section2-4.html#section2-4"><span class="toc-section-number">1.4</span> Permutation testing for the two sample mean situation</a></li>
<li><a href="1-5-section2-5.html#section2-5"><span class="toc-section-number">1.5</span> Hypothesis testing (general)</a></li>
<li><a href="1-6-section2-6.html#section2-6"><span class="toc-section-number">1.6</span> Connecting randomization (nonparametric) and parametric tests</a></li>
<li><a href="1-7-section2-7.html#section2-7"><span class="toc-section-number">1.7</span> Second example of permutation tests</a></li>
<li><a href="1-8-section2-8.html#section2-8"><span class="toc-section-number">1.8</span> Reproducibility Crisis: Moving beyond p &lt; 0.05, publication bias, and multiple testing issues</a></li>
<li><a href="1-9-section2-9.html#section2-9"><span class="toc-section-number">1.9</span> Confidence intervals and bootstrapping</a></li>
<li><a href="1-10-section2-10.html#section2-10"><span class="toc-section-number">1.10</span> Bootstrap confidence intervals for difference in GPAs</a></li>
<li><a href="1-11-section2-11.html#section2-11"><span class="toc-section-number">1.11</span> Chapter summary</a></li>
<li><a href="1-12-section2-12.html#section2-12"><span class="toc-section-number">1.12</span> Summary of important R code</a></li>
<li><a href="1-13-section2-13.html#section2-13"><span class="toc-section-number">1.13</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="2-chapter3.html#chapter3"><span class="toc-section-number">2</span> One-Way ANOVA</a><ul>
<li><a href="2-1-section3-1.html#section3-1"><span class="toc-section-number">2.1</span> Situation</a></li>
<li><a href="2-2-section3-2.html#section3-2"><span class="toc-section-number">2.2</span> Linear model for One-Way ANOVA (cell-means and reference-coding)</a></li>
<li><a href="2-3-section3-3.html#section3-3"><span class="toc-section-number">2.3</span> One-Way ANOVA Sums of Squares, Mean Squares, and F-test</a></li>
<li><a href="2-4-section3-4.html#section3-4"><span class="toc-section-number">2.4</span> ANOVA model diagnostics including QQ-plots</a></li>
<li><a href="2-5-section3-5.html#section3-5"><span class="toc-section-number">2.5</span> Guinea pig tooth growth One-Way ANOVA example</a></li>
<li><a href="2-6-section3-6.html#section3-6"><span class="toc-section-number">2.6</span> Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display</a></li>
<li><a href="2-7-section3-7.html#section3-7"><span class="toc-section-number">2.7</span> Pair-wise comparisons for the Overtake data</a></li>
<li><a href="2-8-section3-8.html#section3-8"><span class="toc-section-number">2.8</span> Chapter summary</a></li>
<li><a href="2-9-section3-9.html#section3-9"><span class="toc-section-number">2.9</span> Summary of important R code</a></li>
<li><a href="2-10-section3-10.html#section3-10"><span class="toc-section-number">2.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="3-chapter4.html#chapter4"><span class="toc-section-number">3</span> Two-Way ANOVA</a><ul>
<li><a href="3-1-section4-1.html#section4-1"><span class="toc-section-number">3.1</span> Situation</a></li>
<li><a href="3-2-section4-2.html#section4-2"><span class="toc-section-number">3.2</span> Designing a two-way experiment and visualizing results</a></li>
<li><a href="3-3-section4-3.html#section4-3"><span class="toc-section-number">3.3</span> Two-Way ANOVA models and hypothesis tests</a></li>
<li><a href="3-4-section4-4.html#section4-4"><span class="toc-section-number">3.4</span> Guinea pig tooth growth analysis with Two-Way ANOVA</a></li>
<li><a href="3-5-section4-5.html#section4-5"><span class="toc-section-number">3.5</span> Observational study example: The Psychology of Debt</a></li>
<li><a href="3-6-section4-6.html#section4-6"><span class="toc-section-number">3.6</span> Pushing Two-Way ANOVA to the limit: Un-replicated designs and Estimability</a></li>
<li><a href="3-7-section4-7.html#section4-7"><span class="toc-section-number">3.7</span> Chapter summary</a></li>
<li><a href="3-8-section4-8.html#section4-8"><span class="toc-section-number">3.8</span> Summary of important R code</a></li>
<li><a href="3-9-section4-9.html#section4-9"><span class="toc-section-number">3.9</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="4-chapter5.html#chapter5"><span class="toc-section-number">4</span> Chi-square tests</a><ul>
<li><a href="4-1-section5-1.html#section5-1"><span class="toc-section-number">4.1</span> Situation, contingency tables, and tableplots</a></li>
<li><a href="4-2-section5-2.html#section5-2"><span class="toc-section-number">4.2</span> Homogeneity test hypotheses</a></li>
<li><a href="4-3-section5-3.html#section5-3"><span class="toc-section-number">4.3</span> Independence test hypotheses</a></li>
<li><a href="4-4-section5-4.html#section5-4"><span class="toc-section-number">4.4</span> Models for R by C tables</a></li>
<li><a href="4-5-section5-5.html#section5-5"><span class="toc-section-number">4.5</span> Permutation tests for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="4-6-section5-6.html#section5-6"><span class="toc-section-number">4.6</span> Chi-square distribution for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="4-7-section5-7.html#section5-7"><span class="toc-section-number">4.7</span> Examining residuals for the source of differences</a></li>
<li><a href="4-8-section5-8.html#section5-8"><span class="toc-section-number">4.8</span> General protocol for <span class="math inline">\(X^2\)</span> tests</a></li>
<li><a href="4-9-section5-9.html#section5-9"><span class="toc-section-number">4.9</span> Political party and voting results: Complete analysis</a></li>
<li><a href="4-10-section5-10.html#section5-10"><span class="toc-section-number">4.10</span> Is cheating and lying related in students?</a></li>
<li><a href="4-11-section5-11.html#section5-11"><span class="toc-section-number">4.11</span> Analyzing a stratified random sample of California schools</a></li>
<li><a href="4-12-section5-12.html#section5-12"><span class="toc-section-number">4.12</span> Chapter summary</a></li>
<li><a href="4-13-section5-13.html#section5-13"><span class="toc-section-number">4.13</span> Summary of important R commands</a></li>
<li><a href="4-14-section5-14.html#section5-14"><span class="toc-section-number">4.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="5-chapter6.html#chapter6"><span class="toc-section-number">5</span> Correlation and Simple Linear Regression</a><ul>
<li><a href="5-1-section6-1.html#section6-1"><span class="toc-section-number">5.1</span> Relationships between two quantitative variables</a></li>
<li><a href="5-2-section6-2.html#section6-2"><span class="toc-section-number">5.2</span> Estimating the correlation coefficient</a></li>
<li><a href="5-3-section6-3.html#section6-3"><span class="toc-section-number">5.3</span> Relationships between variables by groups</a></li>
<li><a href="5-4-section6-4.html#section6-4"><span class="toc-section-number">5.4</span> Inference for the correlation coefficient</a></li>
<li><a href="5-5-section6-5.html#section6-5"><span class="toc-section-number">5.5</span> Are tree diameters related to tree heights?</a></li>
<li><a href="5-6-section6-6.html#section6-6"><span class="toc-section-number">5.6</span> Describing relationships with a regression model</a></li>
<li><a href="5-7-section6-7.html#section6-7"><span class="toc-section-number">5.7</span> Least Squares Estimation</a></li>
<li><a href="5-8-section6-8.html#section6-8"><span class="toc-section-number">5.8</span> Measuring the strength of regressions: R<sup>2</sup></a></li>
<li><a href="5-9-section6-9.html#section6-9"><span class="toc-section-number">5.9</span> Outliers: leverage and influence</a></li>
<li><a href="5-10-section6-10.html#section6-10"><span class="toc-section-number">5.10</span> Residual diagnostics – setting the stage for inference</a></li>
<li><a href="5-11-section6-11.html#section6-11"><span class="toc-section-number">5.11</span> Old Faithful discharge and waiting times</a></li>
<li><a href="5-12-section6-12.html#section6-12"><span class="toc-section-number">5.12</span> Chapter summary</a></li>
<li><a href="5-13-section6-13.html#section6-13"><span class="toc-section-number">5.13</span> Summary of important R code</a></li>
<li><a href="5-14-section6-14.html#section6-14"><span class="toc-section-number">5.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="6-chapter7.html#chapter7"><span class="toc-section-number">6</span> Simple linear regression inference</a><ul>
<li><a href="6-1-section7-1.html#section7-1"><span class="toc-section-number">6.1</span> Model</a></li>
<li><a href="6-2-section7-2.html#section7-2"><span class="toc-section-number">6.2</span> Confidence interval and hypothesis tests for the slope and intercept</a></li>
<li><a href="6-3-section7-3.html#section7-3"><span class="toc-section-number">6.3</span> Bozeman temperature trend</a></li>
<li><a href="6-4-section7-4.html#section7-4"><span class="toc-section-number">6.4</span> Randomization-based inferences for the slope coefficient</a></li>
<li><a href="6-5-section7-5.html#section7-5"><span class="toc-section-number">6.5</span> Transformations part I: Linearizing relationships</a></li>
<li><a href="6-6-section7-6.html#section7-6"><span class="toc-section-number">6.6</span> Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x)</a></li>
<li><a href="6-7-section7-7.html#section7-7"><span class="toc-section-number">6.7</span> Confidence interval for the mean and prediction intervals for a new observation</a></li>
<li><a href="6-8-section7-8.html#section7-8"><span class="toc-section-number">6.8</span> Chapter summary</a></li>
<li><a href="6-9-section7-9.html#section7-9"><span class="toc-section-number">6.9</span> Summary of important R code</a></li>
<li><a href="6-10-section7-10.html#section7-10"><span class="toc-section-number">6.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="7-chapter8.html#chapter8"><span class="toc-section-number">7</span> Multiple linear regression</a><ul>
<li><a href="7-1-section8-1.html#section8-1"><span class="toc-section-number">7.1</span> Going from SLR to MLR</a></li>
<li><a href="7-2-section8-2.html#section8-2"><span class="toc-section-number">7.2</span> Validity conditions in MLR</a></li>
<li><a href="7-3-section8-3.html#section8-3"><span class="toc-section-number">7.3</span> Interpretation of MLR terms</a></li>
<li><a href="7-4-section8-4.html#section8-4"><span class="toc-section-number">7.4</span> Comparing multiple regression models</a></li>
<li><a href="7-5-section8-5.html#section8-5"><span class="toc-section-number">7.5</span> General recommendations for MLR interpretations and VIFs</a></li>
<li><a href="7-6-section8-6.html#section8-6"><span class="toc-section-number">7.6</span> MLR inference: Parameter inferences using the t-distribution</a></li>
<li><a href="7-7-section8-7.html#section8-7"><span class="toc-section-number">7.7</span> Overall F-test in multiple linear regression</a></li>
<li><a href="7-8-section8-8.html#section8-8"><span class="toc-section-number">7.8</span> Case study: First year college GPA and SATs</a></li>
<li><a href="7-9-section8-9.html#section8-9"><span class="toc-section-number">7.9</span> Different intercepts for different groups: MLR with indicator variables</a></li>
<li><a href="7-10-section8-10.html#section8-10"><span class="toc-section-number">7.10</span> Additive MLR with more than two groups: Headache example</a></li>
<li><a href="7-11-section8-11.html#section8-11"><span class="toc-section-number">7.11</span> Different slopes and different intercepts</a></li>
<li><a href="7-12-section8-12.html#section8-12"><span class="toc-section-number">7.12</span> F-tests for MLR models with quantitative and categorical variables and interactions</a></li>
<li><a href="7-13-section8-13.html#section8-13"><span class="toc-section-number">7.13</span> AICs for model selection</a></li>
<li><a href="7-14-section8-14.html#section8-14"><span class="toc-section-number">7.14</span> Case study: Forced expiratory volume model selection using AICs</a></li>
<li><a href="7-15-section8-15.html#section8-15"><span class="toc-section-number">7.15</span> Chapter summary</a></li>
<li><a href="7-16-section8-16.html#section8-16"><span class="toc-section-number">7.16</span> Summary of important R code</a></li>
<li><a href="7-17-section8-17.html#section8-17"><span class="toc-section-number">7.17</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="8-chapter9.html#chapter9"><span class="toc-section-number">8</span> Case studies</a><ul>
<li><a href="8-1-section9-1.html#section9-1"><span class="toc-section-number">8.1</span> Overview of material covered</a></li>
<li><a href="8-2-section9-2.html#section9-2"><span class="toc-section-number">8.2</span> The impact of simulated chronic nitrogen deposition on the biomass and N2-fixation activity of two boreal feather moss–cyanobacteria associations</a></li>
<li><a href="8-3-section9-3.html#section9-3"><span class="toc-section-number">8.3</span> Ants learn to rely on more informative attributes during decision-making</a></li>
<li><a href="8-4-section9-4.html#section9-4"><span class="toc-section-number">8.4</span> Multi-variate models are essential for understanding vertebrate diversification in deep time</a></li>
<li><a href="8-5-section9-5.html#section9-5"><span class="toc-section-number">8.5</span> What do didgeridoos really do about sleepiness?</a></li>
<li><a href="8-6-section9-6.html#section9-6"><span class="toc-section-number">8.6</span> General summary</a></li>
</ul></li>
<li><a href="references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="section8-12" class="section level2">
<h2><span class="header-section-number">7.12</span> F-tests for MLR models with quantitative and categorical variables and interactions</h2>

<p>For models with multi-category <span class="math inline">\((J&gt;2)\)</span> categorical variables we need a method
for deciding if all the extra
complexity present in the additive or interaction models is necessary. We can
appeal to model selection methods such as the adjusted <strong><em>R</em></strong><sup>2</sup> that
focus on balancing model fit and complexity but interests often move to trying to
decide if the differences are more extreme
than we would expect by chance if there were no group differences in intercepts
or slopes. Because of the multi-degree of freedom aspects of the use of indicator
variables (<span class="math inline">\(J-1\)</span> variables for a <span class="math inline">\(J\)</span> level categorical variable), we have to
develop tests that combine and assess information across multiple
“variables” – even though these indicators all pertain to a single original
categorical variable.  ANOVA <span class="math inline">\(F\)</span>-tests did exactly
this sort of thing in the One and Two-Way ANOVA models and can do that for us
here. There are two models that we perform tests in – the additive and the
interaction models.


We start with a discussion of the tests in an interaction
setting since that provides us the <strong>first test to consider</strong> in most situations
to assess evidence of whether the extra complexity of varying slopes is really
needed. If we don’t “need” the varying
slopes or if the plot really does have lines for the groups that look
relatively parallel, we can fit the additive model and either assess evidence of
the need for different intercepts or for the quantitative predictor – either is
a reasonable next step.

Basically this establishes a set of <strong><em>nested models</em></strong>
(each model is a reduced version of another more complicated
model higher in the tree of models) displayed in Figure <a href="7-12-section8-12.html#fig:Figure8-33">1.182</a>.
This is based on
the assumption that we would proceed through the model, dropping terms if the
p-values are large (“not significant” in the diagram) to arrive at a final
model. </p>

<div class="figure"><span id="fig:Figure8-33"></span>
<img src="chapter8_files/nestedModelTree_medium.png" alt="Diagram of models to consider in an interaction model." width="338" />
<p class="caption">
Figure 1.182: Diagram of models to consider in an interaction model.
</p>
</div>
<p>If the initial interaction test suggests the interaction is important, then no
further refinement should be considered and that model should be explored (this
was the same protocol suggested in the 2-WAY ANOVA situation, the other place
where we considered interactions).

If the interaction is not deemed important
based on the test, then the model should be re-fit using both variables in an
additive model.

In that additive model, both variables can be assessed
conditional on the other one. If both have small p-values, then that is the
final model and should be explored further. If either the categorical or
quantitative variable have large p-values, then they can be dropped from the
model and the model re-fit with only one variable in it, usually starting with
dropping the component with the largest p-value if both are not “small”. Note
that if there is only a categorical variable remaining, then we would call that
linear model a One-Way ANOVA (quantitative response and <span class="math inline">\(J\)</span> group categorical
explanatory) and if the only remaining variable is quantitative, then a SLR model
is being fit. If that final variable has a
large p-value in either model, it can be removed and all that is left to
describe the responses is a mean-only model. Otherwise the single variable
model is the final model. Usually we will not have to delve deeply into this
tree of models, but it is good to consider the potential paths that an analysis
could involve before it is started.</p>
<p>To perform the first test (after checking that assumptions are met, of
course),
we can apply the <code>Anova</code> function from the <code>car</code> package to an interaction
model<a href="#fn133" class="footnote-ref" id="fnref133"><sup>133</sup></a>.

It will provide three tests, one for each variable by themselves, which are not
too interesting, and then the interaction test. This will result in an
<span class="math inline">\(F\)</span>-statistic that, if the assumptions are met, will follow an
<span class="math inline">\(F(J-1, n-2J)\)</span>-distribution
under the null hypothesis. This tests
the hypotheses:</p>
<ul>
<li><p><span class="math inline">\(\boldsymbol{H_0:}\)</span> <strong>The slope for <span class="math inline">\(\boldsymbol{x}\)</span> is the same for all
<span class="math inline">\(\boldsymbol{J}\)</span> groups in the population vs</strong></p></li>
<li><p><span class="math inline">\(\boldsymbol{H_A:}\)</span> <strong>The slope for <span class="math inline">\(\boldsymbol{x}\)</span> in at least one group
differs from the others in the population.</strong></p></li>
</ul>
<p>This test is also legitimate in the case of a two-level categorical variable
<span class="math inline">\((J=2)\)</span> and then follows an <span class="math inline">\(F(1, n-4)\)</span>-distribution under the null
hypothesis. With <span class="math inline">\(J=2\)</span>, the p-value from this test matches the results for the
<span class="math inline">\(t\)</span>-test <span class="math inline">\((t_{n-4})\)</span> for the single slope-changing coefficient in the model
summary output. The noise tolerance study, introduced in Section
<a href="7-10-section8-10.html#section8-10">7.10</a>, provides a situation for exploring the results in
detail.</p>
<p>With the <span class="math inline">\(J=4\)</span> level categorical variable (<em>Treatment</em>), the model for the
second noise tolerance measurement (<em>du2</em>) as a function of the interaction
between <em>Treatment</em> and initial noise tolerance (<em>du1</em>) is</p>
<p><span class="math display">\[\begin{array}{rl}
\text{du2}_i = \beta_0 &amp;+ \beta_1\cdot\text{du1}_i + \beta_2I_{T2,i} +
\beta_3I_{T3,i} + \beta_4I_{\text{Control},i} \\
&amp;+ \beta_5I_{T2,i}\cdot\text{du1}_i + \beta_6I_{T3,i}\cdot\text{du1}_i
+ \beta_7I_{\text{Control},i}\cdot\text{du1}_i+\varepsilon_i.
\end{array}\]</span></p>
<p>We can re-write the previous hypotheses in one of two more specific ways:</p>
<ul>
<li><p><span class="math inline">\(H_0:\)</span> The slope for <em>du1</em> is the same for all four <em>Treatment</em> groups in the
population OR</p></li>
<li><p><span class="math inline">\(H_0: \beta_5=\beta_6=\beta_7=0\)</span></p>
<ul>
<li>This defines a null hypothesis that all the deviation coefficients for
getting different slopes for the different treatments are 0 in the
population.</li>
</ul></li>
<li><p><span class="math inline">\(H_A:\)</span> The slope for <em>du1</em> is NOT the same for all four <em>Treatment</em> groups in
the population (at least one group has a different slope) OR</p></li>
<li><p><span class="math inline">\(H_A:\)</span> At least one of <span class="math inline">\(\beta_5,\beta_6,\beta_7\)</span> is different from 0 in the
population.</p>
<ul>
<li>The alternative states that at least one of the deviation coefficients
for getting different slopes for the different <em>Treatments</em> is not 0 in the
population.</li>
</ul></li>
</ul>
<p>In this situation, the results for the test of these hypotheses is in the row
labeled <code>du1:treatment</code> in the <code>Anova</code> output. The ANOVA table below shows
a test statistic of <span class="math inline">\(F=0.768\)</span> with the <em>numerator df</em> of 3, coming from <span class="math inline">\(J-1\)</span>,
and the <em>denominator df</em> of 90, coming from <span class="math inline">\(n-2J=98-2*4=90\)</span> and also provided
in the <code>Residuals</code> row in the table, leading to an <span class="math inline">\(F(3, 90)\)</span>-distribution
for the test statistic under the null hypothesis.

The p-value from this
distribution is 0.515, showing little to no evidence against
the null hypothesis. The conclusion is that there is insufficient evidence to
claim that the slope coefficient for <em>du1</em> in explaining <em>du2</em> is different for
at least one of the <em>Treatment</em> groups in the population.</p>
<div class="sourceCode" id="cb801"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb801-1" title="1"><span class="kw">Anova</span>(head2)</a></code></pre></div>
<pre><code>## Anova Table (Type II tests)
## 
## Response: du2
##                Sum Sq Df  F value Pr(&gt;F)
## du1           1197.78  1 259.5908 &lt;2e-16
## treatment       23.90  3   1.7265 0.1672
## du1:treatment   10.63  3   0.7679 0.5150
## Residuals      415.27 90</code></pre>
<p>Without evidence to support an interaction, we should consider both the
quantitative and categorical variables in an additive model. The ANOVA table
for the additive model contains two interesting tests.


One test is for the
quantitative variable discussed previously. The other is for the categorical
variable, assessing whether different y-intercepts are needed. The additive
model here is</p>
<p><span class="math display">\[\text{du2}_i = \beta_0 + \beta_1\cdot\text{du1}_i + \beta_2I_{T2,i} +
\beta_3I_{T3,i} + \beta_4I_{\text{Control},i} +\varepsilon_i.\ \]</span></p>
<p>The hypotheses assessed in the ANOVA test for treatment are:</p>
<ul>
<li><p><span class="math inline">\(H_0:\)</span> The y-intercept for the model with <em>du1</em> is the same for all four
<em>Treatment</em> groups in the population OR</p></li>
<li><p><span class="math inline">\(H_0: \beta_2=\beta_3=\beta_4=0\)</span></p>
<ul>
<li>This defines a null hypothesis that all the deviation coefficients for
getting different y-intercepts for the different <em>Treatments</em> are 0 in
the population.</li>
</ul></li>
<li><p><span class="math inline">\(H_A:\)</span> The y-intercepts for the model with <em>du1</em> is NOT the same for all four
<em>Treatment</em> groups in the population (at least one group has a different
y-intercept) OR</p></li>
<li><p><span class="math inline">\(H_A:\)</span> At least one of <span class="math inline">\(\beta_2,\beta_3,\beta_4\)</span> is different from 0 in the
population.</p>
<ul>
<li>The alternative states that at least one of the deviation coefficients
for getting different y-intercepts for the different <em>Treatments</em> is not 0
in the population.</li>
</ul></li>
</ul>
<p>The <span class="math inline">\(F\)</span>-test for the categorical variable in an additive model follows
<span class="math inline">\(F(J-1, n-J-1)\)</span>-distribution under the null hypothesis.


For this example, the
test statistic for <em>Treatment</em> follows an <span class="math inline">\(F(3, 93)\)</span>-distribution under the null
hypothesis. The observed test statistic has a value of 1.74, generating a p-value
of 0.164. So we would fail to reject the null hypothesis and conclude that there
is little to no evidence to support the conclusion of some difference in y-intercepts
between the <em>treatment</em> groups, in a model with <em>du1</em>, in the population. We
could interpret this in the fashion we used initially in MLR by stating this
result as: there is little to no evidence of a difference in the mean <em>du2</em> for the
<em>Treatment</em> groups after controlling for <em>du1</em>.</p>
<div class="sourceCode" id="cb803"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb803-1" title="1">head1 &lt;-<span class="st"> </span><span class="kw">lm</span>(du2<span class="op">~</span>du1<span class="op">+</span>treatment, <span class="dt">data=</span>Headache)</a>
<a class="sourceLine" id="cb803-2" title="2"><span class="kw">Anova</span>(head1)</a></code></pre></div>
<pre><code>## Anova Table (Type II tests)
## 
## Response: du2
##           Sum Sq Df  F value Pr(&gt;F)
## du1       1197.8  1 261.5491 &lt;2e-16
## treatment   23.9  3   1.7395 0.1643
## Residuals  425.9 93</code></pre>
<p>In the same ANOVA table, there is a test for the <em>du1</em> effect. This tests
<span class="math inline">\(H_0: \beta_1=0\)</span> vs <span class="math inline">\(H_A: \beta_1\ne 0\)</span> in a model with different y-intercepts
estimated for the different groups. If we remove this term from the model, all
we are left with is different
y-intercepts for the groups. A model just with different y-intercepts is typically
called a One-Way ANOVA model. Here, there is evidence that the quantitative
variable is needed in the model after controlling for the different
y-intercepts for different treatments. Note that this interpretation retains
the conditional wording regardless of whether the other variable had a small
p-value or it did not. If you want an unconditional interpretation for a variable, then you
will need to refit the model without the other variable(s) after deciding that
they are not important.</p>
</div>
<div class="footnotes">
<hr />
<ol start="133">
<li id="fn133"><p>We could also use the <code>anova</code> function to do this but using <code>Anova</code>
throughout this material provides the answers we want in the additive model and
it has no impact for the only test of interest in the interaction model since
the interaction is the last component in the model.<a href="7-12-section8-12.html#fnref133" class="footnote-back">↩</a></p></li>
</ol>
</div>
<p style="text-align: center;">
<a href="7-11-section8-11.html"><button class="btn btn-default">Previous</button></a>
<a href="7-13-section8-13.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
