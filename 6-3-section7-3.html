<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="6.3 Bozeman temperature trend | Intermediate Statistics with R" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="gpeterson406/Greenwood_Book" />

<meta name="author" content="Mark C Greenwood" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="6.3 Bozeman temperature trend | Intermediate Statistics with R">

<title>6.3 Bozeman temperature trend | Intermediate Statistics with R</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#cover">Cover</a></li>
<li class="has-sub"><a href="acknowledgments.html#acknowledgments">Acknowledgments</a><ul>
<li><a href="0-1-section1-5.html#section1-5"><span class="toc-section-number">0.1</span> Summary of important R code</a></li>
</ul></li>
<li class="has-sub"><a href="1-chapter2.html#chapter2"><span class="toc-section-number">1</span> (R)e-Introduction to statistics</a><ul>
<li><a href="1-1-section2-1.html#section2-1"><span class="toc-section-number">1.1</span> Histograms, boxplots, and density curves</a></li>
<li><a href="1-2-section2-2.html#section2-2"><span class="toc-section-number">1.2</span> Pirate-plots</a></li>
<li><a href="1-3-section2-3.html#section2-3"><span class="toc-section-number">1.3</span> Models, hypotheses, and permutations for the two sample mean situation</a></li>
<li><a href="1-4-section2-4.html#section2-4"><span class="toc-section-number">1.4</span> Permutation testing for the two sample mean situation</a></li>
<li><a href="1-5-section2-5.html#section2-5"><span class="toc-section-number">1.5</span> Hypothesis testing (general)</a></li>
<li><a href="1-6-section2-6.html#section2-6"><span class="toc-section-number">1.6</span> Connecting randomization (nonparametric) and parametric tests</a></li>
<li><a href="1-7-section2-7.html#section2-7"><span class="toc-section-number">1.7</span> Second example of permutation tests</a></li>
<li><a href="1-8-section2-8.html#section2-8"><span class="toc-section-number">1.8</span> Reproducibility Crisis: Moving beyond p &lt; 0.05, publication bias, and multiple testing issues</a></li>
<li><a href="1-9-section2-9.html#section2-9"><span class="toc-section-number">1.9</span> Confidence intervals and bootstrapping</a></li>
<li><a href="1-10-section2-10.html#section2-10"><span class="toc-section-number">1.10</span> Bootstrap confidence intervals for difference in GPAs</a></li>
<li><a href="1-11-section2-11.html#section2-11"><span class="toc-section-number">1.11</span> Chapter summary</a></li>
<li><a href="1-12-section2-12.html#section2-12"><span class="toc-section-number">1.12</span> Summary of important R code</a></li>
<li><a href="1-13-section2-13.html#section2-13"><span class="toc-section-number">1.13</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="2-chapter3.html#chapter3"><span class="toc-section-number">2</span> One-Way ANOVA</a><ul>
<li><a href="2-1-section3-1.html#section3-1"><span class="toc-section-number">2.1</span> Situation</a></li>
<li><a href="2-2-section3-2.html#section3-2"><span class="toc-section-number">2.2</span> Linear model for One-Way ANOVA (cell-means and reference-coding)</a></li>
<li><a href="2-3-section3-3.html#section3-3"><span class="toc-section-number">2.3</span> One-Way ANOVA Sums of Squares, Mean Squares, and F-test</a></li>
<li><a href="2-4-section3-4.html#section3-4"><span class="toc-section-number">2.4</span> ANOVA model diagnostics including QQ-plots</a></li>
<li><a href="2-5-section3-5.html#section3-5"><span class="toc-section-number">2.5</span> Guinea pig tooth growth One-Way ANOVA example</a></li>
<li><a href="2-6-section3-6.html#section3-6"><span class="toc-section-number">2.6</span> Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display</a></li>
<li><a href="2-7-section3-7.html#section3-7"><span class="toc-section-number">2.7</span> Pair-wise comparisons for the Overtake data</a></li>
<li><a href="2-8-section3-8.html#section3-8"><span class="toc-section-number">2.8</span> Chapter summary</a></li>
<li><a href="2-9-section3-9.html#section3-9"><span class="toc-section-number">2.9</span> Summary of important R code</a></li>
<li><a href="2-10-section3-10.html#section3-10"><span class="toc-section-number">2.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="3-chapter4.html#chapter4"><span class="toc-section-number">3</span> Two-Way ANOVA</a><ul>
<li><a href="3-1-section4-1.html#section4-1"><span class="toc-section-number">3.1</span> Situation</a></li>
<li><a href="3-2-section4-2.html#section4-2"><span class="toc-section-number">3.2</span> Designing a two-way experiment and visualizing results</a></li>
<li><a href="3-3-section4-3.html#section4-3"><span class="toc-section-number">3.3</span> Two-Way ANOVA models and hypothesis tests</a></li>
<li><a href="3-4-section4-4.html#section4-4"><span class="toc-section-number">3.4</span> Guinea pig tooth growth analysis with Two-Way ANOVA</a></li>
<li><a href="3-5-section4-5.html#section4-5"><span class="toc-section-number">3.5</span> Observational study example: The Psychology of Debt</a></li>
<li><a href="3-6-section4-6.html#section4-6"><span class="toc-section-number">3.6</span> Pushing Two-Way ANOVA to the limit: Un-replicated designs and Estimability</a></li>
<li><a href="3-7-section4-7.html#section4-7"><span class="toc-section-number">3.7</span> Chapter summary</a></li>
<li><a href="3-8-section4-8.html#section4-8"><span class="toc-section-number">3.8</span> Summary of important R code</a></li>
<li><a href="3-9-section4-9.html#section4-9"><span class="toc-section-number">3.9</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="4-chapter5.html#chapter5"><span class="toc-section-number">4</span> Chi-square tests</a><ul>
<li><a href="4-1-section5-1.html#section5-1"><span class="toc-section-number">4.1</span> Situation, contingency tables, and tableplots</a></li>
<li><a href="4-2-section5-2.html#section5-2"><span class="toc-section-number">4.2</span> Homogeneity test hypotheses</a></li>
<li><a href="4-3-section5-3.html#section5-3"><span class="toc-section-number">4.3</span> Independence test hypotheses</a></li>
<li><a href="4-4-section5-4.html#section5-4"><span class="toc-section-number">4.4</span> Models for R by C tables</a></li>
<li><a href="4-5-section5-5.html#section5-5"><span class="toc-section-number">4.5</span> Permutation tests for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="4-6-section5-6.html#section5-6"><span class="toc-section-number">4.6</span> Chi-square distribution for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="4-7-section5-7.html#section5-7"><span class="toc-section-number">4.7</span> Examining residuals for the source of differences</a></li>
<li><a href="4-8-section5-8.html#section5-8"><span class="toc-section-number">4.8</span> General protocol for <span class="math inline">\(X^2\)</span> tests</a></li>
<li><a href="4-9-section5-9.html#section5-9"><span class="toc-section-number">4.9</span> Political party and voting results: Complete analysis</a></li>
<li><a href="4-10-section5-10.html#section5-10"><span class="toc-section-number">4.10</span> Is cheating and lying related in students?</a></li>
<li><a href="4-11-section5-11.html#section5-11"><span class="toc-section-number">4.11</span> Analyzing a stratified random sample of California schools</a></li>
<li><a href="4-12-section5-12.html#section5-12"><span class="toc-section-number">4.12</span> Chapter summary</a></li>
<li><a href="4-13-section5-13.html#section5-13"><span class="toc-section-number">4.13</span> Summary of important R commands</a></li>
<li><a href="4-14-section5-14.html#section5-14"><span class="toc-section-number">4.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="5-chapter6.html#chapter6"><span class="toc-section-number">5</span> Correlation and Simple Linear Regression</a><ul>
<li><a href="5-1-section6-1.html#section6-1"><span class="toc-section-number">5.1</span> Relationships between two quantitative variables</a></li>
<li><a href="5-2-section6-2.html#section6-2"><span class="toc-section-number">5.2</span> Estimating the correlation coefficient</a></li>
<li><a href="5-3-section6-3.html#section6-3"><span class="toc-section-number">5.3</span> Relationships between variables by groups</a></li>
<li><a href="5-4-section6-4.html#section6-4"><span class="toc-section-number">5.4</span> Inference for the correlation coefficient</a></li>
<li><a href="5-5-section6-5.html#section6-5"><span class="toc-section-number">5.5</span> Are tree diameters related to tree heights?</a></li>
<li><a href="5-6-section6-6.html#section6-6"><span class="toc-section-number">5.6</span> Describing relationships with a regression model</a></li>
<li><a href="5-7-section6-7.html#section6-7"><span class="toc-section-number">5.7</span> Least Squares Estimation</a></li>
<li><a href="5-8-section6-8.html#section6-8"><span class="toc-section-number">5.8</span> Measuring the strength of regressions: R<sup>2</sup></a></li>
<li><a href="5-9-section6-9.html#section6-9"><span class="toc-section-number">5.9</span> Outliers: leverage and influence</a></li>
<li><a href="5-10-section6-10.html#section6-10"><span class="toc-section-number">5.10</span> Residual diagnostics – setting the stage for inference</a></li>
<li><a href="5-11-section6-11.html#section6-11"><span class="toc-section-number">5.11</span> Old Faithful discharge and waiting times</a></li>
<li><a href="5-12-section6-12.html#section6-12"><span class="toc-section-number">5.12</span> Chapter summary</a></li>
<li><a href="5-13-section6-13.html#section6-13"><span class="toc-section-number">5.13</span> Summary of important R code</a></li>
<li><a href="5-14-section6-14.html#section6-14"><span class="toc-section-number">5.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="6-chapter7.html#chapter7"><span class="toc-section-number">6</span> Simple linear regression inference</a><ul>
<li><a href="6-1-section7-1.html#section7-1"><span class="toc-section-number">6.1</span> Model</a></li>
<li><a href="6-2-section7-2.html#section7-2"><span class="toc-section-number">6.2</span> Confidence interval and hypothesis tests for the slope and intercept</a></li>
<li><a href="6-3-section7-3.html#section7-3"><span class="toc-section-number">6.3</span> Bozeman temperature trend</a></li>
<li><a href="6-4-section7-4.html#section7-4"><span class="toc-section-number">6.4</span> Randomization-based inferences for the slope coefficient</a></li>
<li><a href="6-5-section7-5.html#section7-5"><span class="toc-section-number">6.5</span> Transformations part I: Linearizing relationships</a></li>
<li><a href="6-6-section7-6.html#section7-6"><span class="toc-section-number">6.6</span> Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x)</a></li>
<li><a href="6-7-section7-7.html#section7-7"><span class="toc-section-number">6.7</span> Confidence interval for the mean and prediction intervals for a new observation</a></li>
<li><a href="6-8-section7-8.html#section7-8"><span class="toc-section-number">6.8</span> Chapter summary</a></li>
<li><a href="6-9-section7-9.html#section7-9"><span class="toc-section-number">6.9</span> Summary of important R code</a></li>
<li><a href="6-10-section7-10.html#section7-10"><span class="toc-section-number">6.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="7-chapter8.html#chapter8"><span class="toc-section-number">7</span> Multiple linear regression</a><ul>
<li><a href="7-1-section8-1.html#section8-1"><span class="toc-section-number">7.1</span> Going from SLR to MLR</a></li>
<li><a href="7-2-section8-2.html#section8-2"><span class="toc-section-number">7.2</span> Validity conditions in MLR</a></li>
<li><a href="7-3-section8-3.html#section8-3"><span class="toc-section-number">7.3</span> Interpretation of MLR terms</a></li>
<li><a href="7-4-section8-4.html#section8-4"><span class="toc-section-number">7.4</span> Comparing multiple regression models</a></li>
<li><a href="7-5-section8-5.html#section8-5"><span class="toc-section-number">7.5</span> General recommendations for MLR interpretations and VIFs</a></li>
<li><a href="7-6-section8-6.html#section8-6"><span class="toc-section-number">7.6</span> MLR inference: Parameter inferences using the t-distribution</a></li>
<li><a href="7-7-section8-7.html#section8-7"><span class="toc-section-number">7.7</span> Overall F-test in multiple linear regression</a></li>
<li><a href="7-8-section8-8.html#section8-8"><span class="toc-section-number">7.8</span> Case study: First year college GPA and SATs</a></li>
<li><a href="7-9-section8-9.html#section8-9"><span class="toc-section-number">7.9</span> Different intercepts for different groups: MLR with indicator variables</a></li>
<li><a href="7-10-section8-10.html#section8-10"><span class="toc-section-number">7.10</span> Additive MLR with more than two groups: Headache example</a></li>
<li><a href="7-11-section8-11.html#section8-11"><span class="toc-section-number">7.11</span> Different slopes and different intercepts</a></li>
<li><a href="7-12-section8-12.html#section8-12"><span class="toc-section-number">7.12</span> F-tests for MLR models with quantitative and categorical variables and interactions</a></li>
<li><a href="7-13-section8-13.html#section8-13"><span class="toc-section-number">7.13</span> AICs for model selection</a></li>
<li><a href="7-14-section8-14.html#section8-14"><span class="toc-section-number">7.14</span> Case study: Forced expiratory volume model selection using AICs</a></li>
<li><a href="7-15-section8-15.html#section8-15"><span class="toc-section-number">7.15</span> Chapter summary</a></li>
<li><a href="7-16-section8-16.html#section8-16"><span class="toc-section-number">7.16</span> Summary of important R code</a></li>
<li><a href="7-17-section8-17.html#section8-17"><span class="toc-section-number">7.17</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="8-chapter9.html#chapter9"><span class="toc-section-number">8</span> Case studies</a><ul>
<li><a href="8-1-section9-1.html#section9-1"><span class="toc-section-number">8.1</span> Overview of material covered</a></li>
<li><a href="8-2-section9-2.html#section9-2"><span class="toc-section-number">8.2</span> The impact of simulated chronic nitrogen deposition on the biomass and N2-fixation activity of two boreal feather moss–cyanobacteria associations</a></li>
<li><a href="8-3-section9-3.html#section9-3"><span class="toc-section-number">8.3</span> Ants learn to rely on more informative attributes during decision-making</a></li>
<li><a href="8-4-section9-4.html#section9-4"><span class="toc-section-number">8.4</span> Multi-variate models are essential for understanding vertebrate diversification in deep time</a></li>
<li><a href="8-5-section9-5.html#section9-5"><span class="toc-section-number">8.5</span> What do didgeridoos really do about sleepiness?</a></li>
<li><a href="8-6-section9-6.html#section9-6"><span class="toc-section-number">8.6</span> General summary</a></li>
</ul></li>
<li><a href="references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="section7-3" class="section level2">
<h2><span class="header-section-number">6.3</span> Bozeman temperature trend</h2>
<p>For a new example, consider the yearly average maximum temperatures in Bozeman, MT.
For over 100 years, daily measurements have been taken of the minimum and
maximum temperatures at hundreds of weather stations across the US. In early
years, this involved manual recording of the temperatures and resetting the
thermometer to track the extremes for the following day. More recently, these
measures have been replaced by digital temperature recording devices that
continue to track this sort of information with much less human effort and,
possibly, errors. This sort of information is often aggregated to monthly or
yearly averages to be able to see “on average” changes from month-to-month or
year-to-year as opposed to the day-to-day variation in the temperature<a href="#fn101" class="footnote-ref" id="fnref101"><sup>101</sup></a>. Often the local information is aggregated further to
provide regional, hemispheric, or even global average temperatures. Climate
change research involves attempting to quantify the changes over time in these
and other long-term temperature or temperature proxies.</p>
<p>These data were extracted from the National Oceanic and Atmospheric
Administration’s National Centers for Environmental Information’s database
(<a href="http://www.ncdc.noaa.gov/cdo-web/" class="uri">http://www.ncdc.noaa.gov/cdo-web/</a>) and we will focus on the yearly
average of the monthly averages of the daily maximum temperature in Bozeman in degrees
F from 1901 to 2014. We can call
them yearly average maximum temperatures but note that it was a little more
complicated than that to arrive at the response variable we are analyzing.</p>
<p>(ref:fig7-5) Scatterplot of average yearly maximum temperatures in
Bozeman from 1900 to 2014 with SLR (solid) and smoothing (dashed) lines.</p>
<div class="sourceCode" id="cb596"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb596-1" title="1">bozemantemps &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;http://www.math.montana.edu/courses/s217/documents/BozemanMeanMax.csv&quot;</span>)</a>
<a class="sourceLine" id="cb596-2" title="2"><span class="kw">summary</span>(bozemantemps)</a></code></pre></div>
<pre><code>##     meanmax           Year     
##  Min.   :49.75   Min.   :1901  
##  1st Qu.:53.97   1st Qu.:1930  
##  Median :55.43   Median :1959  
##  Mean   :55.34   Mean   :1958  
##  3rd Qu.:57.02   3rd Qu.:1986  
##  Max.   :60.05   Max.   :2014</code></pre>
<div class="sourceCode" id="cb598"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb598-1" title="1"><span class="kw">length</span>(bozemantemps<span class="op">$</span>Year) <span class="co">#Some years are missing (1905, 1906, 1948, 1950,1995)</span></a></code></pre></div>
<pre><code>## [1] 109</code></pre>
<div class="sourceCode" id="cb600"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb600-1" title="1"><span class="kw">library</span>(car)</a>
<a class="sourceLine" id="cb600-2" title="2"><span class="kw">scatterplot</span>(meanmax<span class="op">~</span>Year, <span class="dt">data=</span>bozemantemps, </a>
<a class="sourceLine" id="cb600-3" title="3">            <span class="dt">ylab=</span><span class="st">&quot;Mean Maximum Temperature (degrees F)&quot;</span>, <span class="dt">smooth=</span><span class="kw">list</span>(<span class="dt">spread=</span>F),</a>
<a class="sourceLine" id="cb600-4" title="4">            <span class="dt">main=</span><span class="st">&quot;Scatterplot of Bozeman Yearly Average Max Temperatures&quot;</span>)</a></code></pre></div>
<div class="figure"><span id="fig:Figure7-5"></span>
<img src="07-simpleLinearRegressionInference_files/figure-html/Figure7-5-1.png" alt="(ref:fig7-5)" width="960" />
<p class="caption">
Figure 1.129: (ref:fig7-5)
</p>
</div>
<p>The scatterplot in Figure <a href="6-3-section7-3.html#fig:Figure7-5">1.129</a> shows the results between
1901 and 2014 based on a sample of <span class="math inline">\(n=109\)</span> years because four years had too
many missing months to fairly include in the responses. Missing values occur
for many reasons and in
this case were likely just machine or human error<a href="#fn102" class="footnote-ref" id="fnref102"><sup>102</sup></a>.
These are time series data and in time series analysis we assume that the
population of interest for inference is all possible realizations from the
underlying process over this time frame even though we only ever get to observe
one realization. In terms of climate change research, we would want to (a)
assess evidence for a trend over time (hopefully assessing whether any observed
trend is clearly different from a result that could have been observed by
chance if there really is no change over time in the true process) and (b)
quantify the size of the change over time along with the uncertainty in that
estimate relative to the underlying true mean change over time. The hypothesis
test for the slope answers (a) and the confidence interval for the slope
addresses (b). We also should be concerned about problematic (influential)
points, changing variance, and potential nonlinearity in the trend over time
causing problems for the SLR inferences. The scatterplot suggests that there is
a moderate or strong positive linear relationship between <em>temperatures</em> and
<em>year</em>. Both looking at the points and at the smoothing line does not suggest a clear curve in these responses over time and the variability seems similar across the years. There appears to be one potential large outlier
in the late 1930s.</p>
<p>We’ll perform all 6+ steps of the hypothesis test for the slope coefficient
and use the confidence
interval interpretation to discuss the size of the change.

First, we need to select our hypotheses (the 2-sided test
would be a <strong><em>conservative</em></strong> choice and no one that does climate change
research wants to be accused of taking a <strong><em>liberal</em></strong> approach in their analyses<a href="#fn103" class="footnote-ref" id="fnref103"><sup>103</sup></a>) and our test statistic, <span class="math inline">\(t=\frac{b_1}{\text{SE}_{b_1}}\)</span>. The scatterplot is the perfect tool to illustrate the situation.</p>
<ol style="list-style-type: decimal">
<li><strong>Hypotheses for the slope coefficient test:</strong></li>
</ol>
<p><span class="math display">\[H_0: \beta_1=0 \text{ vs } H_A: \beta_1 \ne 0\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Validity conditions:</strong></li>
</ol>
<ul>
<li><p><strong>Quantitative variables condition</strong></p>
<ul>
<li>Both <code>Year</code> and yearly average <code>Temperature</code> are
quantitative variables so are suitable for an SLR analysis.</li>
</ul></li>
<li><p><strong>Independence of observations</strong></p>
<ul>
<li>There may be a lack of independence among years since a warm
year might be followed by another warmer than average year. It
would take more sophisticated models to
account for this and the standard error on the slope coefficient could
either get larger or smaller depending on the type of
<strong><em>autocorrelation</em></strong> (correlation between neighboring time points or
correlation with oneself at some time
lag) present. This creates a caveat on these results but this model is
often the first one researchers fit in these situations and often is
reasonably correct even in the presence of some autocorrelation. </li>
</ul></li>
</ul>
<p>To assess the remaining conditions, we need to fit the regression model and use
the diagnostic plots in Figure <a href="6-3-section7-3.html#fig:Figure7-6">1.130</a> to aid our assessment:</p>

<div class="sourceCode" id="cb601"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb601-1" title="1">temp1 &lt;-<span class="st"> </span><span class="kw">lm</span>(meanmax<span class="op">~</span>Year, <span class="dt">data=</span>bozemantemps)</a>
<a class="sourceLine" id="cb601-2" title="2"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb601-3" title="3"><span class="kw">plot</span>(temp1, <span class="dt">add.smooth=</span>F)</a></code></pre></div>
<div class="figure"><span id="fig:Figure7-6"></span>
<img src="07-simpleLinearRegressionInference_files/figure-html/Figure7-6-1.png" alt="Diagnostic plots of the Bozeman yearly temperature simple linear regression model." width="960" />
<p class="caption">
Figure 1.130: Diagnostic plots of the Bozeman yearly temperature simple linear regression model.
</p>
</div>
<ul>
<li><p><strong>Linearity of relationship</strong></p>
<ul>
<li><p>Examine the Residuals vs Fitted plot:
</p>
<ul>
<li>There does not appear to be a clear curve remaining in
the residuals so we should be able to proceed without worrying too much
about missed nonlinearity.</li>
</ul></li>
</ul></li>
<li><p><strong>Equal (constant) variance</strong></p>
<ul>
<li>Examining the Residuals vs Fitted and the “Scale-Location” plots
provide little to no evidence of changing
variance.


The variability does decrease slightly in the middle fitted
values but those changes are really minor and present no real evidence of
changing variability.</li>
</ul></li>
<li><p><strong>Normality of residuals</strong></p>
<ul>
<li>Examining the Normal QQ-plot for violations of the normality
assumption shows only one real problem in the outlier from the
32<sup>nd</sup> observation in the data set (the temperature observed in 1934)
which was identified as a large outlier when examining the original scatterplot.

We should be careful about inferences that assume normality and contain this
point in the analysis. We might consider running the analysis with it and
without that point to see how much it impacts the results just to be sure
it isn’t creating evidence of a trend because of a violation of the
normality assumption. The next check reassures us that re-running the
model without this point would only result in slightly changing the SEs
and not the slopes.</li>
</ul></li>
<li><p><strong>No influential points:</strong></p>
<ul>
<li><p>There are no influential points displayed in the Residuals vs
Leverage plot since the Cook’s D contours are not displayed.  
</p>
<ul>
<li>Note: by default this plot contains a smoothing line that is
relatively meaningless, so ignore it
if is displayed. We suppressed it using the <code>add.smooth=F</code>
option in <code>plot(temp1)</code> but if you forget to do that, just
ignore the smoothers in the diagnostic plots especially in
the Residuals vs Leverage plot. </li>
</ul></li>
<li><p>These results tells us that the outlier was not influential. If
you look back at the scatterplot, it was
located near the middle of the observed <span class="math inline">\(x\text{&#39;s}\)</span> so its
potential leverage is low. You can find its leverage based on the
plot to be around 0.12 when there are observations in the data set
with leverages over 0.3. The high leverage points occur at the
beginning and the end of the record because they are at the edges of
the observed <span class="math inline">\(x\text{&#39;s}\)</span> and most of these points follow the overall
pattern fairly well.</p></li>
</ul></li>
</ul>
<p>So the main issues are with the assumption of independence
of observations and one non-influential outlier that might be compromising our
normality assumption a bit.</p>
<ol start="3" style="list-style-type: decimal">
<li><p><strong>Calculate the test statistic and p-value:</strong></p>
<ul>
<li><span class="math inline">\(t=0.05244/0.00476 = 11.02\)</span></li>
</ul>
<div class="sourceCode" id="cb602"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb602-1" title="1"><span class="kw">summary</span>(temp1)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = meanmax ~ Year, data = bozemantemps)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.3779 -0.9300  0.1078  1.1960  5.8698 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) -47.35123    9.32184   -5.08 1.61e-06
## Year          0.05244    0.00476   11.02  &lt; 2e-16
## 
## Residual standard error: 1.624 on 107 degrees of freedom
## Multiple R-squared:  0.5315, Adjusted R-squared:  0.5271 
## F-statistic: 121.4 on 1 and 107 DF,  p-value: &lt; 2.2e-16</code></pre>
<ul>
<li><p>From the model summary: p-value &lt; 2e-16 or just &lt; 0.0001</p></li>
<li><p>The test statistic is assumed to follow a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-2=109-2=107\)</span> degrees of freedom. The p-value can also be calculated as:</p></li>
</ul>
<div class="sourceCode" id="cb604"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb604-1" title="1"><span class="dv">2</span><span class="op">*</span><span class="kw">pt</span>(<span class="fl">11.02</span>, <span class="dt">df=</span><span class="dv">107</span>, <span class="dt">lower.tail=</span>F)</a></code></pre></div>
<pre><code>## [1] 2.498481e-19</code></pre>
<ul>
<li>Which is then reported as &lt; 0.0001, which means that the chances of observing a slope coefficient as extreme or more extreme than 0.052 if the null hypothesis of no linear relationship is true is less than 0.01%.</li>
</ul></li>
<li><p><strong>Write a conclusion:</strong></p>
<ul>
<li>There is very strong evidence against the null hypothesis of no linear relationship
between <em>Year</em> and yearly mean <em>Temperature</em> so we can conclude that
there is, in fact, some linear relationship between <em>Year</em> and yearly mean
maximum <em>Temperature</em> in Bozeman.</li>
</ul></li>
<li><p><strong>Size:</strong></p>
<ul>
<li>For a one year increase in Year, we estimate that, on average, the yearly average maximum temperature will change by 0.0524 <span class="math inline">\(^\circ F\)</span> (95% CI: 0.043 to 0.062). This suggests a modest but noticeable change in the mean temperature in Bozeman and the confidence suggests minimal variation around this estimate, going from 0.04 to 0.06 <span class="math inline">\(^\circ F\)</span>. The “size” of this change is discussed more in Section <a href="6-5-section7-5.html#section7-5">6.5</a>.</li>
</ul>
<div class="sourceCode" id="cb606"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb606-1" title="1"><span class="kw">confint</span>(temp1)</a></code></pre></div>
<pre><code>##                    2.5 %       97.5 %
## (Intercept) -65.83068375 -28.87177785
## Year          0.04300681   0.06187746</code></pre></li>
<li><p><strong>Scope of inference:</strong></p>
<ul>
<li>We can conclude that this detected trend pertains to the Bozeman
area in the years 1901 to 2014 but not outside of either this area or time frame. We
cannot say that time caused the observed changes since it was not randomly
assigned and we cannot attribute the changes to any other factors because we
did not consider them. But knowing that there was a trend toward increasing
temperatures is an intriguing first step in a more complete analysis of changing climate in
the area.</li>
</ul></li>
</ol>
<p>It is also good to report the percentage of variation that the model explains:
<em>Year</em> explains 54.91% of the variation in yearly average maximum <em>Temperature</em>.
If the coefficient of determination value had been very
small, we might discount the previous result. Since it is moderately large,
that suggests that just by using a linear trend over time we can account for
quite a bit of the variation in yearly average maximum temperatures in Bozeman.
Note that the percentage of variation explained would get much worse if we
tried to analyze the monthly or original daily maximum temperature data even though we might find about the same estimated mean change over time.</p>
<p>Interpreting a confidence interval provides more useful information than the
hypothesis test here –
instead of just assessing evidence against the null hypothesis, we can actually
provide our best guess at the true change in the mean of <span class="math inline">\(y\)</span> for a change in <span class="math inline">\(x\)</span>.
Here, the 95% CI is (0.043, 0.062). This tells us that for a 1 year increase in <em>Year</em>, we are 95% confident that the change in the true mean of the yearly average maximum <em>Temperatures</em> in Bozeman is between 0.043 and 0.062 <span class="math inline">\(^\circ F\)</span>.</p>
<p>Sometimes the scale of the x-variable makes interpretation a little difficult,
so we can re-scale it
to make the resulting slope coefficient more interpretable without changing how the model fits the responses. One option is to re-scale the variable and
re-fit the regression model and the other (easier) option is to re-scale our
interpretation. The idea here is that a 100-year change might be easier and
more meaningful scale to interpret than a single year change. If we have a
slope in the model of 0.052 (for a 1 year change), we can also say that a 100
year change in the mean is estimated to be 0.052*100 = 0.52<span class="math inline">\(^\circ F\)</span>.
Similarly, the 95% CI for the
population mean 100-year change would be from
0.43<span class="math inline">\(^\circ F\)</span> to 0.62<span class="math inline">\(^\circ F\)</span>. In 2007, the IPCC
(Intergovernmental Panel on Climate Change;
<a href="http://www.ipcc.ch/publications_and_data/ar4/wg1/en/tssts-3-1-1.html" class="uri">http://www.ipcc.ch/publications_and_data/ar4/wg1/en/tssts-3-1-1.html</a>)
estimated the global temperature change from 1906 to 2005 to be
0.74<span class="math inline">\(^\circ C\)</span> per decade or, scaled up, 7.4<span class="math inline">\(^\circ C\)</span> per century
(1.33<span class="math inline">\(^\circ F\)</span>). There are many reasons why our
local temperature trend might differ, including that our analysis was of
average maximum temperatures and the IPCC was considering the average
temperature (which was not measured locally or in most places in a good way
until digital instrumentation was installed) and that local trends are likely
to vary around the global average change based on localized environmental
conditions.</p>
<p>One issue that arises in studies of climate change is that researchers
often consider these sorts
of tests at many locations and on many response variables (if I did the maximum
temperature, why not also do the same analysis of the minimum temperature time
series as well? And if I did the analysis for Bozeman, what about Butte and
Helena and…?). Remember our discussion of multiple testing issues? This issue can arise when regression
modeling is repeated in many similar data sets, say different sites or
different response variables or both, in one study. In <span class="citation">Moore, Harper, and Greenwood (<a href="#ref-Moore2007" role="doc-biblioref">2007</a>)</span>, we considered the impacts on the assessment of evidence of trends
of earlier spring onset timing in the Mountain West when the number of tests
across many sites is accounted for. We found that the evidence for time trends
decreases substantially but does not disappear. In a related study, <span class="citation">Greenwood, Harper, and Moore (<a href="#ref-Greenwood2011" role="doc-biblioref">2011</a>)</span>
found evidence for regional trends to earlier spring
onset using more sophisticated statistical models. The main point here is to
<strong>be careful when using simple statistical methods repeatedly if you are
not accounting for the number of tests performed</strong>. </p>
<p>Along with the confidence interval, we can also plot the estimated model
(Figure <a href="6-3-section7-3.html#fig:Figure7-7">1.131</a>) using a term-plot from the <code>effects</code> package
(Fox, 2003). This is the same function we used for visualizing results
in the ANOVA models and in its basic application you just need
<code>plot(allEffects(MODELNAME))</code> although we from time to time, we will add some options.


In
regression models, we get to see the regression line along with bounds for
95% confidence intervals for the mean at every value of <span class="math inline">\(x\)</span> that was observed
(explained in the next section). Note that there is also a rugplot on the x-axis
showing you where values of the explanatory variable were obtained, which is
useful to understanding how much information is available for different aspects
of the line. Here it provides gaps for missing years of observations as sort of
broken teeth in a comb. Also not used here, we can also turn on the <code>residuals=T</code> option, which in SLR just plots the original points and adds a smoothing line to this plot to reinforce the previous assessment of assumptions.</p>
<p>(ref:fig7-7) Term-plot for the Bozeman mean yearly maximum temperature
linear regression model with 95% confidence interval bands for the mean
in each year.</p>
<div class="sourceCode" id="cb608"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb608-1" title="1"><span class="kw">require</span>(effects)</a>
<a class="sourceLine" id="cb608-2" title="2"><span class="kw">plot</span>(<span class="kw">allEffects</span>(temp1, <span class="dt">xlevels=</span><span class="kw">list</span>(<span class="dt">Year=</span>bozemantemps<span class="op">$</span>Year)),</a>
<a class="sourceLine" id="cb608-3" title="3">     <span class="dt">grid=</span>T)</a></code></pre></div>
<div class="figure"><span id="fig:Figure7-7"></span>
<img src="07-simpleLinearRegressionInference_files/figure-html/Figure7-7-1.png" alt="(ref:fig7-7)" width="576" />
<p class="caption">
Figure 1.131: (ref:fig7-7)
</p>
</div>
<p>If we extended the plot for the model to <code>Year</code> = 0, we could see the
reason that the y-intercept in this model is -47.4<span class="math inline">\(^\circ F\)</span>. This is
obviously a large extrapolation for these data and provides a silly result.
However, in paleoclimate data that goes back
thousands of years using tree rings, ice cores, or sea sediments, the estimated
mean in year 0 might be interesting and within the scope of observed values or it might not. For example, in <span class="citation">Santibáñez et al. (<a href="#ref-Santibanez2018" role="doc-biblioref">2018</a>)</span>, the data were a time series from 27,000 to about 9,000 years before present extracted from Antarctic ice cores. It all depends on the application.</p>
<p>To make the y-intercept more interesting for our data set, we can re-scale
the <span class="math inline">\(x\text{&#39;s}\)</span> before we fit the
model to have the first year in the data set (1901) be “0”. This is
accomplished by calculating <span class="math inline">\(\text{Year2} = \text{Year}-1901\)</span>.</p>
<div class="sourceCode" id="cb609"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb609-1" title="1">bozemantemps<span class="op">$</span>Year2 &lt;-<span class="st"> </span>bozemantemps<span class="op">$</span>Year <span class="op">-</span><span class="st"> </span><span class="dv">1901</span></a>
<a class="sourceLine" id="cb609-2" title="2"><span class="kw">summary</span>(bozemantemps<span class="op">$</span>Year2)</a></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    0.00   29.00   58.00   57.27   85.00  113.00</code></pre>
<p>The new estimated regression equation is
<span class="math inline">\(\widehat{\text{Temp}}_i = 52.34 + 0.052\cdot\text{Year2}_i\)</span>. The slope and
its test statistic are the same as in the previous model. The y-intercept
has changed dramatically with a 95% CI from 51.72<span class="math inline">\(^\circ F\)</span> to 52.96<span class="math inline">\(^\circ F\)</span>
for <code>Year2</code>=0. But we know that <code>Year2</code> has a 0 value for 1901 because
of our subtraction. That means that this CI is
for the true mean in 1901 and is now at least somewhat interesting. If you
revisit Figure <a href="6-3-section7-3.html#fig:Figure7-7">1.131</a> you will actually see that the displayed
confidence intervals
provide upper and lower bounds that match this result for 1901 – the
y-intercept CI matches the 95% CI for the true mean in the first year of the data set.</p>
<div class="sourceCode" id="cb611"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb611-1" title="1">temp2 &lt;-<span class="st"> </span><span class="kw">lm</span>(meanmax<span class="op">~</span>Year2, <span class="dt">data=</span>bozemantemps)</a>
<a class="sourceLine" id="cb611-2" title="2"><span class="kw">summary</span>(temp2)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = meanmax ~ Year2, data = bozemantemps)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.3779 -0.9300  0.1078  1.1960  5.8698 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 52.34126    0.31383  166.78   &lt;2e-16
## Year2        0.05244    0.00476   11.02   &lt;2e-16
## 
## Residual standard error: 1.624 on 107 degrees of freedom
## Multiple R-squared:  0.5315, Adjusted R-squared:  0.5271 
## F-statistic: 121.4 on 1 and 107 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb613"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb613-1" title="1"><span class="kw">confint</span>(temp2)</a></code></pre></div>
<pre><code>##                   2.5 %      97.5 %
## (Intercept) 51.71913822 52.96339150
## Year2        0.04300681  0.06187746</code></pre>
<p>Ideally, we want to find a regression model that does not violate any
assumptions, has a high <span class="math inline">\(\mathbf{R^2}\)</span> value, and a slope coefficient
with a small p-value. If any of these are not the case, then we are
not completely satisfied with the regression and <strong>should be suspicious
of any inference we perform</strong>. We can sometimes resolve some of the
systematic issues noted above using <strong><em>transformations</em></strong>, discussed in
Sections <a href="6-5-section7-5.html#section7-5">6.5</a> and <a href="6-6-section7-6.html#section7-6">6.6</a>.
</p>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Greenwood2011">
<p>Greenwood, Mark C., Joel Harper, and Johnnie Moore. 2011. “An Application of Statistics in Climate Change: Detection of Nonlinear Changes in a Streamflow Timing Measure in the Columbia and Missouri Headwaters.” In <em>Handbook of the Philosophy of Science, Vol. 7: Statistics</em>, edited by P. S. Bandyopadhyay and M. Forster, 1117–42. Elsevier.</p>
</div>
<div id="ref-Moore2007">
<p>Moore, Johnnie N., Joel T. Harper, and Mark C. Greenwood. 2007. “Significance of Trends Toward Earlier Snowmelt Runoff, Columbia and Missouri Basin Headwaters, Western United States.” <em>Geophysical Research Letters</em> 34 (16). <a href="https://doi.org/10.1029/2007GL031022">https://doi.org/10.1029/2007GL031022</a>.</p>
</div>
<div id="ref-Santibanez2018">
<p>Santibáñez, Pamela A., Olivia J. Maselli, Mark C. Greenwood, Mackenzie M. Grieman, Eric S. Saltzman, Joseph R. McConnell, and John C. Priscu. 2018. “Prokaryotes in the Wais Divide Ice Core Reflect Source and Transport Changes Between Last Glacial Maximum and the Early Holocene.” <em>Global Change Biology</em> 24 (5): 2182–97. <a href="https://doi.org/10.1111/gcb.14042">https://doi.org/10.1111/gcb.14042</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="101">
<li id="fn101"><p>See
<a href="http://fivethirtyeight.com/features/which-city-has-the-most-unpredictable-weather/" class="uri">http://fivethirtyeight.com/features/which-city-has-the-most-unpredictable-weather/</a>
for an interesting discussion of
weather variability where Great Falls, MT had a very high rating on
“unpredictability”.<a href="6-3-section7-3.html#fnref101" class="footnote-back">↩</a></p></li>
<li id="fn102"><p>It is actually pretty
amazing that there are hundreds of locations with nearly complete daily
records for over 100 years.<a href="6-3-section7-3.html#fnref102" class="footnote-back">↩</a></p></li>
<li id="fn103"><p>All joking aside, if researchers can find evidence of climate
change using <strong><em>conservative</em></strong> methods (methods that reject the null
hypothesis when it is true less often than stated), then their results are
even harder to ignore.<a href="6-3-section7-3.html#fnref103" class="footnote-back">↩</a></p></li>
</ol>
</div>
<p style="text-align: center;">
<a href="6-2-section7-2.html"><button class="btn btn-default">Previous</button></a>
<a href="6-4-section7-4.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
