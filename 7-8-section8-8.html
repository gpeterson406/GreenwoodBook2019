<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="7.8 Case study: First year college GPA and SATs | Intermediate Statistics with R" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="gpeterson406/Greenwood_Book" />

<meta name="author" content="Mark C Greenwood" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="7.8 Case study: First year college GPA and SATs | Intermediate Statistics with R">

<title>7.8 Case study: First year college GPA and SATs | Intermediate Statistics with R</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#cover">Cover</a></li>
<li class="has-sub"><a href="acknowledgments.html#acknowledgments">Acknowledgments</a><ul>
<li><a href="0-1-section1-5.html#section1-5"><span class="toc-section-number">0.1</span> Summary of important R code</a></li>
</ul></li>
<li class="has-sub"><a href="1-chapter2.html#chapter2"><span class="toc-section-number">1</span> (R)e-Introduction to statistics</a><ul>
<li><a href="1-1-section2-1.html#section2-1"><span class="toc-section-number">1.1</span> Histograms, boxplots, and density curves</a></li>
<li><a href="1-2-section2-2.html#section2-2"><span class="toc-section-number">1.2</span> Pirate-plots</a></li>
<li><a href="1-3-section2-3.html#section2-3"><span class="toc-section-number">1.3</span> Models, hypotheses, and permutations for the two sample mean situation</a></li>
<li><a href="1-4-section2-4.html#section2-4"><span class="toc-section-number">1.4</span> Permutation testing for the two sample mean situation</a></li>
<li><a href="1-5-section2-5.html#section2-5"><span class="toc-section-number">1.5</span> Hypothesis testing (general)</a></li>
<li><a href="1-6-section2-6.html#section2-6"><span class="toc-section-number">1.6</span> Connecting randomization (nonparametric) and parametric tests</a></li>
<li><a href="1-7-section2-7.html#section2-7"><span class="toc-section-number">1.7</span> Second example of permutation tests</a></li>
<li><a href="1-8-section2-8.html#section2-8"><span class="toc-section-number">1.8</span> Reproducibility Crisis: Moving beyond p &lt; 0.05, publication bias, and multiple testing issues</a></li>
<li><a href="1-9-section2-9.html#section2-9"><span class="toc-section-number">1.9</span> Confidence intervals and bootstrapping</a></li>
<li><a href="1-10-section2-10.html#section2-10"><span class="toc-section-number">1.10</span> Bootstrap confidence intervals for difference in GPAs</a></li>
<li><a href="1-11-section2-11.html#section2-11"><span class="toc-section-number">1.11</span> Chapter summary</a></li>
<li><a href="1-12-section2-12.html#section2-12"><span class="toc-section-number">1.12</span> Summary of important R code</a></li>
<li><a href="1-13-section2-13.html#section2-13"><span class="toc-section-number">1.13</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="2-chapter3.html#chapter3"><span class="toc-section-number">2</span> One-Way ANOVA</a><ul>
<li><a href="2-1-section3-1.html#section3-1"><span class="toc-section-number">2.1</span> Situation</a></li>
<li><a href="2-2-section3-2.html#section3-2"><span class="toc-section-number">2.2</span> Linear model for One-Way ANOVA (cell-means and reference-coding)</a></li>
<li><a href="2-3-section3-3.html#section3-3"><span class="toc-section-number">2.3</span> One-Way ANOVA Sums of Squares, Mean Squares, and F-test</a></li>
<li><a href="2-4-section3-4.html#section3-4"><span class="toc-section-number">2.4</span> ANOVA model diagnostics including QQ-plots</a></li>
<li><a href="2-5-section3-5.html#section3-5"><span class="toc-section-number">2.5</span> Guinea pig tooth growth One-Way ANOVA example</a></li>
<li><a href="2-6-section3-6.html#section3-6"><span class="toc-section-number">2.6</span> Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display</a></li>
<li><a href="2-7-section3-7.html#section3-7"><span class="toc-section-number">2.7</span> Pair-wise comparisons for the Overtake data</a></li>
<li><a href="2-8-section3-8.html#section3-8"><span class="toc-section-number">2.8</span> Chapter summary</a></li>
<li><a href="2-9-section3-9.html#section3-9"><span class="toc-section-number">2.9</span> Summary of important R code</a></li>
<li><a href="2-10-section3-10.html#section3-10"><span class="toc-section-number">2.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="3-chapter4.html#chapter4"><span class="toc-section-number">3</span> Two-Way ANOVA</a><ul>
<li><a href="3-1-section4-1.html#section4-1"><span class="toc-section-number">3.1</span> Situation</a></li>
<li><a href="3-2-section4-2.html#section4-2"><span class="toc-section-number">3.2</span> Designing a two-way experiment and visualizing results</a></li>
<li><a href="3-3-section4-3.html#section4-3"><span class="toc-section-number">3.3</span> Two-Way ANOVA models and hypothesis tests</a></li>
<li><a href="3-4-section4-4.html#section4-4"><span class="toc-section-number">3.4</span> Guinea pig tooth growth analysis with Two-Way ANOVA</a></li>
<li><a href="3-5-section4-5.html#section4-5"><span class="toc-section-number">3.5</span> Observational study example: The Psychology of Debt</a></li>
<li><a href="3-6-section4-6.html#section4-6"><span class="toc-section-number">3.6</span> Pushing Two-Way ANOVA to the limit: Un-replicated designs and Estimability</a></li>
<li><a href="3-7-section4-7.html#section4-7"><span class="toc-section-number">3.7</span> Chapter summary</a></li>
<li><a href="3-8-section4-8.html#section4-8"><span class="toc-section-number">3.8</span> Summary of important R code</a></li>
<li><a href="3-9-section4-9.html#section4-9"><span class="toc-section-number">3.9</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="4-chapter5.html#chapter5"><span class="toc-section-number">4</span> Chi-square tests</a><ul>
<li><a href="4-1-section5-1.html#section5-1"><span class="toc-section-number">4.1</span> Situation, contingency tables, and tableplots</a></li>
<li><a href="4-2-section5-2.html#section5-2"><span class="toc-section-number">4.2</span> Homogeneity test hypotheses</a></li>
<li><a href="4-3-section5-3.html#section5-3"><span class="toc-section-number">4.3</span> Independence test hypotheses</a></li>
<li><a href="4-4-section5-4.html#section5-4"><span class="toc-section-number">4.4</span> Models for R by C tables</a></li>
<li><a href="4-5-section5-5.html#section5-5"><span class="toc-section-number">4.5</span> Permutation tests for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="4-6-section5-6.html#section5-6"><span class="toc-section-number">4.6</span> Chi-square distribution for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="4-7-section5-7.html#section5-7"><span class="toc-section-number">4.7</span> Examining residuals for the source of differences</a></li>
<li><a href="4-8-section5-8.html#section5-8"><span class="toc-section-number">4.8</span> General protocol for <span class="math inline">\(X^2\)</span> tests</a></li>
<li><a href="4-9-section5-9.html#section5-9"><span class="toc-section-number">4.9</span> Political party and voting results: Complete analysis</a></li>
<li><a href="4-10-section5-10.html#section5-10"><span class="toc-section-number">4.10</span> Is cheating and lying related in students?</a></li>
<li><a href="4-11-section5-11.html#section5-11"><span class="toc-section-number">4.11</span> Analyzing a stratified random sample of California schools</a></li>
<li><a href="4-12-section5-12.html#section5-12"><span class="toc-section-number">4.12</span> Chapter summary</a></li>
<li><a href="4-13-section5-13.html#section5-13"><span class="toc-section-number">4.13</span> Summary of important R commands</a></li>
<li><a href="4-14-section5-14.html#section5-14"><span class="toc-section-number">4.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="5-chapter6.html#chapter6"><span class="toc-section-number">5</span> Correlation and Simple Linear Regression</a><ul>
<li><a href="5-1-section6-1.html#section6-1"><span class="toc-section-number">5.1</span> Relationships between two quantitative variables</a></li>
<li><a href="5-2-section6-2.html#section6-2"><span class="toc-section-number">5.2</span> Estimating the correlation coefficient</a></li>
<li><a href="5-3-section6-3.html#section6-3"><span class="toc-section-number">5.3</span> Relationships between variables by groups</a></li>
<li><a href="5-4-section6-4.html#section6-4"><span class="toc-section-number">5.4</span> Inference for the correlation coefficient</a></li>
<li><a href="5-5-section6-5.html#section6-5"><span class="toc-section-number">5.5</span> Are tree diameters related to tree heights?</a></li>
<li><a href="5-6-section6-6.html#section6-6"><span class="toc-section-number">5.6</span> Describing relationships with a regression model</a></li>
<li><a href="5-7-section6-7.html#section6-7"><span class="toc-section-number">5.7</span> Least Squares Estimation</a></li>
<li><a href="5-8-section6-8.html#section6-8"><span class="toc-section-number">5.8</span> Measuring the strength of regressions: R<sup>2</sup></a></li>
<li><a href="5-9-section6-9.html#section6-9"><span class="toc-section-number">5.9</span> Outliers: leverage and influence</a></li>
<li><a href="5-10-section6-10.html#section6-10"><span class="toc-section-number">5.10</span> Residual diagnostics – setting the stage for inference</a></li>
<li><a href="5-11-section6-11.html#section6-11"><span class="toc-section-number">5.11</span> Old Faithful discharge and waiting times</a></li>
<li><a href="5-12-section6-12.html#section6-12"><span class="toc-section-number">5.12</span> Chapter summary</a></li>
<li><a href="5-13-section6-13.html#section6-13"><span class="toc-section-number">5.13</span> Summary of important R code</a></li>
<li><a href="5-14-section6-14.html#section6-14"><span class="toc-section-number">5.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="6-chapter7.html#chapter7"><span class="toc-section-number">6</span> Simple linear regression inference</a><ul>
<li><a href="6-1-section7-1.html#section7-1"><span class="toc-section-number">6.1</span> Model</a></li>
<li><a href="6-2-section7-2.html#section7-2"><span class="toc-section-number">6.2</span> Confidence interval and hypothesis tests for the slope and intercept</a></li>
<li><a href="6-3-section7-3.html#section7-3"><span class="toc-section-number">6.3</span> Bozeman temperature trend</a></li>
<li><a href="6-4-section7-4.html#section7-4"><span class="toc-section-number">6.4</span> Randomization-based inferences for the slope coefficient</a></li>
<li><a href="6-5-section7-5.html#section7-5"><span class="toc-section-number">6.5</span> Transformations part I: Linearizing relationships</a></li>
<li><a href="6-6-section7-6.html#section7-6"><span class="toc-section-number">6.6</span> Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x)</a></li>
<li><a href="6-7-section7-7.html#section7-7"><span class="toc-section-number">6.7</span> Confidence interval for the mean and prediction intervals for a new observation</a></li>
<li><a href="6-8-section7-8.html#section7-8"><span class="toc-section-number">6.8</span> Chapter summary</a></li>
<li><a href="6-9-section7-9.html#section7-9"><span class="toc-section-number">6.9</span> Summary of important R code</a></li>
<li><a href="6-10-section7-10.html#section7-10"><span class="toc-section-number">6.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="7-chapter8.html#chapter8"><span class="toc-section-number">7</span> Multiple linear regression</a><ul>
<li><a href="7-1-section8-1.html#section8-1"><span class="toc-section-number">7.1</span> Going from SLR to MLR</a></li>
<li><a href="7-2-section8-2.html#section8-2"><span class="toc-section-number">7.2</span> Validity conditions in MLR</a></li>
<li><a href="7-3-section8-3.html#section8-3"><span class="toc-section-number">7.3</span> Interpretation of MLR terms</a></li>
<li><a href="7-4-section8-4.html#section8-4"><span class="toc-section-number">7.4</span> Comparing multiple regression models</a></li>
<li><a href="7-5-section8-5.html#section8-5"><span class="toc-section-number">7.5</span> General recommendations for MLR interpretations and VIFs</a></li>
<li><a href="7-6-section8-6.html#section8-6"><span class="toc-section-number">7.6</span> MLR inference: Parameter inferences using the t-distribution</a></li>
<li><a href="7-7-section8-7.html#section8-7"><span class="toc-section-number">7.7</span> Overall F-test in multiple linear regression</a></li>
<li><a href="7-8-section8-8.html#section8-8"><span class="toc-section-number">7.8</span> Case study: First year college GPA and SATs</a></li>
<li><a href="7-9-section8-9.html#section8-9"><span class="toc-section-number">7.9</span> Different intercepts for different groups: MLR with indicator variables</a></li>
<li><a href="7-10-section8-10.html#section8-10"><span class="toc-section-number">7.10</span> Additive MLR with more than two groups: Headache example</a></li>
<li><a href="7-11-section8-11.html#section8-11"><span class="toc-section-number">7.11</span> Different slopes and different intercepts</a></li>
<li><a href="7-12-section8-12.html#section8-12"><span class="toc-section-number">7.12</span> F-tests for MLR models with quantitative and categorical variables and interactions</a></li>
<li><a href="7-13-section8-13.html#section8-13"><span class="toc-section-number">7.13</span> AICs for model selection</a></li>
<li><a href="7-14-section8-14.html#section8-14"><span class="toc-section-number">7.14</span> Case study: Forced expiratory volume model selection using AICs</a></li>
<li><a href="7-15-section8-15.html#section8-15"><span class="toc-section-number">7.15</span> Chapter summary</a></li>
<li><a href="7-16-section8-16.html#section8-16"><span class="toc-section-number">7.16</span> Summary of important R code</a></li>
<li><a href="7-17-section8-17.html#section8-17"><span class="toc-section-number">7.17</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="8-chapter9.html#chapter9"><span class="toc-section-number">8</span> Case studies</a><ul>
<li><a href="8-1-section9-1.html#section9-1"><span class="toc-section-number">8.1</span> Overview of material covered</a></li>
<li><a href="8-2-section9-2.html#section9-2"><span class="toc-section-number">8.2</span> The impact of simulated chronic nitrogen deposition on the biomass and N2-fixation activity of two boreal feather moss–cyanobacteria associations</a></li>
<li><a href="8-3-section9-3.html#section9-3"><span class="toc-section-number">8.3</span> Ants learn to rely on more informative attributes during decision-making</a></li>
<li><a href="8-4-section9-4.html#section9-4"><span class="toc-section-number">8.4</span> Multi-variate models are essential for understanding vertebrate diversification in deep time</a></li>
<li><a href="8-5-section9-5.html#section9-5"><span class="toc-section-number">8.5</span> What do didgeridoos really do about sleepiness?</a></li>
<li><a href="8-6-section9-6.html#section9-6"><span class="toc-section-number">8.6</span> General summary</a></li>
</ul></li>
<li><a href="references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="section8-8" class="section level2">
<h2><span class="header-section-number">7.8</span> Case study: First year college GPA and SATs</h2>
<p>Many universities require students to have certain test scores in order to be
admitted into their institutions. They
obviously must think that those scores are useful predictors of student success
to use them in this way. Quality assessments of recruiting classes are also
based on their test scores. The Educational Testing Service (the company behind
such fun exams as the SAT and GRE) collected a data set to validate their SAT
on <span class="math inline">\(n=1000\)</span> students from an unnamed Midwestern university; the data set is
available in the <code>openintro</code> package <span class="citation">(Diez, Barr, and Cetinkaya-Rundel <a href="#ref-R-openintro" role="doc-biblioref">2017</a>)</span>
in the <code>satGPA</code> data set.

It is unclear from the documentation whether a
random sample was collected, in fact it looks like it certainly wasn’t a random
sample of all incoming students at a large university (more later). What
potential issues would arise if a company was providing a data set to show the
performance of their test and it was not based on a random sample?</p>
<p>We will proceed assuming they used good methods in developing their test
(there are sophisticated
statistical models underlying the development of the SAT and GRE) and in
obtaining a data set for testing out the performance of their tests that is at
least representative of the students (or some types of students) at this
university. They provided information on the <em>Sex</em> (<code>sex</code>) of the students
(coded 1 and 2 with possibly 1 for males and 2 for females – but should this
even be displayed in a plot with correlations?), <em>SAT Verbal</em> (<code>SATV</code>)
and <em>Math</em> (<code>SATM</code>) percentiles (these are not the scores but the ranking
percentile that each score translated to in a particular year),
<em>High School GPA</em> (<code>HSGPA</code>), and <em>First Year</em> of college <em>GPA</em> (<code>FYGPA</code>).
Our interests here are in whether the two SAT percentiles are (together?)
related to the first year college GPA, describing the size of their impacts
and assessing the predictive potential of SAT-based measures for first year in
college GPA. There are certainly other possible research questions that can be
addressed with these data but this will keep us focused.
</p>

<div class="sourceCode" id="cb745"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb745-1" title="1"><span class="kw">library</span>(openintro)</a>
<a class="sourceLine" id="cb745-2" title="2"><span class="kw">data</span>(satGPA)</a>
<a class="sourceLine" id="cb745-3" title="3">satGPA &lt;-<span class="st"> </span><span class="kw">as.tibble</span>(satGPA)</a>
<a class="sourceLine" id="cb745-4" title="4"><span class="kw">pairs.panels</span>(satGPA[,<span class="op">-</span><span class="dv">4</span>], <span class="dt">ellipse=</span>F, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)</a></code></pre></div>
<div class="figure"><span id="fig:Figure8-13"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-13-1.png" alt="Scatterplot matrix of SAT and GPA data set." width="672" />
<p class="caption">
Figure 1.162: Scatterplot matrix of SAT and GPA data set.
</p>
</div>
<p>There are positive relationships in Figure <a href="7-8-section8-8.html#fig:Figure8-13">1.162</a> among all the
pre-college measures and the <em>college GPA</em> but none are above the moderate
strength level. The <em>HSGPA</em> has a highest correlation with
first year of college results but its correlation is not that strong. Maybe
together in a model the SAT percentiles can also be useful… Also note that
plot shows an odd <em>HSGPA</em> of 4.5 that probably should be removed<a href="#fn121" class="footnote-ref" id="fnref121"><sup>121</sup></a> if that variable is going to be used (<em>HSGPA</em>
was not used in the following models so the observation remains in the data).</p>
<p>In MLR, the modeling process is a bit more complex and often involves
more than one model, so we will often avoid the 6+ steps in testing initially
and try to generate a model we can use in that more specific process. In this
case, the first model of interest using the two SAT percentiles,</p>
<p><span class="math display">\[\text{FYGPA}_i = \beta_0 + \beta_{\text{SATV}}\text{SATV}_i 
+ \beta_{\text{SATM}}\text{SATM}_i +\varepsilon_i,\]</span></p>
<p>looks like it might be worth interrogating further so we can jump straight
into considering the 6+ steps involved in hypothesis testing for the two slope
coefficients.

We will use <span class="math inline">\(t\)</span>-based
inferences, assuming that we can trust the assumptions.</p>
<p>Note that this is not a randomized experiment but we can assume that
it is representative of the students at that
single university. We would not want to extend these inferences to other
universities (who might be more or less selective) or to students who did not
get into this university and, especially, not to students that failed to complete
the first year. The second and third constraints point to a severe limitation
in this research – only students who were accepted, went to, and finished one
year at this university could be studied. Lower SAT percentile students might
not have been allowed in or may not have finished the first year and higher SAT
students might have been attracted to other more prestigious institutions. So
the scope of inference is just limited to students that were invited and chose
to attend this institution and successfully completed one year of courses. It
is hard to know if the SAT “works” when the inferences are so restricted in who
they might apply to…</p>
<p>The following code fits the model of interest, provides a model summary,
and the diagnostic plots, allowing us to consider the tests of interest:</p>
<p>(ref:fig8-14) Diagnostic plots for the
<span class="math inline">\(\text{FYGPA}\sim\text{ SATV }+\text{ SATM}\)</span> model.</p>
<div class="sourceCode" id="cb746"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb746-1" title="1">gpa1 &lt;-<span class="st"> </span><span class="kw">lm</span>(FYGPA<span class="op">~</span>SATV<span class="op">+</span>SATM, <span class="dt">data=</span>satGPA)</a>
<a class="sourceLine" id="cb746-2" title="2"><span class="kw">summary</span>(gpa1)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = FYGPA ~ SATV + SATM, data = satGPA)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.19647 -0.44777  0.02895  0.45717  1.60940 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 0.007372   0.152292   0.048    0.961
## SATV        0.025390   0.002859   8.879  &lt; 2e-16
## SATM        0.022395   0.002786   8.037 2.58e-15
## 
## Residual standard error: 0.6582 on 997 degrees of freedom
## Multiple R-squared:  0.2122, Adjusted R-squared:  0.2106 
## F-statistic: 134.2 on 2 and 997 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb748"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb748-1" title="1"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="dt">oma=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">0</span>))</a>
<a class="sourceLine" id="cb748-2" title="2"><span class="kw">plot</span>(gpa1, <span class="dt">sub.caption=</span><span class="st">&quot;Diagnostics for GPA model with SATV and SATM&quot;</span>)</a></code></pre></div>
<div class="figure"><span id="fig:Figure8-14"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-14-1.png" alt="(ref:fig8-14)" width="960" />
<p class="caption">
Figure 1.163: (ref:fig8-14)
</p>
</div>
<ol style="list-style-type: decimal">
<li><p>Hypotheses of interest:</p>
<ul>
<li><p><span class="math inline">\(H_0: \beta_\text{SATV}=0\)</span> given <em>SATM</em> in the model vs
<span class="math inline">\(H_A: \beta_\text{SATV}\ne 0\)</span> given <em>SATM</em> in the model.</p></li>
<li><p><span class="math inline">\(H_0: \beta_\text{SATM}=0\)</span> given <em>SATV</em> in the model vs
<span class="math inline">\(H_A: \beta_\text{SATM}\ne 0\)</span> given <em>SATV</em> in the model.</p></li>
</ul></li>
<li><p>Validity conditions:</p>
<ul>
<li><p><strong>Quantitative variables condition:</strong></p>
<ul>
<li>The variables used here in this model are quantitative. Note that <em>sex</em> was
plotted in the previous scatterplot matrix and is not quantitative –
we will explore its use later.</li>
</ul></li>
</ul>
<p></p>
<ul>
<li><p><strong>Independence of observations:</strong></p>
<ul>
<li>With a sample from a single university from (we are assuming) a
single year of students, there is no particular reason to assume a
violation of the independence assumption.</li>
</ul></li>
<li><p><strong>Linearity of relationships:</strong></p>
<ul>
<li><p>The initial scatterplots (Figure <a href="7-8-section8-8.html#fig:Figure8-13">1.162</a>) do not show
any clear nonlinearities with each predictor used in this model.</p></li>
<li><p>The Residuals vs Fitted and Scale-Location plots (Figure
<a href="7-8-section8-8.html#fig:Figure8-14">1.163</a>) do not show much more than a football shape,
which is our desired result.</p>
<ul>
<li>Together, there is no suggestion of a violation of the linearity
assumption.</li>
</ul></li>
</ul></li>
<li><p><strong>Multicollinearity checked for:</strong></p>
<ul>
<li><p>The original scatterplots suggest that there is some collinearity
between the two SAT percentiles with a correlation of 0.47. That is
actually a bit lower than one might expect and suggests that each
score must be measuring some independent information about different
characteristics of the students.</p></li>
<li><p>VIFs also do not suggest a major issue with multicollinearity in the
model with the VIFs for both variables the same at 1.278<a href="#fn122" class="footnote-ref" id="fnref122"><sup>122</sup></a>. This suggests that both SEs are about 13% larger than they
otherwise would have been due to shared information between the two
predictor variables. </p></li>
</ul>
<div class="sourceCode" id="cb749"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb749-1" title="1"><span class="kw">vif</span>(gpa1)</a></code></pre></div>
<pre><code>##     SATV     SATM 
## 1.278278 1.278278</code></pre>
<div class="sourceCode" id="cb751"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb751-1" title="1"><span class="kw">sqrt</span>(<span class="kw">vif</span>(gpa1))</a></code></pre></div>
<pre><code>##    SATV    SATM 
## 1.13061 1.13061</code></pre></li>
<li><p><strong>Equal (constant) variance:</strong></p>
<ul>
<li>There is no clear change in variability as a function of fitted
values so no indication of a violation of the constant variance of residuals assumption.</li>
</ul></li>
<li><p><strong>Normality of residuals:</strong></p>
<ul>
<li>There is a minor deviation in the upper tail of the residual
distribution from normality. It is not pushing towards having larger
values than a normal distribution would generate so should not cause us
any real problems with inferences from this model. Note that this upper limit is likely due to using
GPA as a response variable and it has an upper limit. This is an
example of a potentially <strong><em>censored</em></strong> variable. For a continuous
variable it is possible that the range of a measurement scale doesn’t
distinguish among subjects who differ once they pass a certain point.
For example, a 4.0 high school student is likely going to have a high first
year college GPA, on average, but there is no room for variability in
college GPA up, just down once you are at the top of the GPA scale. For students more in the middle of the range,
they can vary up or down. So in some places you can get symmetric
distributions around the mean and in others you cannot. There are
specific statistical models for these types of responses that are
beyond our scope. In this situation, failing to account for the
censoring may push some slopes toward 0 a little because we can’t have
responses over 4.0 in college GPA to work with.</li>
</ul></li>
<li><p><strong>No influential points:</strong></p>
<ul>
<li>There are no influential points. In large data sets, the influence
of any point is decreased and even high leverage and outlying points
can struggle to have any impacts at all on the results.</li>
</ul></li>
</ul></li>
</ol>
<p>So we are fairly comfortable with all the assumptions being at least not clearly
violated and so the inferences from our model should be relatively trustworthy.</p>
<ol start="3" style="list-style-type: decimal">
<li><p>Calculate the test statistics:</p>
<ul>
<li><p>For <em>SATV</em>: <span class="math inline">\(t=\dfrac{0.02539}{0.002859}=8.88\)</span> with <span class="math inline">\(df=997\)</span>.</p></li>
<li><p>For <em>SATM</em>: <span class="math inline">\(t=\dfrac{0.02240}{0.002786}=8.04\)</span> with <span class="math inline">\(df=997\)</span>.</p></li>
</ul></li>
<li><p>Find the p-values:</p>
<ul>
<li><p>For <em>SATV</em>: p-value <span class="math inline">\(&lt;0.0001\)</span></p></li>
<li><p>For <em>SATM</em>: p-value <span class="math inline">\(&lt;0.0001\)</span></p></li>
</ul></li>
<li><p>Decisions:</p>
<ul>
<li><p>For <em>SATV</em>: Reject <span class="math inline">\(H_0\)</span> because there is almost no chance of observing
a test statistic as extreme or more extreme than was observed if there
really were no linear relationship between <em>FYGPA</em> and <em>SATV</em>, in a model
that controls for <em>SATM</em>.</p></li>
<li><p>For <em>SATM</em>: Reject <span class="math inline">\(H_0\)</span> because there is almost no chance of observing
a test statistic as extreme or more extreme than was observed if there
really were no linear relationship between <em>FYGPA</em> and <em>SATM</em>, in a model
that controls for <em>SATV</em>.</p></li>
</ul></li>
<li><p>Conclusions and Scope of Inference:</p>
<ul>
<li><p>For <em>SATV</em>: There is strong evidence to reject the null hypothesis of
no linear relationship between <em>SATV</em> and <em>FYGPA</em> (<span class="math inline">\(t_{997}=8.88\)</span>,
p-value &lt; 0.0001) and conclude that, in
fact, there is a linear relationship between <em>SATV</em> percentile and the
first year of college <em>GPA</em>, after controlling for the <em>SATM</em> percentile,
in the population of students that completed their first year at this
university.</p></li>
<li><p>For <em>SATM</em>: There is strong evidence to reject the null hypothesis of
no linear relationship between <em>SATM</em> and <em>FYGPA</em> (<span class="math inline">\(t_{997}=8.04\)</span>,
p-value &lt; 0.0001)and conclude that, in
fact, there is a linear relationship between <em>SATM</em> percentile and the
first year of college <em>GPA</em>, after controlling for the <em>SATV</em> percentile,
in the population of students that completed their first year at this
university.</p></li>
<li><p>Note that neither inference is causal because there was no random
assignment of SAT percentiles to the subjects. The inferences
are also limited to students who stayed in school long enough to get a
<em>GPA</em> from their first year of college at this university.</p></li>
</ul></li>
</ol>
<p>The model seems to be valid and have predictors with small p-values, but note how much of the variation is not explained by the model. It only explains 21.22%  of the variation in the responses. So we found evidence that these variables are useful in predicting the responses, but are they useful enough to use for decisions on admitting students? By quantifying
the size of the estimated results, we can add to the information about how potentially useful this model might be. The estimated MLR model is</p>
<p><span class="math display">\[\widehat{\text{FYGPA}}_i=0.00737+0.0254\cdot\text{SATV}_i
+0.0224\cdot\text{SATM}_i\ .\]</span></p>
<p>So for a 1 percent increase in the <em>SATV</em> percentile, we expect, on average,
to get a 0.0254 point change in <em>GPA</em>, after controlling for <em>SATM</em> percentile.
Similarly, for a 1 percent increase in the <em>SATM</em> percentile, we expect, on
average, to get a 0.0224 point change in <em>GPA</em>, after controlling for <em>SATV</em>
percentile. While this is a correct interpretation of the slope coefficients,
it is often easier to assess “practical” importance of the results by considering
how much change this implies over the range of observed predictor values.</p>
<p>The term-plots (Figure <a href="7-8-section8-8.html#fig:Figure8-15">1.164</a>) provide a visualization of the
“size” of the differences in the response variable explained by each predictor. 
The <em>SATV</em> term-plot shows that for the range of percentiles from around the
30<sup>th</sup> percentile to the 70<sup>th</sup> percentile, the mean first
year <em>GPA</em> is predicted to go from approximately 1.9 to 3.0. That is a pretty
wide range of differences in GPAs across the range of observed percentiles.
This looks like a pretty interesting and important change in the mean first
year GPA across that range of different SAT percentiles. Similarly, the <em>SATM</em>
term-plot shows that the <em>SATM</em> percentiles were observed to range between
around the 30<sup>th</sup> percentile and 70<sup>th</sup> percentile and
predict mean GPAs between 1.95 and 2.8. It seems that the SAT Verbal
percentiles produce slightly more impacts
in the model, holding the other variable constant, but that both are important
variables. The 95% confidence intervals for the means in both plots suggest
that the results are fairly precisely estimated – there is little variability
around the predicted means in each plot. This is mostly a function of the
sample size as opposed to the model itself explaining most of the variation in the
responses. </p>
<div class="sourceCode" id="cb753"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb753-1" title="1"><span class="kw">plot</span>(<span class="kw">allEffects</span>(gpa1))</a></code></pre></div>
<p>(ref:fig8-15) Term-plots for the <span class="math inline">\(\text{FYGPA}\sim\text{SATV} + \text{SATM}\)</span>
model.</p>
<div class="figure"><span id="fig:Figure8-15"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-15-1.png" alt="(ref:fig8-15)" width="576" />
<p class="caption">
Figure 1.164: (ref:fig8-15)
</p>
</div>
<p>These plots also inform the types of students attending this university and
successfully completing the first year of school. This seems like a good, but
maybe not great, institution with few students scoring over the 75<sup>th</sup>
percentile on either SAT Verbal or Math (at least that ended up in this data
set). This result makes questions about their sampling mechanism re-occur as
to who this data set might actually be representative of…</p>
<p>The confidence intervals also help us pin down the uncertainty in each
estimated slope coefficient. As always, the “easy” way to get 95% confidence
intervals is using the <code>confint</code> function:</p>
<div class="sourceCode" id="cb754"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb754-1" title="1"><span class="kw">confint</span>(gpa1)</a></code></pre></div>
<pre><code>##                   2.5 %     97.5 %
## (Intercept) -0.29147825 0.30622148
## SATV         0.01977864 0.03100106
## SATM         0.01692690 0.02786220</code></pre>
<p>So, for a 1 percent increase in the <em>SATV</em> percentile, we are 95% confident
that the true mean <em>FYGPA</em> changes between 0.0198 and 0.031 points, in the
population of students who completed this year at this institution, after
controlling for <em>SATM</em>. The <em>SATM</em> result is similar with an interval from
0.0169 and 0.0279. Both of these intervals might benefit from re-scaling
the interpretation to, say, a 10 percentile increase in the predictor variable, with
the change in the <em>FYGPA</em> for that level of increase of <em>SATV</em> providing an
interval from 0.198 to 0.31 points and for <em>SATM</em> providing an interval from
0.169 to 0.279. So a boost of 10% in either exam percentile likely results in a
noticeable but not huge average <em>FYGPA</em> increase.</p>
<p>One final use of these methods is to do prediction and generate prediction
intervals, which could be quite informative for a student considering going to
this university who has a particular set of SAT scores. For example, suppose
that the student is interested in the average <em>FYGPA</em> to expect with <em>SATV</em>
at the 30<sup>th</sup> percentile and <em>SATM</em> at the 60<sup>th</sup> percentile.
The predicted mean value is</p>
<p><span class="math display">\[\begin{array}{rl}
\hat{\mu}_{\text{GPA}_i} &amp;= 0.00737 + 0.0254\cdot\text{SATV}_i 
+ 0.0224\cdot\text{SATM}_i \\
&amp;= 0.00737 + 0.0254*30 + 0.0224*60 = 2.113.
\end{array}\]</span></p>
<p>This result and the 95% confidence interval for the mean student <em>GPA</em> at these
scores can be found using the <code>predict</code> function as:</p>
<div class="sourceCode" id="cb756"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb756-1" title="1"><span class="kw">predict</span>(gpa1, <span class="dt">newdata=</span><span class="kw">tibble</span>(<span class="dt">SATV=</span><span class="dv">30</span>,<span class="dt">SATM=</span><span class="dv">60</span>))</a></code></pre></div>
<pre><code>##       1 
## 2.11274</code></pre>
<div class="sourceCode" id="cb758"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb758-1" title="1"><span class="kw">predict</span>(gpa1, <span class="dt">newdata=</span><span class="kw">tibble</span>(<span class="dt">SATV=</span><span class="dv">30</span>,<span class="dt">SATM=</span><span class="dv">60</span>), <span class="dt">interval=</span><span class="st">&quot;confidence&quot;</span>)</a></code></pre></div>
<pre><code>##       fit      lwr      upr
## 1 2.11274 1.982612 2.242868</code></pre>
<p>For students at the 30<sup>th</sup> percentile of <em>SATV</em> and 60<sup>th</sup>
percentile of <em>SATM</em>, we are 95% confident that the true mean first year GPA
is between 1.98 and 2.24 points. For an individual student, we would want the
95% prediction interval:</p>
<div class="sourceCode" id="cb760"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb760-1" title="1"><span class="kw">predict</span>(gpa1,<span class="dt">newdata=</span><span class="kw">tibble</span>(<span class="dt">SATV=</span><span class="dv">30</span>,<span class="dt">SATM=</span><span class="dv">60</span>),<span class="dt">interval=</span><span class="st">&quot;prediction&quot;</span>)</a></code></pre></div>
<pre><code>##       fit       lwr      upr
## 1 2.11274 0.8145859 3.410894</code></pre>
<p>For a student with <em>SATV</em>=30 and <em>SATM</em>=60, we are 95% sure that their first
year GPA will be between 0.81 and 3.4 points. You can see that while we are
very certain about the mean in this situation, there is a lot of uncertainty
in the predictions for individual students. The PI is so wide as to almost
not be useful.</p>
<p>To support this difficulty in getting a precise prediction for a new student,
review the original scatterplots: there is quite a bit of vertical variability
in first year <em>GPA</em>s for each level of any of the predictors. The residual
SE, <span class="math inline">\(\hat{\sigma}\)</span>, is also informative in this regard –
remember that it is the standard deviation of the residuals around the
regression line. It is 0.6582, so the SD of new observations around the line is
0.66 GPA points and that is pretty large on a GPA scale. Remember that if the residuals meet our assumptions and follow a normal distribution around the line, observations within 2 or 3 SDs of the mean would be expected which is a large range of GPA values.
Figure <a href="7-8-section8-8.html#fig:Figure8-16">1.165</a> remakes
both term-plots, holding the other predictor at its mean, and adds the 95%
prediction intervals to show the difference in variability between estimating
the mean and pinning down the value of a new observation. The R code is very messy
and rarely needed, but hopefully this helps reinforce the differences in these
two types of intervals – to make them in MLR, you have to fix all but one of
the predictor variables and we usually do that by fixing the other variables at
their means. </p>
<p>(ref:fig8-16) Term-plots for the <span class="math inline">\(\text{FYGPA}\sim\text{SATV} + \text{SATM}\)</span>
model with 95% confidence intervals (red, dashed lines) and 95% PIs (light grey, dotted lines).</p>
<div class="sourceCode" id="cb762"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb762-1" title="1"><span class="co">#Remake effects plots with 95% PIs</span></a>
<a class="sourceLine" id="cb762-2" title="2">dv1 &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">SATV=</span><span class="kw">seq</span>(<span class="dt">from=</span><span class="dv">24</span>,<span class="dt">to=</span><span class="dv">76</span>,<span class="dt">length.out=</span><span class="dv">50</span>), <span class="dt">SATM=</span><span class="kw">rep</span>(<span class="fl">54.4</span>,<span class="dv">50</span>))</a>
<a class="sourceLine" id="cb762-3" title="3">dm1 &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">SATV=</span><span class="kw">rep</span>(<span class="fl">48.93</span>,<span class="dv">50</span>), <span class="dt">SATM=</span><span class="kw">seq</span>(<span class="dt">from=</span><span class="dv">29</span>,<span class="dt">to=</span><span class="dv">77</span>,<span class="dt">length.out=</span><span class="dv">50</span>))</a>
<a class="sourceLine" id="cb762-4" title="4"></a>
<a class="sourceLine" id="cb762-5" title="5">mv1 &lt;-<span class="st"> </span><span class="kw">as_tibble</span>(<span class="kw">predict</span>(gpa1, <span class="dt">newdata=</span>dv1, <span class="dt">interval=</span><span class="st">&quot;confidence&quot;</span>))</a>
<a class="sourceLine" id="cb762-6" title="6">pv1 &lt;-<span class="st"> </span><span class="kw">as_tibble</span>(<span class="kw">predict</span>(gpa1, <span class="dt">newdata=</span>dv1, <span class="dt">interval=</span><span class="st">&quot;prediction&quot;</span>))</a>
<a class="sourceLine" id="cb762-7" title="7"></a>
<a class="sourceLine" id="cb762-8" title="8">mm1 &lt;-<span class="st"> </span><span class="kw">as_tibble</span>(<span class="kw">predict</span>(gpa1, <span class="dt">newdata=</span>dm1, <span class="dt">interval=</span><span class="st">&quot;confidence&quot;</span>))</a>
<a class="sourceLine" id="cb762-9" title="9">pm1 &lt;-<span class="st"> </span><span class="kw">as_tibble</span>(<span class="kw">predict</span>(gpa1, <span class="dt">newdata=</span>dm1, <span class="dt">interval=</span><span class="st">&quot;prediction&quot;</span>))</a>
<a class="sourceLine" id="cb762-10" title="10"></a>
<a class="sourceLine" id="cb762-11" title="11"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb762-12" title="12"></a>
<a class="sourceLine" id="cb762-13" title="13"><span class="kw">plot</span>(dv1<span class="op">$</span>SATV, mv1<span class="op">$</span>fit, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">ylim=</span><span class="kw">c</span>(pv1<span class="op">$</span>lwr[<span class="dv">1</span>],pv1<span class="op">$</span>upr[<span class="dv">50</span>]), <span class="dt">type=</span><span class="st">&quot;l&quot;</span>,</a>
<a class="sourceLine" id="cb762-14" title="14">     <span class="dt">xlab=</span><span class="st">&quot;SATV Percentile&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;GPA&quot;</span>, <span class="dt">main=</span><span class="st">&quot;SATV Effect, CI and PI&quot;</span>)</a>
<a class="sourceLine" id="cb762-15" title="15"><span class="kw">lines</span>(dv1<span class="op">$</span>SATV, mv1<span class="op">$</span>lwr, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">lwd=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb762-16" title="16"><span class="kw">lines</span>(dv1<span class="op">$</span>SATV, mv1<span class="op">$</span>upr, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">lwd=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb762-17" title="17"><span class="kw">lines</span>(dv1<span class="op">$</span>SATV, pv1<span class="op">$</span>lwr, <span class="dt">col=</span><span class="st">&quot;grey&quot;</span>, <span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">lwd=</span><span class="dv">3</span>)</a>
<a class="sourceLine" id="cb762-18" title="18"><span class="kw">lines</span>(dv1<span class="op">$</span>SATV, pv1<span class="op">$</span>upr, <span class="dt">col=</span><span class="st">&quot;grey&quot;</span>, <span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">lwd=</span><span class="dv">3</span>)</a>
<a class="sourceLine" id="cb762-19" title="19"><span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="kw">c</span>(<span class="st">&quot;Estimate&quot;</span>, <span class="st">&quot;CI&quot;</span>,<span class="st">&quot;PI&quot;</span>), <span class="dt">lwd=</span><span class="dv">3</span>, <span class="dt">lty=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>),</a>
<a class="sourceLine" id="cb762-20" title="20">       <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;red&quot;</span>,<span class="st">&quot;grey&quot;</span>))</a>
<a class="sourceLine" id="cb762-21" title="21"></a>
<a class="sourceLine" id="cb762-22" title="22"><span class="kw">plot</span>(dm1<span class="op">$</span>SATM, mm1<span class="op">$</span>fit, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">ylim=</span><span class="kw">c</span>(pm1<span class="op">$</span>lwr[<span class="dv">1</span>],pm1<span class="op">$</span>upr[<span class="dv">50</span>]), <span class="dt">type=</span><span class="st">&quot;l&quot;</span>,</a>
<a class="sourceLine" id="cb762-23" title="23">     <span class="dt">xlab=</span><span class="st">&quot;SATM Percentile&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;GPA&quot;</span>, <span class="dt">main=</span><span class="st">&quot;SATM Effect, CI and PI&quot;</span>)</a>
<a class="sourceLine" id="cb762-24" title="24"><span class="kw">lines</span>(dm1<span class="op">$</span>SATM, mm1<span class="op">$</span>lwr, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">lwd=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb762-25" title="25"><span class="kw">lines</span>(dm1<span class="op">$</span>SATM, mm1<span class="op">$</span>upr, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">lwd=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb762-26" title="26"><span class="kw">lines</span>(dm1<span class="op">$</span>SATM, pm1<span class="op">$</span>lwr, <span class="dt">col=</span><span class="st">&quot;grey&quot;</span>, <span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">lwd=</span><span class="dv">3</span>)</a>
<a class="sourceLine" id="cb762-27" title="27"><span class="kw">lines</span>(dm1<span class="op">$</span>SATM, pm1<span class="op">$</span>upr, <span class="dt">col=</span><span class="st">&quot;grey&quot;</span>, <span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">lwd=</span><span class="dv">3</span>)</a></code></pre></div>
<div class="figure"><span id="fig:Figure8-16"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-16-1.png" alt="(ref:fig8-16)" width="960" />
<p class="caption">
Figure 1.165: (ref:fig8-16)
</p>
</div>

</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-R-openintro">
<p>Diez, David M, Christopher D Barr, and Mine Cetinkaya-Rundel. 2017. <em>Openintro: Data Sets and Supplemental Functions from ’Openintro’ Textbooks</em>. <a href="https://CRAN.R-project.org/package=openintro">https://CRAN.R-project.org/package=openintro</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="121">
<li id="fn121"><p>Either
someone had a weighted GPA with bonus points, or more likely here, there
was a coding error in the data set since only one observation was over 4.0 in
the GPA data. Either way, we could remove it and note that our inferences for
HSGPA do not extend above 4.0.<a href="7-8-section8-8.html#fnref121" class="footnote-back">↩</a></p></li>
<li id="fn122"><p>When there
are just two predictors, the VIFs have to be the same since the
proportion of information shared is the same in both directions. With
more than two predictors, each variable can have a different VIF
value.<a href="7-8-section8-8.html#fnref122" class="footnote-back">↩</a></p></li>
</ol>
</div>
<p style="text-align: center;">
<a href="7-7-section8-7.html"><button class="btn btn-default">Previous</button></a>
<a href="7-9-section8-9.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
