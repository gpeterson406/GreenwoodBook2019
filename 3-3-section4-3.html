<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="3.3 Two-Way ANOVA models and hypothesis tests | Intermediate Statistics with R" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="gpeterson406/Greenwood_Book" />

<meta name="author" content="Mark C Greenwood" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="3.3 Two-Way ANOVA models and hypothesis tests | Intermediate Statistics with R">

<title>3.3 Two-Way ANOVA models and hypothesis tests | Intermediate Statistics with R</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#cover">Cover</a></li>
<li class="has-sub"><a href="acknowledgments.html#acknowledgments">Acknowledgments</a><ul>
<li><a href="0-1-section1-5.html#section1-5"><span class="toc-section-number">0.1</span> Summary of important R code</a></li>
</ul></li>
<li class="has-sub"><a href="1-chapter2.html#chapter2"><span class="toc-section-number">1</span> (R)e-Introduction to statistics</a><ul>
<li><a href="1-1-section2-1.html#section2-1"><span class="toc-section-number">1.1</span> Histograms, boxplots, and density curves</a></li>
<li><a href="1-2-section2-2.html#section2-2"><span class="toc-section-number">1.2</span> Pirate-plots</a></li>
<li><a href="1-3-section2-3.html#section2-3"><span class="toc-section-number">1.3</span> Models, hypotheses, and permutations for the two sample mean situation</a></li>
<li><a href="1-4-section2-4.html#section2-4"><span class="toc-section-number">1.4</span> Permutation testing for the two sample mean situation</a></li>
<li><a href="1-5-section2-5.html#section2-5"><span class="toc-section-number">1.5</span> Hypothesis testing (general)</a></li>
<li><a href="1-6-section2-6.html#section2-6"><span class="toc-section-number">1.6</span> Connecting randomization (nonparametric) and parametric tests</a></li>
<li><a href="1-7-section2-7.html#section2-7"><span class="toc-section-number">1.7</span> Second example of permutation tests</a></li>
<li><a href="1-8-section2-8.html#section2-8"><span class="toc-section-number">1.8</span> Reproducibility Crisis: Moving beyond p &lt; 0.05, publication bias, and multiple testing issues</a></li>
<li><a href="1-9-section2-9.html#section2-9"><span class="toc-section-number">1.9</span> Confidence intervals and bootstrapping</a></li>
<li><a href="1-10-section2-10.html#section2-10"><span class="toc-section-number">1.10</span> Bootstrap confidence intervals for difference in GPAs</a></li>
<li><a href="1-11-section2-11.html#section2-11"><span class="toc-section-number">1.11</span> Chapter summary</a></li>
<li><a href="1-12-section2-12.html#section2-12"><span class="toc-section-number">1.12</span> Summary of important R code</a></li>
<li><a href="1-13-section2-13.html#section2-13"><span class="toc-section-number">1.13</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="2-chapter3.html#chapter3"><span class="toc-section-number">2</span> One-Way ANOVA</a><ul>
<li><a href="2-1-section3-1.html#section3-1"><span class="toc-section-number">2.1</span> Situation</a></li>
<li><a href="2-2-section3-2.html#section3-2"><span class="toc-section-number">2.2</span> Linear model for One-Way ANOVA (cell-means and reference-coding)</a></li>
<li><a href="2-3-section3-3.html#section3-3"><span class="toc-section-number">2.3</span> One-Way ANOVA Sums of Squares, Mean Squares, and F-test</a></li>
<li><a href="2-4-section3-4.html#section3-4"><span class="toc-section-number">2.4</span> ANOVA model diagnostics including QQ-plots</a></li>
<li><a href="2-5-section3-5.html#section3-5"><span class="toc-section-number">2.5</span> Guinea pig tooth growth One-Way ANOVA example</a></li>
<li><a href="2-6-section3-6.html#section3-6"><span class="toc-section-number">2.6</span> Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display</a></li>
<li><a href="2-7-section3-7.html#section3-7"><span class="toc-section-number">2.7</span> Pair-wise comparisons for the Overtake data</a></li>
<li><a href="2-8-section3-8.html#section3-8"><span class="toc-section-number">2.8</span> Chapter summary</a></li>
<li><a href="2-9-section3-9.html#section3-9"><span class="toc-section-number">2.9</span> Summary of important R code</a></li>
<li><a href="2-10-section3-10.html#section3-10"><span class="toc-section-number">2.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="3-chapter4.html#chapter4"><span class="toc-section-number">3</span> Two-Way ANOVA</a><ul>
<li><a href="3-1-section4-1.html#section4-1"><span class="toc-section-number">3.1</span> Situation</a></li>
<li><a href="3-2-section4-2.html#section4-2"><span class="toc-section-number">3.2</span> Designing a two-way experiment and visualizing results</a></li>
<li><a href="3-3-section4-3.html#section4-3"><span class="toc-section-number">3.3</span> Two-Way ANOVA models and hypothesis tests</a></li>
<li><a href="3-4-section4-4.html#section4-4"><span class="toc-section-number">3.4</span> Guinea pig tooth growth analysis with Two-Way ANOVA</a></li>
<li><a href="3-5-section4-5.html#section4-5"><span class="toc-section-number">3.5</span> Observational study example: The Psychology of Debt</a></li>
<li><a href="3-6-section4-6.html#section4-6"><span class="toc-section-number">3.6</span> Pushing Two-Way ANOVA to the limit: Un-replicated designs and Estimability</a></li>
<li><a href="3-7-section4-7.html#section4-7"><span class="toc-section-number">3.7</span> Chapter summary</a></li>
<li><a href="3-8-section4-8.html#section4-8"><span class="toc-section-number">3.8</span> Summary of important R code</a></li>
<li><a href="3-9-section4-9.html#section4-9"><span class="toc-section-number">3.9</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="4-chapter5.html#chapter5"><span class="toc-section-number">4</span> Chi-square tests</a><ul>
<li><a href="4-1-section5-1.html#section5-1"><span class="toc-section-number">4.1</span> Situation, contingency tables, and tableplots</a></li>
<li><a href="4-2-section5-2.html#section5-2"><span class="toc-section-number">4.2</span> Homogeneity test hypotheses</a></li>
<li><a href="4-3-section5-3.html#section5-3"><span class="toc-section-number">4.3</span> Independence test hypotheses</a></li>
<li><a href="4-4-section5-4.html#section5-4"><span class="toc-section-number">4.4</span> Models for R by C tables</a></li>
<li><a href="4-5-section5-5.html#section5-5"><span class="toc-section-number">4.5</span> Permutation tests for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="4-6-section5-6.html#section5-6"><span class="toc-section-number">4.6</span> Chi-square distribution for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="4-7-section5-7.html#section5-7"><span class="toc-section-number">4.7</span> Examining residuals for the source of differences</a></li>
<li><a href="4-8-section5-8.html#section5-8"><span class="toc-section-number">4.8</span> General protocol for <span class="math inline">\(X^2\)</span> tests</a></li>
<li><a href="4-9-section5-9.html#section5-9"><span class="toc-section-number">4.9</span> Political party and voting results: Complete analysis</a></li>
<li><a href="4-10-section5-10.html#section5-10"><span class="toc-section-number">4.10</span> Is cheating and lying related in students?</a></li>
<li><a href="4-11-section5-11.html#section5-11"><span class="toc-section-number">4.11</span> Analyzing a stratified random sample of California schools</a></li>
<li><a href="4-12-section5-12.html#section5-12"><span class="toc-section-number">4.12</span> Chapter summary</a></li>
<li><a href="4-13-section5-13.html#section5-13"><span class="toc-section-number">4.13</span> Summary of important R commands</a></li>
<li><a href="4-14-section5-14.html#section5-14"><span class="toc-section-number">4.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="5-chapter6.html#chapter6"><span class="toc-section-number">5</span> Correlation and Simple Linear Regression</a><ul>
<li><a href="5-1-section6-1.html#section6-1"><span class="toc-section-number">5.1</span> Relationships between two quantitative variables</a></li>
<li><a href="5-2-section6-2.html#section6-2"><span class="toc-section-number">5.2</span> Estimating the correlation coefficient</a></li>
<li><a href="5-3-section6-3.html#section6-3"><span class="toc-section-number">5.3</span> Relationships between variables by groups</a></li>
<li><a href="5-4-section6-4.html#section6-4"><span class="toc-section-number">5.4</span> Inference for the correlation coefficient</a></li>
<li><a href="5-5-section6-5.html#section6-5"><span class="toc-section-number">5.5</span> Are tree diameters related to tree heights?</a></li>
<li><a href="5-6-section6-6.html#section6-6"><span class="toc-section-number">5.6</span> Describing relationships with a regression model</a></li>
<li><a href="5-7-section6-7.html#section6-7"><span class="toc-section-number">5.7</span> Least Squares Estimation</a></li>
<li><a href="5-8-section6-8.html#section6-8"><span class="toc-section-number">5.8</span> Measuring the strength of regressions: R<sup>2</sup></a></li>
<li><a href="5-9-section6-9.html#section6-9"><span class="toc-section-number">5.9</span> Outliers: leverage and influence</a></li>
<li><a href="5-10-section6-10.html#section6-10"><span class="toc-section-number">5.10</span> Residual diagnostics – setting the stage for inference</a></li>
<li><a href="5-11-section6-11.html#section6-11"><span class="toc-section-number">5.11</span> Old Faithful discharge and waiting times</a></li>
<li><a href="5-12-section6-12.html#section6-12"><span class="toc-section-number">5.12</span> Chapter summary</a></li>
<li><a href="5-13-section6-13.html#section6-13"><span class="toc-section-number">5.13</span> Summary of important R code</a></li>
<li><a href="5-14-section6-14.html#section6-14"><span class="toc-section-number">5.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="6-chapter7.html#chapter7"><span class="toc-section-number">6</span> Simple linear regression inference</a><ul>
<li><a href="6-1-section7-1.html#section7-1"><span class="toc-section-number">6.1</span> Model</a></li>
<li><a href="6-2-section7-2.html#section7-2"><span class="toc-section-number">6.2</span> Confidence interval and hypothesis tests for the slope and intercept</a></li>
<li><a href="6-3-section7-3.html#section7-3"><span class="toc-section-number">6.3</span> Bozeman temperature trend</a></li>
<li><a href="6-4-section7-4.html#section7-4"><span class="toc-section-number">6.4</span> Randomization-based inferences for the slope coefficient</a></li>
<li><a href="6-5-section7-5.html#section7-5"><span class="toc-section-number">6.5</span> Transformations part I: Linearizing relationships</a></li>
<li><a href="6-6-section7-6.html#section7-6"><span class="toc-section-number">6.6</span> Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x)</a></li>
<li><a href="6-7-section7-7.html#section7-7"><span class="toc-section-number">6.7</span> Confidence interval for the mean and prediction intervals for a new observation</a></li>
<li><a href="6-8-section7-8.html#section7-8"><span class="toc-section-number">6.8</span> Chapter summary</a></li>
<li><a href="6-9-section7-9.html#section7-9"><span class="toc-section-number">6.9</span> Summary of important R code</a></li>
<li><a href="6-10-section7-10.html#section7-10"><span class="toc-section-number">6.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="7-chapter8.html#chapter8"><span class="toc-section-number">7</span> Multiple linear regression</a><ul>
<li><a href="7-1-section8-1.html#section8-1"><span class="toc-section-number">7.1</span> Going from SLR to MLR</a></li>
<li><a href="7-2-section8-2.html#section8-2"><span class="toc-section-number">7.2</span> Validity conditions in MLR</a></li>
<li><a href="7-3-section8-3.html#section8-3"><span class="toc-section-number">7.3</span> Interpretation of MLR terms</a></li>
<li><a href="7-4-section8-4.html#section8-4"><span class="toc-section-number">7.4</span> Comparing multiple regression models</a></li>
<li><a href="7-5-section8-5.html#section8-5"><span class="toc-section-number">7.5</span> General recommendations for MLR interpretations and VIFs</a></li>
<li><a href="7-6-section8-6.html#section8-6"><span class="toc-section-number">7.6</span> MLR inference: Parameter inferences using the t-distribution</a></li>
<li><a href="7-7-section8-7.html#section8-7"><span class="toc-section-number">7.7</span> Overall F-test in multiple linear regression</a></li>
<li><a href="7-8-section8-8.html#section8-8"><span class="toc-section-number">7.8</span> Case study: First year college GPA and SATs</a></li>
<li><a href="7-9-section8-9.html#section8-9"><span class="toc-section-number">7.9</span> Different intercepts for different groups: MLR with indicator variables</a></li>
<li><a href="7-10-section8-10.html#section8-10"><span class="toc-section-number">7.10</span> Additive MLR with more than two groups: Headache example</a></li>
<li><a href="7-11-section8-11.html#section8-11"><span class="toc-section-number">7.11</span> Different slopes and different intercepts</a></li>
<li><a href="7-12-section8-12.html#section8-12"><span class="toc-section-number">7.12</span> F-tests for MLR models with quantitative and categorical variables and interactions</a></li>
<li><a href="7-13-section8-13.html#section8-13"><span class="toc-section-number">7.13</span> AICs for model selection</a></li>
<li><a href="7-14-section8-14.html#section8-14"><span class="toc-section-number">7.14</span> Case study: Forced expiratory volume model selection using AICs</a></li>
<li><a href="7-15-section8-15.html#section8-15"><span class="toc-section-number">7.15</span> Chapter summary</a></li>
<li><a href="7-16-section8-16.html#section8-16"><span class="toc-section-number">7.16</span> Summary of important R code</a></li>
<li><a href="7-17-section8-17.html#section8-17"><span class="toc-section-number">7.17</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="8-chapter9.html#chapter9"><span class="toc-section-number">8</span> Case studies</a><ul>
<li><a href="8-1-section9-1.html#section9-1"><span class="toc-section-number">8.1</span> Overview of material covered</a></li>
<li><a href="8-2-section9-2.html#section9-2"><span class="toc-section-number">8.2</span> The impact of simulated chronic nitrogen deposition on the biomass and N2-fixation activity of two boreal feather moss–cyanobacteria associations</a></li>
<li><a href="8-3-section9-3.html#section9-3"><span class="toc-section-number">8.3</span> Ants learn to rely on more informative attributes during decision-making</a></li>
<li><a href="8-4-section9-4.html#section9-4"><span class="toc-section-number">8.4</span> Multi-variate models are essential for understanding vertebrate diversification in deep time</a></li>
<li><a href="8-5-section9-5.html#section9-5"><span class="toc-section-number">8.5</span> What do didgeridoos really do about sleepiness?</a></li>
<li><a href="8-6-section9-6.html#section9-6"><span class="toc-section-number">8.6</span> General summary</a></li>
</ul></li>
<li><a href="references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="section4-3" class="section level2">
<h2><span class="header-section-number">3.3</span> Two-Way ANOVA models and hypothesis tests</h2>
<p>To assess interactions with two
variables, we need to fully describe models for the additive and interaction
scenarios and then develop a method for assessing evidence of the need for
different aspects of the models. First, we need to define the notation for
these models:</p>
<ul>
<li><p><span class="math inline">\(y_{ijk}\)</span> is the <span class="math inline">\(i^{th}\)</span> response from the group for level <span class="math inline">\(j\)</span> of factor A
and level <span class="math inline">\(k\)</span> of factor B</p>
<ul>
<li><p><span class="math inline">\(j=1,\ldots,J\)</span>     <span class="math inline">\(J\)</span> is the number of levels of A</p></li>
<li><p><span class="math inline">\(k=1,\ldots,K\)</span>     <span class="math inline">\(K\)</span> is the number of levels of B</p></li>
<li><p><span class="math inline">\(i=1,\ldots,n_{jk}\)</span>     <span class="math inline">\(n_{jk}\)</span> is the sample size for level
<span class="math inline">\(j\)</span> of factor A and level <span class="math inline">\(k\)</span> of factor B</p></li>
<li><p><span class="math inline">\(N=\Sigma_j\Sigma_k n_{jk}\)</span> is the total sample size (sum of the number of
observations across all <span class="math inline">\(JK\)</span> groups)</p></li>
</ul></li>
</ul>
<p>We need to extend our previous discussion of reference-coded models to develop a
Two-Way ANOVA model. We start with the <strong><em>Two-Way ANOVA interaction model</em></strong>:
</p>
<p><span class="math display">\[y_{ijk} = \alpha + \tau_j + \gamma_k + \omega_{jk} + \varepsilon_{ijk},\]</span></p>
<p>where <span class="math inline">\(\alpha\)</span> is the baseline group mean (for level 1 of A <strong>and</strong> level 1 of B),
<span class="math inline">\(\tau_j\)</span> is the deviation for the <strong><em>main effect</em></strong> of A from the baseline
for levels <span class="math inline">\(2,\ldots,J\)</span>, <span class="math inline">\(\gamma_k\)</span> (gamma <span class="math inline">\(k\)</span>) is the deviation for the main
effect of B from the baseline for levels <span class="math inline">\(2,\ldots,K\)</span>, and <span class="math inline">\(\omega_{jk}\)</span>
(omega <span class="math inline">\(jk\)</span>) is the adjustment for the <strong><em>interaction effect</em></strong> for level
<span class="math inline">\(j\)</span> of factor A and level <span class="math inline">\(k\)</span> of factor B for <span class="math inline">\(j=1,\ldots,J\)</span> and <span class="math inline">\(k=1,\ldots,K\)</span>. In this model, <span class="math inline">\(\tau_1\)</span>, <span class="math inline">\(\gamma_1\)</span>, and <span class="math inline">\(\omega_{11}\)</span> are all fixed at 0 because <span class="math inline">\(\alpha\)</span> is the mean for the combination of the baseline levels of both variables and so no adjustments are needed.
As in Chapter <a href="2-chapter3.html#chapter3"><strong>??</strong></a>, R will typically choose the baseline categories
alphabetically but now it is choosing a baseline for both variables and so our
detective work will be doubled to sort this out.</p>
<p>If the interaction term is not important, usually based on the interaction test
presented below, the <span class="math inline">\(\omega_{jk}\text{&#39;s}\)</span> can be dropped from the model
and we get a model that corresponds to Scenario 4
above. Scenario 4 is where there are two main effects in the model but no interaction
between them. The <strong><em>additive Two-Way model</em></strong> is
</p>
<p><span class="math display">\[y_{ijk} = \alpha + \tau_j + \gamma_k + \varepsilon_{ijk},\]</span></p>
<p>where each component is defined as in the interaction model. The difference between
the interaction and additive models is setting all the <span class="math inline">\(\omega_{jk}\text{&#39;s}\)</span>
to 0 that are present in the interaction model. When we set parameters to 0 in
models it removes them from the model. Setting parameters to 0 is also how we will develop
our hypotheses to test for an interaction, by assessing evidence against a null hypothesis that all <span class="math inline">\(\omega_{jk}\text{&#39;s}=0\)</span>.</p>
<p>The interaction test hypotheses are</p>
<ul>
<li><p><span class="math inline">\(H_0\)</span>: No interaction between A and B on response in population <span class="math inline">\(\Leftrightarrow\)</span> All
<span class="math inline">\(\omega_{jk}\text{&#39;s}=0\)</span>.</p></li>
<li><p><span class="math inline">\(H_A\)</span>: Interaction between A and B on response in population <span class="math inline">\(\Leftrightarrow\)</span> At least
one <span class="math inline">\(\omega_{jk}\ne 0\)</span>.</p></li>
</ul>
<p>To perform this test, a new ANOVA <span class="math inline">\(F\)</span>-test is required (presented below) but
there are also hypotheses relating to the main effects of A (<span class="math inline">\(\tau_j\text{&#39;s}\)</span>)
and B (<span class="math inline">\(\gamma_k\text{&#39;s}\)</span>).


If you decide that there is sufficient evidence against the null hypothesis
that no interaction is
present to conclude that one is likely present, then it is dangerous to ignore the interaction and test for the main effects
because important main effects can be masked by interactions (examples later).
It is important to note that, by definition, <strong>both variables matter if an interaction is found to be important</strong> so the main effect tests may not be
very interesting in an interaction model. If the interaction is found
to be important based on the test and so is retained in the model, you should focus
on the interaction model (also called the <strong><em>full model</em></strong>) in order to
understand and describe the form of the interaction among the variables.

</p>
<p>If the interaction test does not return
a small p-value and you decide that you do not have enough evidence against the null hypothesis to suggest that it is needed, it
can be dropped from the model. In this situation, we would re-fit the model and
focus on the results provided by the additive model – performing tests for the
two additive main effects.

For the first, but not last time, we encounter a
model with more than one variable and more than one test of potential interest. In models
with multiple variables at similar levels (here both are main effects), we are
interested in the results for each variable given that the other variable is in
the model. In many situations, including more than one variable in a model
changes the results for the other variable even if those variables do not
interact. The reason for this is more clear in Chapter <a href="7-chapter8.html#chapter8"><strong>??</strong></a> and really only
matters here if we have unbalanced designs, but we need to start adding a short
modifier to our discussions of main effects – they are the results
<em>conditional on</em> or <em>adjusting for</em> or, simply, <em>given</em>, the other variable(s)
in the model. Specifically, the hypotheses for the two main effects are:</p>
<ul>
<li><p>Main effect test for A: </p>
<ul>
<li><p><span class="math inline">\(H_0\)</span>: No differences in means across levels of A in population,
given B in the model</p>
<p><span class="math inline">\(\Leftrightarrow\)</span> All <span class="math inline">\(\tau_j\text{&#39;s} = 0\)</span> in additive model.</p></li>
<li><p><span class="math inline">\(H_A\)</span>: Some difference in means across levels A in population,
given B in the model</p>
<p><span class="math inline">\(\Leftrightarrow\)</span> At least one <span class="math inline">\(\tau_j \ne 0\)</span>, in additive model.</p></li>
</ul></li>
<li><p>Main effect test for B:</p>
<ul>
<li><p><span class="math inline">\(H_0\)</span>: No differences in means across levels of B in population,
given A in the model</p>
<p><span class="math inline">\(\Leftrightarrow\)</span> All <span class="math inline">\(\gamma_k\text{&#39;s} = 0\)</span> in additive model.</p></li>
<li><p><span class="math inline">\(H_A\)</span>: Some difference in means across levels B in population,
given A in the model</p>
<p><span class="math inline">\(\Leftrightarrow\)</span> At least one <span class="math inline">\(\gamma_k \ne 0\)</span>, in additive model.</p></li>
</ul></li>
</ul>
<p>In order to test these effects (interaction in the interaction model and
main effects in the additive model), <span class="math inline">\(F\)</span>-tests are developed using Sums of
Squares, Mean Squares, and degrees of freedom similar to those in
Chapter <a href="2-chapter3.html#chapter3"><strong>??</strong></a>.

We
won’t worry about the details of the sums of squares formulas but you should
remember the sums of squares decomposition, which still applies<a href="#fn73" class="footnote-ref" id="fnref73"><sup>73</sup></a>. 

Table <a href="3-3-section4-3.html#tab:Table4-1">1.5</a>
summarizes the ANOVA results you will obtain for the interaction
model and Table <a href="3-3-section4-3.html#tab:Table4-2">1.6</a> provides the similar general results for the additive
model. As we saw in Chapter <a href="2-chapter3.html#chapter3"><strong>??</strong></a>, the degrees of freedom are the amount of
information that is free to vary at a particular level and that rule generally holds
here. For example, for factor A with <span class="math inline">\(J\)</span> levels, there are <span class="math inline">\(J-1\)</span> parameters that
are free since the baseline is fixed. The residual degrees of freedom for both
models are not as easily explained but have a simple formula. Note that the sum
of the degrees of freedom from the main effects, (interaction if present), and
error need to equal <span class="math inline">\(N-1\)</span>, just like in the One-Way ANOVA table.</p>

<table>
<caption><span id="tab:Table4-1">Table 1.5: </span> Interaction Model ANOVA Table.</caption>
<colgroup>
<col width="18%" />
<col width="19%" />
<col width="22%" />
<col width="24%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"><strong>Source</strong>    </th>
<th align="left"><strong>DF</strong>     </th>
<th align="left"><strong>SS</strong></th>
<th align="left"><strong>MS</strong></th>
<th align="left"><strong>F-statistics</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">A</td>
<td align="left"><span class="math inline">\(J-1\)</span></td>
<td align="left"><span class="math inline">\(\text{SS}_A\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_A=\text{SS}_A/\text{df}_A\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_A/\text{MS}_E\)</span></td>
</tr>
<tr class="even">
<td align="left">B</td>
<td align="left"><span class="math inline">\(K-1\)</span></td>
<td align="left"><span class="math inline">\(\text{SS}_B\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_B=\text{SS}_B/\text{df}_B\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_B/\text{MS}_E\)</span></td>
</tr>
<tr class="odd">
<td align="left">A:B (interaction)</td>
<td align="left"><span class="math inline">\((J-1)(K-1)\)</span></td>
<td align="left"><span class="math inline">\(\text{SS}_{AB}\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_{AB}=\text{SS}_{AB}/\text{df}_{AB}\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_{AB}/\text{MS}_E\)</span></td>
</tr>
<tr class="even">
<td align="left">Error</td>
<td align="left"><span class="math inline">\(N-JK\)</span></td>
<td align="left"><span class="math inline">\(\text{SS}_E\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_E=\text{SS}_E/\text{df}_E\)</span></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left"><b><font
color='red'>Total</font></b></td>
<td align="left"><span class="math inline">\(\color{red}{\mathbf{N-1}}\)</span></td>
<td align="left"><span class="math inline">\(\color{red}{\textbf{SS}_{\textbf{Total}}}\)</span></td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody>
</table>

<table>
<caption><span id="tab:Table4-2">Table 1.6: </span> Additive Model ANOVA Table.</caption>
<colgroup>
<col width="19%" />
<col width="20%" />
<col width="24%" />
<col width="21%" />
<col width="14%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"><strong>Source</strong>    </th>
<th align="left"><strong>DF</strong>     </th>
<th align="left"><strong>SS</strong></th>
<th align="left"><strong>MS</strong></th>
<th align="left"><strong>F-statistics</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">A</td>
<td align="left"><span class="math inline">\(J-1\)</span></td>
<td align="left"><span class="math inline">\(\text{SS}_A\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_A=\text{SS}_A/\text{df}_A\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_A/\text{MS}_E\)</span></td>
</tr>
<tr class="even">
<td align="left">B</td>
<td align="left"><span class="math inline">\(K-1\)</span></td>
<td align="left"><span class="math inline">\(\text{SS}_B\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_B=\text{SS}_B/\text{df}_B\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_B/\text{MS}_E\)</span></td>
</tr>
<tr class="odd">
<td align="left">Error</td>
<td align="left"><span class="math inline">\(N-J-K+1\)</span></td>
<td align="left"><span class="math inline">\(\text{SS}_E\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_E=\text{SS}_E/\text{df}_E\)</span></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left"><b><font
color='red'>Total</font></b></td>
<td align="left"><span class="math inline">\(\color{red}{\mathbf{N-1}}\)</span></td>
<td align="left"><span class="math inline">\(\color{red}{\textbf{SS}_{\textbf{Total}}}\)</span></td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody>
</table>
<p>The mean squares are formed by taking the sums of squares (we’ll let R find those
for us) and dividing by the <span class="math inline">\(df\)</span> in the row.

The <span class="math inline">\(F\)</span>-ratios are found by taking
the mean squares from the row and dividing by the mean squared error (<span class="math inline">\(\text{MS}_E\)</span>).
They follow <span class="math inline">\(F\)</span>-distributions with numerator degrees
of freedom from the row and denominator degrees of freedom from the Error row
(in R output this the <code>Residuals</code> row).


It is possible to develop permutation
tests for these methods but some
technical issues arise in doing permutation tests for interaction model components
so we will not use them here. This means we will have to place even more
emphasis on the data not presenting clear violations of assumptions since we only have the parametric method
available.

</p>
<p>With some basic expectations about the ANOVA tables and <span class="math inline">\(F\)</span>-statistic construction
in mind, we can get to actually estimating the models and exploring the results.

The first example involves the fake paper towel data
displayed in Figure <a href="3-2-section4-2.html#fig:Figure4-1">1.49</a> and <a href="3-2-section4-2.html#fig:Figure4-2">1.50</a>. It appeared
that Scenario 5 was the correct
story since the lines appeared to be non-parallel, but we need to know whether there is
sufficient evidence to suggest that the interaction is “real” and we get that through the
interaction hypothesis test. To fit the interaction model using <code>lm</code>,
the general formulation is <code>lm(y~x1*x2, data=...)</code>. The
order of the variables doesn’t matter as the most important part of the model,
to start with, relates to the interaction of the variables.
</p>
<p>The ANOVA table output
shows the results for the interaction model obtained by running the <code>anova</code>
function on the model called <code>m1</code>.

Specifically, the test that
<span class="math inline">\(H_0: \text{ All } \omega_{jk}\text{&#39;s} = 0\)</span> has a
test statistic of <span class="math inline">\(F(2,24)=1.92\)</span> (in the output from the row with
brands:drops) and a p-value of 0.17. So there is weak evidence against the null hypothesis of no interaction, with a 17% chance we would
observe a difference in the <span class="math inline">\(\omega_{jk}\text{&#39;s}\)</span> like we did or more
extreme if the <span class="math inline">\(\omega_{jk}\text{&#39;s}\)</span> really were all 0. So it seems that the interaction probably is not needed. Note that for the interaction
model components, R presents them with a colon, <code>:</code>, between the variable
names.
</p>
<div class="sourceCode" id="cb323"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb323-1" title="1">m1 &lt;-<span class="st"> </span><span class="kw">lm</span>(responses<span class="op">~</span>brand<span class="op">*</span>drops, <span class="dt">data=</span>pt)</a>
<a class="sourceLine" id="cb323-2" title="2"><span class="kw">anova</span>(m1)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: responses
##             Df Sum Sq Mean Sq F value   Pr(&gt;F)
## brand        1 4.3322  4.3322 10.5192 0.003458
## drops        2 4.8581  2.4290  5.8981 0.008251
## brand:drops  2 1.5801  0.7901  1.9184 0.168695
## Residuals   24 9.8840  0.4118</code></pre>
<p>It is useful to display the estimates from this model and we can utilize
<code>plot(allEffects(MODELNAME))</code> to visualize the results for the terms
in our models. If we turn on the options for <code>grid=T</code>, <code>multiline=T</code>,
and <code>ci.style="bars"</code> we get a useful version of the basic
“effect plot” for Two-Way ANOVA
models with interaction. The results of the estimated interaction model are
displayed in Figure <a href="3-3-section4-3.html#fig:Figure4-7">1.55</a>, which looks very similar to our
previous interaction plot. The only difference is that this comes from model
that assumes equal variance and these plots show 95% confidence intervals
for the means instead of the <span class="math inline">\(\pm\)</span> 1 SE used in the <code>intplot</code> where each SE is calculated using the variance of the observations at each combination of levels. Note that other than the lines connecting the means, this plot also is similar to the pirate-plot in Figure <a href="3-2-section4-2.html#fig:Figure4-1">1.49</a> that also displayed the original responses for each of the six combinations of the two explanatory variables. That plot then provides a place to assess assumptions of the equal variance and distributions for each group as well as explore differences in the group means.
</p>

<div class="sourceCode" id="cb325"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb325-1" title="1"><span class="kw">library</span>(effects)</a>
<a class="sourceLine" id="cb325-2" title="2"><span class="kw">plot</span>(<span class="kw">allEffects</span>(m1), <span class="dt">grid=</span>T, <span class="dt">multiline=</span>T, <span class="dt">lty=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="dt">ci.style=</span><span class="st">&quot;bars&quot;</span>)</a></code></pre></div>
<div class="figure"><span id="fig:Figure4-7"></span>
<img src="04-twoWayAnova_files/figure-html/Figure4-7-1.png" alt="Plot of estimated results of interaction model for the paper towel performance data." width="576" />
<p class="caption">
Figure 1.55: Plot of estimated results of interaction model for the paper towel performance data.
</p>
</div>
<p>In the absence of sufficient evidence to include the
interaction, the model should be simplified to the additive model and the interpretation
focused on each main effect, conditional on having the other variable in the
model. To fit an additive model and not include an interaction, the model
formula involves a “+” instead of a “<code>*</code>” between the explanatory variables.</p>
<div class="sourceCode" id="cb326"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb326-1" title="1">m2 &lt;-<span class="st"> </span><span class="kw">lm</span>(responses<span class="op">~</span>brand<span class="op">+</span>drops, <span class="dt">data=</span>pt)</a></code></pre></div>
<p></p>
<div class="sourceCode" id="cb327"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb327-1" title="1"><span class="kw">anova</span>(m2)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: responses
##           Df  Sum Sq Mean Sq F value   Pr(&gt;F)
## brand      1  4.3322  4.3322  9.8251 0.004236
## drops      2  4.8581  2.4290  5.5089 0.010123
## Residuals 26 11.4641  0.4409</code></pre>
<p>The p-values for the main effects of <code>brand</code> and <code>drops</code> change slightly from the
results in the interaction model due to changes in the <span class="math inline">\(\text{MS}_E\)</span> from
0.4118 to 0.4409 (more variability is left over in the simpler model) and the
<span class="math inline">\(\text{DF}_{\text{error}}\)</span> that increases from 24 to 26. In both models, the
<span class="math inline">\(\text{SS}_{\text{Total}}\)</span> is the same (20.6544). In the interaction model,</p>
<p><span class="math display">\[\begin{array}{rl}
\text{SS}_{\text{Total}} &amp; = \text{SS}_{\text{brand}} + \text{SS}_{\text{drops}}
+ \text{SS}_{\text{brand:drops}} + \text{SS}_{\text{E}}\\
&amp; = 4.3322 + 4.8581 + 1.5801 + 9.8840\\
&amp; = 20.6544.\\
\end{array}\]</span></p>
<p>In the additive model, the variability that was attributed to the interaction term
in the interaction model (<span class="math inline">\(\text{SS}_{\text{brand:drops}} = 1.5801\)</span>) is pushed into the
<span class="math inline">\(\text{SS}_{\text{E}}\)</span>, which increases from 9.884 to 11.4641. The sums of squares
decomposition in the additive model is</p>
<p><span class="math display">\[\begin{array}{rl}
\text{SS}_{\text{Total}} &amp; = \text{SS}_{\text{brand}} + \text{SS}_{\text{drops}}
 + \text{SS}_{\text{E}} \\
&amp; = 4.3322 + 4.8581 + 11.4641 \\
&amp; = 20.6544. \\
\end{array}\]</span></p>
<p>This shows that the sums of squares decomposition applies in these more complicated
models as it did in the One-Way ANOVA.

It also shows that if the interaction is
removed from the model, that variability is lumped in with the other
unexplained variability that goes in the <span class="math inline">\(\text{SS}_{\text{E}}\)</span> in any model.</p>
<p>The fact that the sums of squares decomposition can be applied here is
useful, except that there is a small issue
with the main effect tests in the ANOVA table results that follow this
decomposition when the design is not balanced. It ends up that the tests in a
typical ANOVA table are only conditional on the tests higher up in the table. For
example, in the additive model ANOVA table, the <code>Brand</code> test is not
conditional on the <code>Drops</code> effect, but the <code>Drops</code> effect is conditional on the
<code>Brand</code> effect. In balanced designs, conditioning on the other variable does not change the results but in unbalanced designs, the order does matter. To get both results to be similarly conditional on the other variable, we have to use another type of sums of
squares, called <strong><em>Type II sums of squares</em></strong>.

These sums of squares will no longer always
follow the rules of the sums of squares decomposition but they
will test the desired hypotheses. Specifically, they provide each test
conditional on any other terms at the same level of the model and match the
hypotheses written out earlier in this section. To get the “correct” ANOVA
results, the <code>car</code> (<span class="citation">Fox, Weisberg, and Price (<a href="#ref-R-car" role="doc-biblioref">2019</a>)</span>, <span class="citation">Fox and Weisberg (<a href="#ref-Fox2011" role="doc-biblioref">2011</a>)</span>) package is required. We use the
<code>Anova</code> function on our linear models from here forward to get the “right”
tests in our ANOVA tables<a href="#fn74" class="footnote-ref" id="fnref74"><sup>74</sup></a>.

Note how the case-sensitive nature of R code shows
up in the use of the capital “A” <code>Anova</code> function instead of the lower-case “a” <code>anova</code>
function used previously. In this situation, because the design was balanced, the
results are the same using either function. Observational studies rarely
generate balanced designs (some designed studies can result in unbalanced
designs too) so we will generally just use the Type II version of the sums of
squares to give us the desired results across different data sets we might analyze. The <code>Anova</code> results using the Type II sums of
squares are slightly more conservative than the results from <code>anova</code>,
which are called Type I sums of squares.

The sums of squares decomposition no
longer applies, but it is a small sacrifice to get each test after
adjusting for all other variables<a href="#fn75" class="footnote-ref" id="fnref75"><sup>75</sup></a>.
</p>
<div class="sourceCode" id="cb329"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb329-1" title="1"><span class="kw">library</span>(car)</a>
<a class="sourceLine" id="cb329-2" title="2"><span class="kw">Anova</span>(m2)</a></code></pre></div>
<pre><code>## Anova Table (Type II tests)
## 
## Response: responses
##            Sum Sq Df F value   Pr(&gt;F)
## brand      4.3322  1  9.8251 0.004236
## drops      4.8581  2  5.5089 0.010123
## Residuals 11.4641 26</code></pre>
<p>The new output switches the columns around and doesn’t show you the mean squares,
but gives the most critical parts of the output. Here, there is no change in
results because it is a balanced design with equal counts of responses in each
combination of the two explanatory variables.</p>
<p>The additive model, when appropriate, provides simpler interpretations for
each explanatory variable compared to models
with interactions because the effect of one variable is the same regardless of
the levels of the other variable and vice versa.

There are two tools to aid in
understanding the impacts of the two variables in the additive model. First,
the model summary provides estimated coefficients with interpretations like
those seen in Chapter <a href="2-chapter3.html#chapter3"><strong>??</strong></a> (deviation of group <span class="math inline">\(j\)</span> or <span class="math inline">\(k\)</span> from
the baseline group’s mean), except with the additional wording of
“controlling for” the other variable
added to any of the discussion. Second, the term-plots now show each main
effect and how the groups differ with one panel for each of the two explanatory
variables in the model. These term-plots are created by holding the other
variable constant at one of its levels (the most frequently occurring or first if the there are multiple groups tied for being most frequent) and presenting the estimated means across the levels of the variable in the plot.</p>
<div class="sourceCode" id="cb331"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb331-1" title="1"><span class="kw">summary</span>(m2)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = responses ~ brand + drops, data = pt)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.4561 -0.4587  0.1297  0.4434  0.9695 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)   1.8454     0.2425   7.611 4.45e-08
## brandB2       0.7600     0.2425   3.134  0.00424
## drops20      -0.4680     0.2970  -1.576  0.12715
## drops30      -0.9853     0.2970  -3.318  0.00269
## 
## Residual standard error: 0.664 on 26 degrees of freedom
## Multiple R-squared:  0.445,  Adjusted R-squared:  0.3809 
## F-statistic: 6.948 on 3 and 26 DF,  p-value: 0.001381</code></pre>
<p>In the model summary, the baseline combination estimated in the <code>(Intercept)</code>
row is for <code>Brand</code> <em>B1</em> and <code>Drops</code> 10 and estimates the mean failure
time as 1.85 seconds for this combination. As
before, the group labels that do not show up are the baseline but there are two
variables’ baselines to identify. Now the “simple” aspects of the additive
model show up. The interpretation of the <code>Brands</code> <em>B2</em> coefficient is as
a deviation from the baseline but it applies regardless of the level of
<code>Drops</code>. Any difference between <em>B1</em> and <em>B2</em> involves a shift up of 0.76 seconds
in the estimated mean failure time. Similarly, going from 10 (baseline) to 20
drops results in a drop in the estimated failure mean of 0.47 seconds and going
from 10 to 30 drops results in a drop of almost 1 second in the average time to
failure, both estimated changes are the same regardless of the brand of paper
towel being considered. Sometimes, especially in observational studies, we use
the terminology “controlled for” to remind the reader that the other variable
was present in the model<a href="#fn76" class="footnote-ref" id="fnref76"><sup>76</sup></a> and also explained some of the variability in the
responses. The term-plots for
the additive model (Figure <a href="3-3-section4-3.html#fig:Figure4-8">1.56</a>) help us visualize the
impacts of changes brand and changing water levels, holding the other
variable constant. The differences in heights in each panel correspond
to the coefficients just discussed.</p>
<p>(ref:fig4-8) Term-plots of additive model for paper towel data. Left panel displays
results for two brands and right panel for number of drops of water, each after
controlling for the other.</p>
<div class="sourceCode" id="cb333"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb333-1" title="1"><span class="kw">require</span>(effects)</a>
<a class="sourceLine" id="cb333-2" title="2"><span class="kw">plot</span>(<span class="kw">allEffects</span>(m2))</a></code></pre></div>
<div class="figure"><span id="fig:Figure4-8"></span>
<img src="04-twoWayAnova_files/figure-html/Figure4-8-1.png" alt="(ref:fig4-8)" width="480" />
<p class="caption">
Figure 1.56: (ref:fig4-8)
</p>
</div>
<p>With the first additive model we have considered, it is now the first time where we are working with a model where we can’t display the observations together with the means that the model is producing because the results for each predictor are averaged across the levels of the other predictor. To visualize some aspects of the original observations with the estimates from each group, we can turn on an option in the term-plots (<code>residuals=T</code>) to obtain the <strong><em>partial residuals</em></strong>  that show the residuals as a function of one variable after adjusting for the effects of other variables. We will avoid the specifics of the calculations, but you can use these to explore the residuals at different levels of each predictor. They will be most useful in the Chapters <a href="6-chapter7.html#chapter7"><strong>??</strong></a> and <a href="7-chapter8.html#chapter8"><strong>??</strong></a> but give us some insights in unexplained variation in each level of the predictors once we remove the impacts of other predictors in the model. Use plots like Figure <a href="3-3-section4-3.html#fig:Figure4-9">1.57</a> to look for different variability at different levels of the predictors and possibly locations of outliers in these models. Note that the points (open circles) are jittered to aid in seeing all of them, the means of each group of residuals are indicated by a filled large circle, and the smaller circles in the center of the bars for the 95% confidence intervals are the means from the model. Term-plots with partial residuals accompany our regular diagnostic plots for assessing equal variance assumptions in these models – in some cases adding the residuals will clutter the term-plots so much that reporting them is not useful since one of the main purposes of the term-plots is to visualize the model estimates. So use the <code>residuals=T</code> option judiciously.</p>

<div class="sourceCode" id="cb334"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb334-1" title="1"><span class="kw">require</span>(effects)</a>
<a class="sourceLine" id="cb334-2" title="2"><span class="kw">plot</span>(<span class="kw">allEffects</span>(m2, <span class="dt">residuals =</span> T))</a></code></pre></div>
<div class="figure"><span id="fig:Figure4-9"></span>
<img src="04-twoWayAnova_files/figure-html/Figure4-9-1.png" alt="Term-plots of additive model for paper towel data with partial residuals added. Relatively similar variability seems to be present in each of the groups of residuals after adjusting for the other variable except for the residuals for the 10 drops where the variability is smaller, especially if one small outlier is ignored." width="480" />
<p class="caption">
Figure 1.57: Term-plots of additive model for paper towel data with partial residuals added. Relatively similar variability seems to be present in each of the groups of residuals after adjusting for the other variable except for the residuals for the 10 drops where the variability is smaller, especially if one small outlier is ignored.
</p>
</div>
<p>For the One-Way and Two-Way interaction models, the partial residuals are just the original observations so present similar information as the pirate-plots but do show the model estimated 95% confidence intervals. With interaction models, you can use the default the settings in <code>effects</code> when adding in the partial residuals as seen below in Figure XXX.</p>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Fox2011">
<p>Fox, John, and Sanford Weisberg. 2011. <em>An R-Companion to Applied Regression, Second Edition</em>. Thousand Oaks, CA: SAGE Publications. <a href="http://socserv.socsci.mcmaster.ca/jfox/Books/Companion">http://socserv.socsci.mcmaster.ca/jfox/Books/Companion</a>.</p>
</div>
<div id="ref-R-car">
<p>Fox, John, Sanford Weisberg, and Brad Price. 2019. <em>Car: Companion to Applied Regression</em>. <a href="https://CRAN.R-project.org/package=car">https://CRAN.R-project.org/package=car</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="73">
<li id="fn73"><p>In the standard
ANOVA table,
<span class="math inline">\(\text{SS}_A + \text{SS}_B + \text{SS}_{AB} + \text{SS}_E = \text{SS}_{\text{Total}}\)</span>.
However, to get the tests we really desire when our designs are not balanced, a
slight modification of the SS is used, using what are called Type II sums of
squares and this result doesn’t hold in the output you will see for additive
models. This is discussed further below.<a href="3-3-section4-3.html#fnref73" class="footnote-back">↩</a></p></li>
<li id="fn74"><p>The <code>anova</code> results are not wrong, just not what we want in all situations.<a href="3-3-section4-3.html#fnref74" class="footnote-back">↩</a></p></li>
<li id="fn75"><p>Actually, the tests are only conditional
on other main effects if Type II Sums of Squares are used for an interaction
model, but we rarely focus on the main effect tests when the interaction is present.<a href="3-3-section4-3.html#fnref75" class="footnote-back">↩</a></p></li>
<li id="fn76"><p>In Multiple Linear Regression models in
Chapter <a href="7-chapter8.html#chapter8"><strong>??</strong></a>, the reasons for this wording will (hopefully)
become clearer.<a href="3-3-section4-3.html#fnref76" class="footnote-back">↩</a></p></li>
</ol>
</div>
<p style="text-align: center;">
<a href="3-2-section4-2.html"><button class="btn btn-default">Previous</button></a>
<a href="3-4-section4-4.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
