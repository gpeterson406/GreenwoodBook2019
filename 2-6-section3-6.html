<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="2.6 Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display | Intermediate Statistics with R" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="gpeterson406/Greenwood_Book" />

<meta name="author" content="Mark C Greenwood" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="2.6 Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display | Intermediate Statistics with R">

<title>2.6 Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display | Intermediate Statistics with R</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#cover">Cover</a></li>
<li class="has-sub"><a href="acknowledgments.html#acknowledgments">Acknowledgments</a><ul>
<li><a href="0-1-section1-5.html#section1-5"><span class="toc-section-number">0.1</span> Summary of important R code</a></li>
</ul></li>
<li class="has-sub"><a href="1-chapter2.html#chapter2"><span class="toc-section-number">1</span> (R)e-Introduction to statistics</a><ul>
<li><a href="1-1-section2-1.html#section2-1"><span class="toc-section-number">1.1</span> Histograms, boxplots, and density curves</a></li>
<li><a href="1-2-section2-2.html#section2-2"><span class="toc-section-number">1.2</span> Pirate-plots</a></li>
<li><a href="1-3-section2-3.html#section2-3"><span class="toc-section-number">1.3</span> Models, hypotheses, and permutations for the two sample mean situation</a></li>
<li><a href="1-4-section2-4.html#section2-4"><span class="toc-section-number">1.4</span> Permutation testing for the two sample mean situation</a></li>
<li><a href="1-5-section2-5.html#section2-5"><span class="toc-section-number">1.5</span> Hypothesis testing (general)</a></li>
<li><a href="1-6-section2-6.html#section2-6"><span class="toc-section-number">1.6</span> Connecting randomization (nonparametric) and parametric tests</a></li>
<li><a href="1-7-section2-7.html#section2-7"><span class="toc-section-number">1.7</span> Second example of permutation tests</a></li>
<li><a href="1-8-section2-8.html#section2-8"><span class="toc-section-number">1.8</span> Reproducibility Crisis: Moving beyond p &lt; 0.05, publication bias, and multiple testing issues</a></li>
<li><a href="1-9-section2-9.html#section2-9"><span class="toc-section-number">1.9</span> Confidence intervals and bootstrapping</a></li>
<li><a href="1-10-section2-10.html#section2-10"><span class="toc-section-number">1.10</span> Bootstrap confidence intervals for difference in GPAs</a></li>
<li><a href="1-11-section2-11.html#section2-11"><span class="toc-section-number">1.11</span> Chapter summary</a></li>
<li><a href="1-12-section2-12.html#section2-12"><span class="toc-section-number">1.12</span> Summary of important R code</a></li>
<li><a href="1-13-section2-13.html#section2-13"><span class="toc-section-number">1.13</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="2-chapter3.html#chapter3"><span class="toc-section-number">2</span> One-Way ANOVA</a><ul>
<li><a href="2-1-section3-1.html#section3-1"><span class="toc-section-number">2.1</span> Situation</a></li>
<li><a href="2-2-section3-2.html#section3-2"><span class="toc-section-number">2.2</span> Linear model for One-Way ANOVA (cell-means and reference-coding)</a></li>
<li><a href="2-3-section3-3.html#section3-3"><span class="toc-section-number">2.3</span> One-Way ANOVA Sums of Squares, Mean Squares, and F-test</a></li>
<li><a href="2-4-section3-4.html#section3-4"><span class="toc-section-number">2.4</span> ANOVA model diagnostics including QQ-plots</a></li>
<li><a href="2-5-section3-5.html#section3-5"><span class="toc-section-number">2.5</span> Guinea pig tooth growth One-Way ANOVA example</a></li>
<li><a href="2-6-section3-6.html#section3-6"><span class="toc-section-number">2.6</span> Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display</a></li>
<li><a href="2-7-section3-7.html#section3-7"><span class="toc-section-number">2.7</span> Pair-wise comparisons for the Overtake data</a></li>
<li><a href="2-8-section3-8.html#section3-8"><span class="toc-section-number">2.8</span> Chapter summary</a></li>
<li><a href="2-9-section3-9.html#section3-9"><span class="toc-section-number">2.9</span> Summary of important R code</a></li>
<li><a href="2-10-section3-10.html#section3-10"><span class="toc-section-number">2.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="3-chapter4.html#chapter4"><span class="toc-section-number">3</span> Two-Way ANOVA</a><ul>
<li><a href="3-1-section4-1.html#section4-1"><span class="toc-section-number">3.1</span> Situation</a></li>
<li><a href="3-2-section4-2.html#section4-2"><span class="toc-section-number">3.2</span> Designing a two-way experiment and visualizing results</a></li>
<li><a href="3-3-section4-3.html#section4-3"><span class="toc-section-number">3.3</span> Two-Way ANOVA models and hypothesis tests</a></li>
<li><a href="3-4-section4-4.html#section4-4"><span class="toc-section-number">3.4</span> Guinea pig tooth growth analysis with Two-Way ANOVA</a></li>
<li><a href="3-5-section4-5.html#section4-5"><span class="toc-section-number">3.5</span> Observational study example: The Psychology of Debt</a></li>
<li><a href="3-6-section4-6.html#section4-6"><span class="toc-section-number">3.6</span> Pushing Two-Way ANOVA to the limit: Un-replicated designs and Estimability</a></li>
<li><a href="3-7-section4-7.html#section4-7"><span class="toc-section-number">3.7</span> Chapter summary</a></li>
<li><a href="3-8-section4-8.html#section4-8"><span class="toc-section-number">3.8</span> Summary of important R code</a></li>
<li><a href="3-9-section4-9.html#section4-9"><span class="toc-section-number">3.9</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="4-chapter5.html#chapter5"><span class="toc-section-number">4</span> Chi-square tests</a><ul>
<li><a href="4-1-section5-1.html#section5-1"><span class="toc-section-number">4.1</span> Situation, contingency tables, and tableplots</a></li>
<li><a href="4-2-section5-2.html#section5-2"><span class="toc-section-number">4.2</span> Homogeneity test hypotheses</a></li>
<li><a href="4-3-section5-3.html#section5-3"><span class="toc-section-number">4.3</span> Independence test hypotheses</a></li>
<li><a href="4-4-section5-4.html#section5-4"><span class="toc-section-number">4.4</span> Models for R by C tables</a></li>
<li><a href="4-5-section5-5.html#section5-5"><span class="toc-section-number">4.5</span> Permutation tests for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="4-6-section5-6.html#section5-6"><span class="toc-section-number">4.6</span> Chi-square distribution for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="4-7-section5-7.html#section5-7"><span class="toc-section-number">4.7</span> Examining residuals for the source of differences</a></li>
<li><a href="4-8-section5-8.html#section5-8"><span class="toc-section-number">4.8</span> General protocol for <span class="math inline">\(X^2\)</span> tests</a></li>
<li><a href="4-9-section5-9.html#section5-9"><span class="toc-section-number">4.9</span> Political party and voting results: Complete analysis</a></li>
<li><a href="4-10-section5-10.html#section5-10"><span class="toc-section-number">4.10</span> Is cheating and lying related in students?</a></li>
<li><a href="4-11-section5-11.html#section5-11"><span class="toc-section-number">4.11</span> Analyzing a stratified random sample of California schools</a></li>
<li><a href="4-12-section5-12.html#section5-12"><span class="toc-section-number">4.12</span> Chapter summary</a></li>
<li><a href="4-13-section5-13.html#section5-13"><span class="toc-section-number">4.13</span> Summary of important R commands</a></li>
<li><a href="4-14-section5-14.html#section5-14"><span class="toc-section-number">4.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="5-chapter6.html#chapter6"><span class="toc-section-number">5</span> Correlation and Simple Linear Regression</a><ul>
<li><a href="5-1-section6-1.html#section6-1"><span class="toc-section-number">5.1</span> Relationships between two quantitative variables</a></li>
<li><a href="5-2-section6-2.html#section6-2"><span class="toc-section-number">5.2</span> Estimating the correlation coefficient</a></li>
<li><a href="5-3-section6-3.html#section6-3"><span class="toc-section-number">5.3</span> Relationships between variables by groups</a></li>
<li><a href="5-4-section6-4.html#section6-4"><span class="toc-section-number">5.4</span> Inference for the correlation coefficient</a></li>
<li><a href="5-5-section6-5.html#section6-5"><span class="toc-section-number">5.5</span> Are tree diameters related to tree heights?</a></li>
<li><a href="5-6-section6-6.html#section6-6"><span class="toc-section-number">5.6</span> Describing relationships with a regression model</a></li>
<li><a href="5-7-section6-7.html#section6-7"><span class="toc-section-number">5.7</span> Least Squares Estimation</a></li>
<li><a href="5-8-section6-8.html#section6-8"><span class="toc-section-number">5.8</span> Measuring the strength of regressions: R<sup>2</sup></a></li>
<li><a href="5-9-section6-9.html#section6-9"><span class="toc-section-number">5.9</span> Outliers: leverage and influence</a></li>
<li><a href="5-10-section6-10.html#section6-10"><span class="toc-section-number">5.10</span> Residual diagnostics – setting the stage for inference</a></li>
<li><a href="5-11-section6-11.html#section6-11"><span class="toc-section-number">5.11</span> Old Faithful discharge and waiting times</a></li>
<li><a href="5-12-section6-12.html#section6-12"><span class="toc-section-number">5.12</span> Chapter summary</a></li>
<li><a href="5-13-section6-13.html#section6-13"><span class="toc-section-number">5.13</span> Summary of important R code</a></li>
<li><a href="5-14-section6-14.html#section6-14"><span class="toc-section-number">5.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="6-chapter7.html#chapter7"><span class="toc-section-number">6</span> Simple linear regression inference</a><ul>
<li><a href="6-1-section7-1.html#section7-1"><span class="toc-section-number">6.1</span> Model</a></li>
<li><a href="6-2-section7-2.html#section7-2"><span class="toc-section-number">6.2</span> Confidence interval and hypothesis tests for the slope and intercept</a></li>
<li><a href="6-3-section7-3.html#section7-3"><span class="toc-section-number">6.3</span> Bozeman temperature trend</a></li>
<li><a href="6-4-section7-4.html#section7-4"><span class="toc-section-number">6.4</span> Randomization-based inferences for the slope coefficient</a></li>
<li><a href="6-5-section7-5.html#section7-5"><span class="toc-section-number">6.5</span> Transformations part I: Linearizing relationships</a></li>
<li><a href="6-6-section7-6.html#section7-6"><span class="toc-section-number">6.6</span> Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x)</a></li>
<li><a href="6-7-section7-7.html#section7-7"><span class="toc-section-number">6.7</span> Confidence interval for the mean and prediction intervals for a new observation</a></li>
<li><a href="6-8-section7-8.html#section7-8"><span class="toc-section-number">6.8</span> Chapter summary</a></li>
<li><a href="6-9-section7-9.html#section7-9"><span class="toc-section-number">6.9</span> Summary of important R code</a></li>
<li><a href="6-10-section7-10.html#section7-10"><span class="toc-section-number">6.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="7-chapter8.html#chapter8"><span class="toc-section-number">7</span> Multiple linear regression</a><ul>
<li><a href="7-1-section8-1.html#section8-1"><span class="toc-section-number">7.1</span> Going from SLR to MLR</a></li>
<li><a href="7-2-section8-2.html#section8-2"><span class="toc-section-number">7.2</span> Validity conditions in MLR</a></li>
<li><a href="7-3-section8-3.html#section8-3"><span class="toc-section-number">7.3</span> Interpretation of MLR terms</a></li>
<li><a href="7-4-section8-4.html#section8-4"><span class="toc-section-number">7.4</span> Comparing multiple regression models</a></li>
<li><a href="7-5-section8-5.html#section8-5"><span class="toc-section-number">7.5</span> General recommendations for MLR interpretations and VIFs</a></li>
<li><a href="7-6-section8-6.html#section8-6"><span class="toc-section-number">7.6</span> MLR inference: Parameter inferences using the t-distribution</a></li>
<li><a href="7-7-section8-7.html#section8-7"><span class="toc-section-number">7.7</span> Overall F-test in multiple linear regression</a></li>
<li><a href="7-8-section8-8.html#section8-8"><span class="toc-section-number">7.8</span> Case study: First year college GPA and SATs</a></li>
<li><a href="7-9-section8-9.html#section8-9"><span class="toc-section-number">7.9</span> Different intercepts for different groups: MLR with indicator variables</a></li>
<li><a href="7-10-section8-10.html#section8-10"><span class="toc-section-number">7.10</span> Additive MLR with more than two groups: Headache example</a></li>
<li><a href="7-11-section8-11.html#section8-11"><span class="toc-section-number">7.11</span> Different slopes and different intercepts</a></li>
<li><a href="7-12-section8-12.html#section8-12"><span class="toc-section-number">7.12</span> F-tests for MLR models with quantitative and categorical variables and interactions</a></li>
<li><a href="7-13-section8-13.html#section8-13"><span class="toc-section-number">7.13</span> AICs for model selection</a></li>
<li><a href="7-14-section8-14.html#section8-14"><span class="toc-section-number">7.14</span> Case study: Forced expiratory volume model selection using AICs</a></li>
<li><a href="7-15-section8-15.html#section8-15"><span class="toc-section-number">7.15</span> Chapter summary</a></li>
<li><a href="7-16-section8-16.html#section8-16"><span class="toc-section-number">7.16</span> Summary of important R code</a></li>
<li><a href="7-17-section8-17.html#section8-17"><span class="toc-section-number">7.17</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="8-chapter9.html#chapter9"><span class="toc-section-number">8</span> Case studies</a><ul>
<li><a href="8-1-section9-1.html#section9-1"><span class="toc-section-number">8.1</span> Overview of material covered</a></li>
<li><a href="8-2-section9-2.html#section9-2"><span class="toc-section-number">8.2</span> The impact of simulated chronic nitrogen deposition on the biomass and N2-fixation activity of two boreal feather moss–cyanobacteria associations</a></li>
<li><a href="8-3-section9-3.html#section9-3"><span class="toc-section-number">8.3</span> Ants learn to rely on more informative attributes during decision-making</a></li>
<li><a href="8-4-section9-4.html#section9-4"><span class="toc-section-number">8.4</span> Multi-variate models are essential for understanding vertebrate diversification in deep time</a></li>
<li><a href="8-5-section9-5.html#section9-5"><span class="toc-section-number">8.5</span> What do didgeridoos really do about sleepiness?</a></li>
<li><a href="8-6-section9-6.html#section9-6"><span class="toc-section-number">8.6</span> General summary</a></li>
</ul></li>
<li><a href="references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="section3-6" class="section level2">
<h2><span class="header-section-number">2.6</span> Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display</h2>

<p>With evidence that the true means are likely not all equal, many researchers
want to explore which groups show evidence of differing from one another. This
provides information on the source of the overall difference that was
detected and detailed information on which groups differed from one another.
Because this is a shot-gun/unfocused sort of approach, some people think it
is an over-used procedure. Others feel that
it is an important method of addressing detailed questions about group
comparisons in a valid and safe way. For example, we might want to know if OJ is
different from VC <em>at the 0.5 mg/day</em> dosage level and these methods will allow
us to get an answer to this sort of question.
It also will test for differences between the OJ.0.5 and VC.2 groups
and every other pair of levels that you can construct (15 total!). This method actually
takes us back to the methods in Chapter <a href="1-chapter2.html#chapter2">1</a> where we compared the means of two
groups except that we need to deal with potentially many pair-wise comparisons,
making an adjustment to account for that inflation in Type I errors

that occurs due to many tests being performed at the same time. A commonly used method to make all the pair-wise comparisons that includes a correction for doing this is called <strong><em>Tukey’s Honest Significant Difference</em></strong> (Tukey’s HSD) 
method<a href="#fn64" class="footnote-ref" id="fnref64"><sup>64</sup></a>. The name suggests that not using it could lead to a
dishonest answer and that it will give you an honest result. It is more that if you don’t
do some sort of correction for all the tests you are performing, you might find some <strong><em>spurious</em></strong><a href="#fn65" class="footnote-ref" id="fnref65"><sup>65</sup></a> results. There are other methods that could be used
to do a similar correction and also provide “honest” inferences; we are just going to learn
one of them. Tukey’s method employs a different correction from the Bonferroni method discussed in Chapter <a href="1-chapter2.html#chapter2">1</a> but also controls the <strong><em>family-wise error rate</em></strong> 
across all the pairs being compared.</p>
<p>In pair-wise comparisons between all the pairs of means in a One-Way ANOVA, the number of
tests is based on the number of pairs. We can calculate the number of tests using
<span class="math inline">\(J\)</span> choose 2, <span class="math inline">\(\begin{pmatrix}J\\2\end{pmatrix}\)</span>, to get the number of unique pairs of
size 2 that we can make out of <span class="math inline">\(J\)</span> individual treatment levels. We don’t need to
explore the combinatorics formula for this, as the <code>choose</code> function in R can give us the
answers:</p>
<div class="sourceCode" id="cb276"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb276-1" title="1"><span class="kw">choose</span>(<span class="dv">3</span>,<span class="dv">2</span>)</a></code></pre></div>
<pre><code>## [1] 3</code></pre>
<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb278-1" title="1"><span class="kw">choose</span>(<span class="dv">4</span>,<span class="dv">2</span>)</a></code></pre></div>
<pre><code>## [1] 6</code></pre>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb280-1" title="1"><span class="kw">choose</span>(<span class="dv">5</span>,<span class="dv">2</span>)</a></code></pre></div>
<pre><code>## [1] 10</code></pre>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb282-1" title="1"><span class="kw">choose</span>(<span class="dv">6</span>,<span class="dv">2</span>)</a></code></pre></div>
<pre><code>## [1] 15</code></pre>
<div class="sourceCode" id="cb284"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb284-1" title="1"><span class="kw">choose</span>(<span class="dv">7</span>,<span class="dv">2</span>)</a></code></pre></div>
<pre><code>## [1] 21</code></pre>
<p>So if you have three groups (the smallest number where we have to worry about more than one pair), there are three unique pairs to
compare. For six groups, like in the guinea pig study, we have to consider 15 tests to compare all the unique pairs of groups and with seven groups, there are 21 tests. Once there are more than two groups to compare, it seems like we
should be worried about inflated family-wise error rates. Fortunately, the
Tukey’s HSD method controls the family-wise error rate at your specified level
(say 0.05) across any number of pair-wise comparisons. This means that the
overall rate of at least one Type I error across all the tests is controlled at the specified
significance level, often 5%. To do this, each test must use a slightly more
conservative cut-off than if just one test is performed and the procedure helps
us figure out how much more conservative we need to be.</p>
<p>Tukey’s HSD starts  with focusing on the difference between the groups with the
largest and smallest means (<span class="math inline">\(\bar{y}_{max}-\bar{y}_{min}\)</span>). If
<span class="math inline">\((\bar{y}_{max}-\bar{y}_{min}) \le \text{Margin of Error}\)</span>
for the difference in the means, then all other pairwise differences, say
<span class="math inline">\(\vert \bar{y}_j - \bar{y}_{j&#39;}\vert\)</span>, for two groups <span class="math inline">\(j\)</span> and <span class="math inline">\(j&#39;\)</span>, will be less
than or equal to that margin of error. This also means that any confidence
intervals for any difference in the means will contain 0. Tukey’s HSD selects a
critical value so that (<span class="math inline">\(\bar{y}_{max}-\bar{y}_{min}\)</span>) will be less than the margin of
error in 95% of data sets drawn from populations with a common mean. This implies
that in 95% of data sets in which all the population means are the same, all
confidence intervals for differences in pairs of means will contain 0. Tukey’s
HSD provides confidence intervals for the difference in true means between
groups <span class="math inline">\(j\)</span> and <span class="math inline">\(j&#39;\)</span>, <span class="math inline">\(\mu_j-\mu_{j&#39;}\)</span>, for all pairs where <span class="math inline">\(j \ne j&#39;\)</span>, using</p>
<p><span class="math display">\[(\bar{y}_j - \bar{y}_{j&#39;}) \mp \frac{q^*}{\sqrt{2}}\sqrt{\text{MS}_E\left(\frac{1}{n_j}+
\frac{1}{n_{j&#39;}}\right)}\]</span></p>
<p>where
<span class="math inline">\(\frac{q^*}{\sqrt{2}}\sqrt{\text{MS}_E\left(\frac{1}{n_j}+\frac{1}{n_{j&#39;}}\right)}\)</span>
is the margin of error for the intervals. The distribution used
to find the multiplier, <span class="math inline">\(q^*\)</span>, for the confidence intervals is available in the
<code>qtukey</code> function and generally provides a slightly larger multiplier than the
regular <span class="math inline">\(t^*\)</span> from our two-sample <span class="math inline">\(t\)</span>-based confidence interval discussed in
Chapter <a href="1-chapter2.html#chapter2">1</a>. The formula otherwise is very similar to the one used in Chapter <a href="1-chapter2.html#chapter2">1</a> with the SE for the difference in the means based on a measure of residual variance (here <span class="math inline">\(MS_E\)</span>) times <span class="math inline">\(\left(\frac{1}{n_j}+\frac{1}{n_{j&#39;}}\right)\)</span> which weights the results based on the relative sample sizes in the groups.</p>
<p>We will use the <code>confint</code>, <code>cld</code>, and <code>plot</code> functions
applied to output from the <code>glht</code> function (all from the <code>multcomp</code> package;
<span class="citation">Hothorn, Bretz, and Westfall (<a href="#ref-Hothorn2008" role="doc-biblioref">2008</a>)</span>, <span class="citation">(Hothorn, Bretz, and Westfall <a href="#ref-R-multcomp" role="doc-biblioref">2019</a>)</span>) to get the required comparisons from our
ANOVA model.

Unfortunately, its code format is a little complicated – but there are
just two places to modify the code: include the model name and after <code>mcp</code>
(stands for <em>multiple comparison procedure</em>) in the <code>linfct</code> option, you need to include the
explanatory variable name as <code>VARIABLENAME="Tukey"</code>. The last part is to get the
Tukey HSD multiple comparisons run on our explanatory variable<a href="#fn66" class="footnote-ref" id="fnref66"><sup>66</sup></a>. Once we obtain the
intervals using the <code>confint</code> function or using <code>plot</code> applied to the stored results, we can use them to test <span class="math inline">\(H_0: \mu_j = \mu_{j&#39;} \text{ vs } H_A: \mu_j \ne \mu_{j&#39;}\)</span>
by assessing whether 0 is in the confidence interval for each pair. If 0 is in the
interval, then there is weak evidence against the null hypothesis for that pair, so we not detect a difference in that pair and not conclude that there is a difference. If 0 is not in the
interval, then we have strong evidence against <span class="math inline">\(H_0\)</span> for that pair, detect a difference, and conclude that there is a difference in that pair <em>at the specified family-wise significance
level</em>. You will see a switch to using the
word “detection” to describe null hypotheses that we find strong evidence against as it
can help to compactly write up these complicated results. The following code provides the numerical
and graphical<a href="#fn67" class="footnote-ref" id="fnref67"><sup>67</sup></a> results of applying Tukey’s HSD
to the linear model for the Guinea Pig data:</p>
<p>(ref:fig3-19) Graphical display of pair-wise comparisons from Tukey’s HSD for the
Guinea Pig data. Any confidence intervals that do not contain 0 provide strong evidence
against the null hypothesis of no difference in the true means for that pair of groups.</p>
<div class="sourceCode" id="cb286"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb286-1" title="1"><span class="kw">require</span>(multcomp)</a>
<a class="sourceLine" id="cb286-2" title="2">Tm2 &lt;-<span class="st"> </span><span class="kw">glht</span>(m2, <span class="dt">linfct =</span> <span class="kw">mcp</span>(<span class="dt">Treat =</span> <span class="st">&quot;Tukey&quot;</span>))</a>
<a class="sourceLine" id="cb286-3" title="3"><span class="kw">confint</span>(Tm2)</a></code></pre></div>
<pre><code>## 
##   Simultaneous Confidence Intervals
## 
## Multiple Comparisons of Means: Tukey Contrasts
## 
## 
## Fit: lm(formula = len ~ Treat, data = ToothGrowth)
## 
## Quantile = 2.955
## 95% family-wise confidence level
##  
## 
## Linear Hypotheses:
##                      Estimate lwr      upr     
## VC.0.5 - OJ.0.5 == 0  -5.2500 -10.0490  -0.4510
## OJ.1 - OJ.0.5 == 0     9.4700   4.6710  14.2690
## VC.1 - OJ.0.5 == 0     3.5400  -1.2590   8.3390
## OJ.2 - OJ.0.5 == 0    12.8300   8.0310  17.6290
## VC.2 - OJ.0.5 == 0    12.9100   8.1110  17.7090
## OJ.1 - VC.0.5 == 0    14.7200   9.9210  19.5190
## VC.1 - VC.0.5 == 0     8.7900   3.9910  13.5890
## OJ.2 - VC.0.5 == 0    18.0800  13.2810  22.8790
## VC.2 - VC.0.5 == 0    18.1600  13.3610  22.9590
## VC.1 - OJ.1 == 0      -5.9300 -10.7290  -1.1310
## OJ.2 - OJ.1 == 0       3.3600  -1.4390   8.1590
## VC.2 - OJ.1 == 0       3.4400  -1.3590   8.2390
## OJ.2 - VC.1 == 0       9.2900   4.4910  14.0890
## VC.2 - VC.1 == 0       9.3700   4.5710  14.1690
## VC.2 - OJ.2 == 0       0.0800  -4.7190   4.8790</code></pre>
<div class="sourceCode" id="cb288"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb288-1" title="1">old.par &lt;-<span class="st"> </span><span class="kw">par</span>(<span class="dt">mai=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">1</span>)) <span class="co">#Makes room on the plot for the group names</span></a>
<a class="sourceLine" id="cb288-2" title="2"><span class="kw">plot</span>(Tm2)</a></code></pre></div>
<div class="figure"><span id="fig:Figure3-19"></span>
<img src="03-oneWayAnova_files/figure-html/Figure3-19-1.png" alt="(ref:fig3-19)" width="960" />
<p class="caption">
Figure 1.45: (ref:fig3-19)
</p>
</div>
<p>Figure <a href="2-6-section3-6.html#fig:Figure3-19">1.45</a> contains confidence intervals for the difference in
the means for all 15 pairs of groups. For example, the first row in the plot contains
the confidence interval for comparing VC.0.5 and OJ.0.5 (VC.0.5 <strong>minus</strong> OJ.0.5). In the numerical output, you can find that this 95%
family-wise confidence interval goes from -10.05 to -0.45 microns (<code>lwr</code> and
<code>upr</code> in the numerical output provide the CI endpoints). This interval does not
contain 0 since its upper end point is -0.45 microns and so we can now say that
there is strong evidence against the null hypothesis of no difference in this pair and that we detect that OJ and VC have different true mean growth rates at the 0.5 mg
dosage level. We can go further and say that we are 95% confident that the difference
in the true mean tooth growth between VC.0.5 and OJ.0.5 (VC.0.5-OJ.0.5) is between
-10.05 and -0.45 microns, after adjusting for comparing all the pairs of groups. The center of this CI is -5.25 which is <span class="math inline">\(\hat{\tau}_2\)</span> and the estimate difference between VC.0.5 and the baseline category of OJ.0.5. That means we can get an un-adjusted 95% confidence interval from the <code>confint</code> function to compare to this adjusted CI. The interval that does not account for all the comparisons goes from -8.51 to -1.99 microns (second row out <code>confint</code> output), showing the increased width needed in Tukey’s interval to control the family-wise error rate when many pairs are being compared. With 14 other intervals, we obviously can’t give them all this much attention…</p>
<div class="sourceCode" id="cb289"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb289-1" title="1"><span class="kw">confint</span>(m2)</a></code></pre></div>
<pre><code>##                  2.5 %    97.5 %
## (Intercept) 10.9276907 15.532309
## TreatVC.0.5 -8.5059571 -1.994043
## TreatOJ.1    6.2140429 12.725957
## TreatVC.1    0.2840429  6.795957
## TreatOJ.2    9.5740429 16.085957
## TreatVC.2    9.6540429 16.165957</code></pre>
<p>If you put all these pair-wise tests together, you can generate an overall
interpretation of Tukey’s HSD results that discusses sets of groups that
are not detectably different from one another and those groups that were
distinguished from other sets of groups. To do this, start with listing
out the groups that are not detectably different (CIs contain 0), which,
here, only occurs for four of the pairs. The CIs that contain 0 are for the
pairs VC.1 and OJ.0.5, OJ.2 and OJ.1, VC.2 and OJ.1, and, finally, VC.2 and
OJ.2. So VC.2, OJ.1, and OJ.2 are all not detectably different from each
other and VC.1 and OJ.0.5 are also not detectably different. If you look carefully, VC.0.5 is detected as different from every other group. So there are basically
three sets of groups that can be grouped together as “similar”: VC.2, OJ.1,
and OJ.2; VC.1 and OJ.0.5; and VC.0.5. Sometimes groups overlap with some
levels not being detectably different from other levels that belong to
different groups and the story is not as clear as it is in this case. An
example of this sort of overlap is seen in the next section.</p>
<p>There is a method that many researchers use to more efficiently generate and
report these sorts of results that is called a <strong><em>compact letter display</em></strong> 
(CLD, <span class="citation">Piepho (<a href="#ref-Piepho2004" role="doc-biblioref">2004</a>)</span>)<a href="#fn68" class="footnote-ref" id="fnref68"><sup>68</sup></a>. The <code>cld</code> function can be applied to the results from
<code>glht</code> to generate the CLD that we can use to provide a “simple” summary of
the sets of groups. In this discussion, we define a <strong>set as a union of different
groups that can contain one or more members</strong> and the member of these groups are
the different treatment levels.</p>
<div class="sourceCode" id="cb291"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb291-1" title="1"><span class="kw">cld</span>(Tm2)</a></code></pre></div>
<pre><code>## OJ.0.5 VC.0.5   OJ.1   VC.1   OJ.2   VC.2 
##    &quot;b&quot;    &quot;a&quot;    &quot;c&quot;    &quot;b&quot;    &quot;c&quot;    &quot;c&quot;</code></pre>

<p>Groups with the same letter are not detectably different (are in the same set)
and groups that are detectably different get different letters (are in
different sets). Groups can have more than one letter to reflect “overlap”
between the sets of groups and sometimes a set of groups contains only a
single treatment level (VC.0.5 is a set of size 1). Note
that if the groups have the same letter, this does not mean they are the same,
just that there is <strong>insufficient evidence to declare a difference for that pair</strong>. If we consider
the previous output for the CLD, the “a” set contains VC.0.5, the “b” set contains
OJ.0.5 and VC.1, and the “c” set contains OJ.1, OJ.2, and VC.2. These are exactly
the groups of treatment levels that we obtained by going through all fifteen
pairwise results.</p>
<p>One benefit of this work is that the CLD letters can be added to a plot (such as the pirate-plot) to
help fully report the results and understand the sorts of differences Tukey’s
HSD detected. The code with <code>text</code>  involves placing text on the figure. In the <code>text</code> function, the x and y axis locations are specified (x-axis goes from 1 to 6 for the 6 categories) as well as the text to add (the CLD here). Some trial and error for locations may be needed to get the letters to be easily seen in a given pirate-plot.<br />
Figure <a href="2-6-section3-6.html#fig:Figure3-20">1.46</a> enhances the discussion by showing that the
“<b><font color='blue'>a</font></b>” group with VC.0.5 had the lowest average tooth
growth, the “<b><font color='red'>b</font></b>” group had intermediate tooth growth
for treatments OJ.0.5 and VC.1, and the highest growth rates came from
OJ.1, OJ.2, and VC.2. Even though VC.2 had the highest average growth rate,
we are not able to prove that its true mean is any higher
than the other groups labeled with “<b><font color='green'>c</font></b>”. Hopefully the
ease of getting to the story of the Tukey’s HSD results from a plot like this
explains why it is common to report results using these methods instead of
reporting 15 confidence intervals for all the pair-wise differences, either in a table or the plot.</p>
<p>(ref:fig3-20) Pirate-plot of odontoblast growth by group with Tukey’s HSD compact
letter display. Note some extra pirate-plot options are used to enhance focus on the CLD results.</p>
<div class="sourceCode" id="cb293"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb293-1" title="1"><span class="kw">pirateplot</span>(len<span class="op">~</span>Treat, <span class="dt">data=</span>ToothGrowth, <span class="dt">ylab=</span><span class="st">&quot;Growth (microns)&quot;</span>, <span class="dt">inf.method=</span><span class="st">&quot;ci&quot;</span>, <span class="dt">theme=</span><span class="dv">2</span>,<span class="dt">inf.f.o =</span> <span class="dv">0</span>,<span class="dt">point.o =</span> <span class="fl">.5</span>) <span class="co">#Options theme=2,inf.f.o = 0,point.o = .5 added to focus on CLD</span></a>
<a class="sourceLine" id="cb293-2" title="2"><span class="kw">text</span>(<span class="dt">x=</span><span class="dv">2</span>,<span class="dt">y=</span><span class="dv">10</span>,<span class="st">&quot;a&quot;</span>,<span class="dt">col=</span><span class="st">&quot;blue&quot;</span>,<span class="dt">cex=</span><span class="fl">1.5</span>) <span class="co">#CLD added</span></a>
<a class="sourceLine" id="cb293-3" title="3"><span class="kw">text</span>(<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">4</span>),<span class="dt">y=</span><span class="kw">c</span>(<span class="dv">15</span>,<span class="dv">18</span>),<span class="st">&quot;b&quot;</span>,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>,<span class="dt">cex=</span><span class="fl">1.5</span>)</a>
<a class="sourceLine" id="cb293-4" title="4"><span class="kw">text</span>(<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">6</span>),<span class="dt">y=</span><span class="kw">c</span>(<span class="dv">25</span>,<span class="dv">28</span>,<span class="dv">28</span>),<span class="st">&quot;c&quot;</span>,<span class="dt">col=</span><span class="st">&quot;green&quot;</span>,<span class="dt">cex=</span><span class="fl">1.5</span>)</a></code></pre></div>
<div class="figure"><span id="fig:Figure3-20"></span>
<img src="03-oneWayAnova_files/figure-html/Figure3-20-1.png" alt="(ref:fig3-20)" width="960" />
<p class="caption">
Figure 1.46: (ref:fig3-20)
</p>
</div>
<p>There are just a couple of other details to mention on this set of methods. First,
note that we interpret the set of confidence intervals simultaneously: We are
95% confident that <strong>ALL</strong> the intervals contain the respective differences in
the true means (this is a <strong><em>family-wise interpretation</em></strong>). These intervals are
adjusted from our regular two-sample <span class="math inline">\(t\)</span> intervals that came from <code>lm</code> from Chapter <a href="1-chapter2.html#chapter2">1</a>
to allow this stronger interpretation. Specifically,
they are wider. Second, if sample sizes are unequal in the groups, Tukey’s HSD
is conservative and provides a family-wise error rate that is lower than the
<em>nominal</em> (or specified) level. In other words, it fails less often than expected
and the intervals provided are a little wider than needed, containing all the
pairwise differences at higher than the nominal confidence level of (typically)
95%. Third, this is a parametric approach and violations of normality and
constant variance will push the method in the other direction, potentially
making the technique dangerously liberal. Nonparametric approaches to this
problem are also possible, but will not be considered here.</p>
<p>Tukey’s HSD results can also be displayed as p-values for each pair-wise test result. This is a little less common but can allow you to directly assess the strength of evidence for a particular pair instead of using the detected/not result that the family-wise CIs provide. But the family-wise CIs are useful for exploring the size of the differences in the pairs and we need to simplify things to detect/not in these situations because there are so many tests. But if you want to see the Tukey HSD p-values, you can use the <code>summary</code> function on the object that is storing the results:</p>
<div class="sourceCode" id="cb294"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb294-1" title="1"><span class="kw">summary</span>(Tm2)</a></code></pre></div>
<pre><code>## 
##   Simultaneous Tests for General Linear Hypotheses
## 
## Multiple Comparisons of Means: Tukey Contrasts
## 
## 
## Fit: lm(formula = len ~ Treat, data = ToothGrowth)
## 
## Linear Hypotheses:
##                      Estimate Std. Error t value Pr(&gt;|t|)
## VC.0.5 - OJ.0.5 == 0   -5.250      1.624  -3.233  0.02424
## OJ.1 - OJ.0.5 == 0      9.470      1.624   5.831  &lt; 0.001
## VC.1 - OJ.0.5 == 0      3.540      1.624   2.180  0.26411
## OJ.2 - OJ.0.5 == 0     12.830      1.624   7.900  &lt; 0.001
## VC.2 - OJ.0.5 == 0     12.910      1.624   7.949  &lt; 0.001
## OJ.1 - VC.0.5 == 0     14.720      1.624   9.064  &lt; 0.001
## VC.1 - VC.0.5 == 0      8.790      1.624   5.413  &lt; 0.001
## OJ.2 - VC.0.5 == 0     18.080      1.624  11.133  &lt; 0.001
## VC.2 - VC.0.5 == 0     18.160      1.624  11.182  &lt; 0.001
## VC.1 - OJ.1 == 0       -5.930      1.624  -3.651  0.00739
## OJ.2 - OJ.1 == 0        3.360      1.624   2.069  0.31868
## VC.2 - OJ.1 == 0        3.440      1.624   2.118  0.29372
## OJ.2 - VC.1 == 0        9.290      1.624   5.720  &lt; 0.001
## VC.2 - VC.1 == 0        9.370      1.624   5.770  &lt; 0.001
## VC.2 - OJ.2 == 0        0.080      1.624   0.049  1.00000
## (Adjusted p values reported -- single-step method)</code></pre>
<p>These reinforce the strong evidence for many of the pairs and less strong evidence for four pairs that were not detected to be different. So these p-values provide another method to employ to report the Tukey’s HSD results – you would only need to report and explore the confidence intervals or the p-values, not both.</p>
<p>Tukey’s HSD does not require you
to find a small p-value from your overall <span class="math inline">\(F\)</span>-test to employ the methods
but if you apply it to situations with p-values larger than your
<em>a priori</em> significance level,
you are unlikely to find any pairs that are detected as being different. Some
statisticians suggest that you shouldn’t employ follow-up tests such as Tukey’s
HSD when there is not sufficient evidence to reject the overall null hypothesis
and would be able to reasonably criticize the following results.</p>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Hothorn2008">
<p>Hothorn, Torsten, Frank Bretz, and Peter Westfall. 2008. “Simultaneous Inference in General Parametric Models.” <em>Biometrical Journal</em> 50 (3): 346–63.</p>
</div>
<div id="ref-R-multcomp">
<p>Hothorn, Torsten, Frank Bretz, and Peter Westfall. 2019. <em>Multcomp: Simultaneous Inference in General Parametric Models</em>. <a href="https://CRAN.R-project.org/package=multcomp">https://CRAN.R-project.org/package=multcomp</a>.</p>
</div>
<div id="ref-Piepho2004">
<p>Piepho, Hans-Peter. 2004. “An Algorithm for a Letter-Based Representation of All-Pairwise Comparisons.” <em>Journal of Computational and Graphical Statistics</em> 13 (2): 456–66.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="64">
<li id="fn64"><p>When this procedure is used with unequal group sizes it is also sometimes
called Tukey-Kramer’s method.<a href="2-6-section3-6.html#fnref64" class="footnote-back">↩</a></p></li>
<li id="fn65"><p>We often use “spurious” to describe falsely rejected null hypotheses, but
they are also called false detections.<a href="2-6-section3-6.html#fnref65" class="footnote-back">↩</a></p></li>
<li id="fn66"><p>In more complex models, this code can be used to create pair-wise comparisons on one of many explanatory variables.<a href="2-6-section3-6.html#fnref66" class="footnote-back">↩</a></p></li>
<li id="fn67"><p>The plot of results usually contains all the labels of groups but if the labels are long or there many groups, sometimes the row labels are hard to see even with re-sizing the plot to make it taller in RStudio. The numerical output is
useful as a guide to help you read the plot in those situations.<a href="2-6-section3-6.html#fnref67" class="footnote-back">↩</a></p></li>
<li id="fn68"><p>Note that this method is implemented slightly differently than explained here in some software packages so if you see this in a journal article, read the discussion carefully.<a href="2-6-section3-6.html#fnref68" class="footnote-back">↩</a></p></li>
</ol>
</div>
<p style="text-align: center;">
<a href="2-5-section3-5.html"><button class="btn btn-default">Previous</button></a>
<a href="2-7-section3-7.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
