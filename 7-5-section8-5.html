<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="7.5 General recommendations for MLR interpretations and VIFs | Intermediate Statistics with R" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="gpeterson406/Greenwood_Book" />

<meta name="author" content="Mark C Greenwood" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="7.5 General recommendations for MLR interpretations and VIFs | Intermediate Statistics with R">

<title>7.5 General recommendations for MLR interpretations and VIFs | Intermediate Statistics with R</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#cover">Cover</a></li>
<li class="has-sub"><a href="acknowledgments.html#acknowledgments">Acknowledgments</a><ul>
<li><a href="0-1-section1-5.html#section1-5"><span class="toc-section-number">0.1</span> Summary of important R code</a></li>
</ul></li>
<li class="has-sub"><a href="1-chapter2.html#chapter2"><span class="toc-section-number">1</span> (R)e-Introduction to statistics</a><ul>
<li><a href="1-1-section2-1.html#section2-1"><span class="toc-section-number">1.1</span> Histograms, boxplots, and density curves</a></li>
<li><a href="1-2-section2-2.html#section2-2"><span class="toc-section-number">1.2</span> Pirate-plots</a></li>
<li><a href="1-3-section2-3.html#section2-3"><span class="toc-section-number">1.3</span> Models, hypotheses, and permutations for the two sample mean situation</a></li>
<li><a href="1-4-section2-4.html#section2-4"><span class="toc-section-number">1.4</span> Permutation testing for the two sample mean situation</a></li>
<li><a href="1-5-section2-5.html#section2-5"><span class="toc-section-number">1.5</span> Hypothesis testing (general)</a></li>
<li><a href="1-6-section2-6.html#section2-6"><span class="toc-section-number">1.6</span> Connecting randomization (nonparametric) and parametric tests</a></li>
<li><a href="1-7-section2-7.html#section2-7"><span class="toc-section-number">1.7</span> Second example of permutation tests</a></li>
<li><a href="1-8-section2-8.html#section2-8"><span class="toc-section-number">1.8</span> Reproducibility Crisis: Moving beyond p &lt; 0.05, publication bias, and multiple testing issues</a></li>
<li><a href="1-9-section2-9.html#section2-9"><span class="toc-section-number">1.9</span> Confidence intervals and bootstrapping</a></li>
<li><a href="1-10-section2-10.html#section2-10"><span class="toc-section-number">1.10</span> Bootstrap confidence intervals for difference in GPAs</a></li>
<li><a href="1-11-section2-11.html#section2-11"><span class="toc-section-number">1.11</span> Chapter summary</a></li>
<li><a href="1-12-section2-12.html#section2-12"><span class="toc-section-number">1.12</span> Summary of important R code</a></li>
<li><a href="1-13-section2-13.html#section2-13"><span class="toc-section-number">1.13</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="2-chapter3.html#chapter3"><span class="toc-section-number">2</span> One-Way ANOVA</a><ul>
<li><a href="2-1-section3-1.html#section3-1"><span class="toc-section-number">2.1</span> Situation</a></li>
<li><a href="2-2-section3-2.html#section3-2"><span class="toc-section-number">2.2</span> Linear model for One-Way ANOVA (cell-means and reference-coding)</a></li>
<li><a href="2-3-section3-3.html#section3-3"><span class="toc-section-number">2.3</span> One-Way ANOVA Sums of Squares, Mean Squares, and F-test</a></li>
<li><a href="2-4-section3-4.html#section3-4"><span class="toc-section-number">2.4</span> ANOVA model diagnostics including QQ-plots</a></li>
<li><a href="2-5-section3-5.html#section3-5"><span class="toc-section-number">2.5</span> Guinea pig tooth growth One-Way ANOVA example</a></li>
<li><a href="2-6-section3-6.html#section3-6"><span class="toc-section-number">2.6</span> Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display</a></li>
<li><a href="2-7-section3-7.html#section3-7"><span class="toc-section-number">2.7</span> Pair-wise comparisons for the Overtake data</a></li>
<li><a href="2-8-section3-8.html#section3-8"><span class="toc-section-number">2.8</span> Chapter summary</a></li>
<li><a href="2-9-section3-9.html#section3-9"><span class="toc-section-number">2.9</span> Summary of important R code</a></li>
<li><a href="2-10-section3-10.html#section3-10"><span class="toc-section-number">2.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="3-chapter4.html#chapter4"><span class="toc-section-number">3</span> Two-Way ANOVA</a><ul>
<li><a href="3-1-section4-1.html#section4-1"><span class="toc-section-number">3.1</span> Situation</a></li>
<li><a href="3-2-section4-2.html#section4-2"><span class="toc-section-number">3.2</span> Designing a two-way experiment and visualizing results</a></li>
<li><a href="3-3-section4-3.html#section4-3"><span class="toc-section-number">3.3</span> Two-Way ANOVA models and hypothesis tests</a></li>
<li><a href="3-4-section4-4.html#section4-4"><span class="toc-section-number">3.4</span> Guinea pig tooth growth analysis with Two-Way ANOVA</a></li>
<li><a href="3-5-section4-5.html#section4-5"><span class="toc-section-number">3.5</span> Observational study example: The Psychology of Debt</a></li>
<li><a href="3-6-section4-6.html#section4-6"><span class="toc-section-number">3.6</span> Pushing Two-Way ANOVA to the limit: Un-replicated designs and Estimability</a></li>
<li><a href="3-7-section4-7.html#section4-7"><span class="toc-section-number">3.7</span> Chapter summary</a></li>
<li><a href="3-8-section4-8.html#section4-8"><span class="toc-section-number">3.8</span> Summary of important R code</a></li>
<li><a href="3-9-section4-9.html#section4-9"><span class="toc-section-number">3.9</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="4-chapter5.html#chapter5"><span class="toc-section-number">4</span> Chi-square tests</a><ul>
<li><a href="4-1-section5-1.html#section5-1"><span class="toc-section-number">4.1</span> Situation, contingency tables, and tableplots</a></li>
<li><a href="4-2-section5-2.html#section5-2"><span class="toc-section-number">4.2</span> Homogeneity test hypotheses</a></li>
<li><a href="4-3-section5-3.html#section5-3"><span class="toc-section-number">4.3</span> Independence test hypotheses</a></li>
<li><a href="4-4-section5-4.html#section5-4"><span class="toc-section-number">4.4</span> Models for R by C tables</a></li>
<li><a href="4-5-section5-5.html#section5-5"><span class="toc-section-number">4.5</span> Permutation tests for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="4-6-section5-6.html#section5-6"><span class="toc-section-number">4.6</span> Chi-square distribution for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="4-7-section5-7.html#section5-7"><span class="toc-section-number">4.7</span> Examining residuals for the source of differences</a></li>
<li><a href="4-8-section5-8.html#section5-8"><span class="toc-section-number">4.8</span> General protocol for <span class="math inline">\(X^2\)</span> tests</a></li>
<li><a href="4-9-section5-9.html#section5-9"><span class="toc-section-number">4.9</span> Political party and voting results: Complete analysis</a></li>
<li><a href="4-10-section5-10.html#section5-10"><span class="toc-section-number">4.10</span> Is cheating and lying related in students?</a></li>
<li><a href="4-11-section5-11.html#section5-11"><span class="toc-section-number">4.11</span> Analyzing a stratified random sample of California schools</a></li>
<li><a href="4-12-section5-12.html#section5-12"><span class="toc-section-number">4.12</span> Chapter summary</a></li>
<li><a href="4-13-section5-13.html#section5-13"><span class="toc-section-number">4.13</span> Summary of important R commands</a></li>
<li><a href="4-14-section5-14.html#section5-14"><span class="toc-section-number">4.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="5-chapter6.html#chapter6"><span class="toc-section-number">5</span> Correlation and Simple Linear Regression</a><ul>
<li><a href="5-1-section6-1.html#section6-1"><span class="toc-section-number">5.1</span> Relationships between two quantitative variables</a></li>
<li><a href="5-2-section6-2.html#section6-2"><span class="toc-section-number">5.2</span> Estimating the correlation coefficient</a></li>
<li><a href="5-3-section6-3.html#section6-3"><span class="toc-section-number">5.3</span> Relationships between variables by groups</a></li>
<li><a href="5-4-section6-4.html#section6-4"><span class="toc-section-number">5.4</span> Inference for the correlation coefficient</a></li>
<li><a href="5-5-section6-5.html#section6-5"><span class="toc-section-number">5.5</span> Are tree diameters related to tree heights?</a></li>
<li><a href="5-6-section6-6.html#section6-6"><span class="toc-section-number">5.6</span> Describing relationships with a regression model</a></li>
<li><a href="5-7-section6-7.html#section6-7"><span class="toc-section-number">5.7</span> Least Squares Estimation</a></li>
<li><a href="5-8-section6-8.html#section6-8"><span class="toc-section-number">5.8</span> Measuring the strength of regressions: R<sup>2</sup></a></li>
<li><a href="5-9-section6-9.html#section6-9"><span class="toc-section-number">5.9</span> Outliers: leverage and influence</a></li>
<li><a href="5-10-section6-10.html#section6-10"><span class="toc-section-number">5.10</span> Residual diagnostics – setting the stage for inference</a></li>
<li><a href="5-11-section6-11.html#section6-11"><span class="toc-section-number">5.11</span> Old Faithful discharge and waiting times</a></li>
<li><a href="5-12-section6-12.html#section6-12"><span class="toc-section-number">5.12</span> Chapter summary</a></li>
<li><a href="5-13-section6-13.html#section6-13"><span class="toc-section-number">5.13</span> Summary of important R code</a></li>
<li><a href="5-14-section6-14.html#section6-14"><span class="toc-section-number">5.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="6-chapter7.html#chapter7"><span class="toc-section-number">6</span> Simple linear regression inference</a><ul>
<li><a href="6-1-section7-1.html#section7-1"><span class="toc-section-number">6.1</span> Model</a></li>
<li><a href="6-2-section7-2.html#section7-2"><span class="toc-section-number">6.2</span> Confidence interval and hypothesis tests for the slope and intercept</a></li>
<li><a href="6-3-section7-3.html#section7-3"><span class="toc-section-number">6.3</span> Bozeman temperature trend</a></li>
<li><a href="6-4-section7-4.html#section7-4"><span class="toc-section-number">6.4</span> Randomization-based inferences for the slope coefficient</a></li>
<li><a href="6-5-section7-5.html#section7-5"><span class="toc-section-number">6.5</span> Transformations part I: Linearizing relationships</a></li>
<li><a href="6-6-section7-6.html#section7-6"><span class="toc-section-number">6.6</span> Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x)</a></li>
<li><a href="6-7-section7-7.html#section7-7"><span class="toc-section-number">6.7</span> Confidence interval for the mean and prediction intervals for a new observation</a></li>
<li><a href="6-8-section7-8.html#section7-8"><span class="toc-section-number">6.8</span> Chapter summary</a></li>
<li><a href="6-9-section7-9.html#section7-9"><span class="toc-section-number">6.9</span> Summary of important R code</a></li>
<li><a href="6-10-section7-10.html#section7-10"><span class="toc-section-number">6.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="7-chapter8.html#chapter8"><span class="toc-section-number">7</span> Multiple linear regression</a><ul>
<li><a href="7-1-section8-1.html#section8-1"><span class="toc-section-number">7.1</span> Going from SLR to MLR</a></li>
<li><a href="7-2-section8-2.html#section8-2"><span class="toc-section-number">7.2</span> Validity conditions in MLR</a></li>
<li><a href="7-3-section8-3.html#section8-3"><span class="toc-section-number">7.3</span> Interpretation of MLR terms</a></li>
<li><a href="7-4-section8-4.html#section8-4"><span class="toc-section-number">7.4</span> Comparing multiple regression models</a></li>
<li><a href="7-5-section8-5.html#section8-5"><span class="toc-section-number">7.5</span> General recommendations for MLR interpretations and VIFs</a></li>
<li><a href="7-6-section8-6.html#section8-6"><span class="toc-section-number">7.6</span> MLR inference: Parameter inferences using the t-distribution</a></li>
<li><a href="7-7-section8-7.html#section8-7"><span class="toc-section-number">7.7</span> Overall F-test in multiple linear regression</a></li>
<li><a href="7-8-section8-8.html#section8-8"><span class="toc-section-number">7.8</span> Case study: First year college GPA and SATs</a></li>
<li><a href="7-9-section8-9.html#section8-9"><span class="toc-section-number">7.9</span> Different intercepts for different groups: MLR with indicator variables</a></li>
<li><a href="7-10-section8-10.html#section8-10"><span class="toc-section-number">7.10</span> Additive MLR with more than two groups: Headache example</a></li>
<li><a href="7-11-section8-11.html#section8-11"><span class="toc-section-number">7.11</span> Different slopes and different intercepts</a></li>
<li><a href="7-12-section8-12.html#section8-12"><span class="toc-section-number">7.12</span> F-tests for MLR models with quantitative and categorical variables and interactions</a></li>
<li><a href="7-13-section8-13.html#section8-13"><span class="toc-section-number">7.13</span> AICs for model selection</a></li>
<li><a href="7-14-section8-14.html#section8-14"><span class="toc-section-number">7.14</span> Case study: Forced expiratory volume model selection using AICs</a></li>
<li><a href="7-15-section8-15.html#section8-15"><span class="toc-section-number">7.15</span> Chapter summary</a></li>
<li><a href="7-16-section8-16.html#section8-16"><span class="toc-section-number">7.16</span> Summary of important R code</a></li>
<li><a href="7-17-section8-17.html#section8-17"><span class="toc-section-number">7.17</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="8-chapter9.html#chapter9"><span class="toc-section-number">8</span> Case studies</a><ul>
<li><a href="8-1-section9-1.html#section9-1"><span class="toc-section-number">8.1</span> Overview of material covered</a></li>
<li><a href="8-2-section9-2.html#section9-2"><span class="toc-section-number">8.2</span> The impact of simulated chronic nitrogen deposition on the biomass and N2-fixation activity of two boreal feather moss–cyanobacteria associations</a></li>
<li><a href="8-3-section9-3.html#section9-3"><span class="toc-section-number">8.3</span> Ants learn to rely on more informative attributes during decision-making</a></li>
<li><a href="8-4-section9-4.html#section9-4"><span class="toc-section-number">8.4</span> Multi-variate models are essential for understanding vertebrate diversification in deep time</a></li>
<li><a href="8-5-section9-5.html#section9-5"><span class="toc-section-number">8.5</span> What do didgeridoos really do about sleepiness?</a></li>
<li><a href="8-6-section9-6.html#section9-6"><span class="toc-section-number">8.6</span> General summary</a></li>
</ul></li>
<li><a href="references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="section8-5" class="section level2">
<h2><span class="header-section-number">7.5</span> General recommendations for MLR interpretations and VIFs</h2>
<p>There are some important issues to remember<a href="#fn119" class="footnote-ref" id="fnref119"><sup>119</sup></a> when interpreting
regression models that can result in common mistakes.</p>
<ul>
<li><p><strong>Don’t claim to “hold everything constant” for a single individual</strong>:</p>
<p>Mathematically this is a correct interpretation of the MLR model but it is
rarely the case that we could have this occur in real applications. Is it
possible to increase the <em>Elevation</em> while holding the <em>Max.Temp</em> constant?
We discussed making term-plots doing exactly this – holding the other
variables constant at their means. If we
interpret each slope coefficient in an MLR conditionally then we can craft
interpretations such as: For locations that have a <em>Max.Temp</em> of, say,
<span class="math inline">\(45^\circ F\)</span> and <em>Min.Temp</em> of, say, <span class="math inline">\(30^\circ F\)</span>, a 1 foot increase in
<em>Elevation</em> tends to be associated with a 0.0268 inch increase in <em>Snow Depth</em>
on average. This does not try to imply that we can actually make that sort
of change but that given those other variables, the change for that variable
is a certain magnitude.</p></li>
<li><p><strong>Don’t interpret the regression results causally (or casually?)…</strong></p>
<p>Unless you are analyzing the results of a designed experiment (where the
levels
of the explanatory variable(s) were randomly assigned) you cannot state that a
change in that <span class="math inline">\(x\)</span> <strong>causes</strong> a change in <span class="math inline">\(y\)</span>, especially for a given
individual. The multicollinearity in predictors makes it especially difficult
to
put too much emphasis on a single slope coefficient because it may
be corrupted/modified by the other variables being in the model. In
observational studies, there are also all the potential lurking variables that
we did not measure or even confounding variables that we did measure but can’t
disentangle from the variable used in a particular model.

While we do have a
complicated mathematical model relating various <span class="math inline">\(x\text{&#39;s}\)</span> to the response,
do not lose that fundamental focus on causal vs non-causal inferences based on
the design of the study.</p></li>
<li><p><strong>Be cautious about doing prediction in MLR – you might be doing extrapolation!</strong></p>
<p>It is harder to know if you are doing extrapolation in MLR since you could be
in a region of the <span class="math inline">\(x\text{&#39;s}\)</span> that no observations were obtained. Suppose we
want to predict the <em>Snow Depth</em> for an <em>Elevation</em> of 6000 and <em>Max.Temp</em>
of 30. Is this extrapolation based on Figure <a href="7-5-section8-5.html#fig:Figure8-11">1.160</a>? In other
words, can you find any observations “nearby” in the plot of the two
variables together? What about an <em>Elevation</em> of 6000 and a <em>Max.Temp</em> of
40? The first prediction is in a different proximity to observations than
the second one… In situations with more than two explanatory variables it
becomes even more challenging to know whether you are doing extrapolation
and the problem grows as the number of dimensions to search increases… In
fact, in complicated MLR models we typically do not know whether there are
observations “nearby” if we are doing predictions for unobserved
combinations of our predictors. Note that Figure
<a href="7-5-section8-5.html#fig:Figure8-11">1.160</a> also reinforces our potential collinearity problem
between <em>Elevation</em> and <em>Max.Temp</em> with higher elevations being strongly
associated with lower temperatures.</p>
<div class="figure"><span id="fig:Figure8-11"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-11-1.png" alt="Scatterplot of observed Elevations and Maximum Temperatures for SNOTEL data." width="480" />
<p class="caption">
Figure 1.160: Scatterplot of observed Elevations and Maximum Temperatures for SNOTEL data.
</p>
</div></li>
<li><p><strong>Don’t think that the sign of a coefficient is special…</strong></p>
<p>Adding other variables into the MLR models can cause a switch in the
coefficients or change their magnitude or make them go from “important” to
“unimportant” without changing the slope too much. This is related to the
conditionality of the relationships being estimated in MLR and the potential
for sharing of information in the predictors when it is present.</p></li>
<li><p><strong>Multicollinearity in MLR models:</strong></p>
<p>When explanatory variables are not independent (related) to one another, then
including one variable will have an impact on the other variable. Consider the
correlations among the predictors in the SNOTEL data set or visually displayed
in Figure <a href="7-5-section8-5.html#fig:Figure8-12">1.161</a>:

</p>
<div class="sourceCode" id="cb726"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb726-1" title="1"><span class="kw">library</span>(corrplot)</a>
<a class="sourceLine" id="cb726-2" title="2"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">oma=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>))</a>
<a class="sourceLine" id="cb726-3" title="3"><span class="kw">corrplot.mixed</span>(<span class="kw">cor</span>(snotel2[<span class="op">-</span><span class="kw">c</span>(<span class="dv">9</span>,<span class="dv">22</span>),<span class="dv">3</span><span class="op">:</span><span class="dv">6</span>]), <span class="dt">upper.col=</span><span class="kw">c</span>(<span class="dv">1</span>, <span class="st">&quot;orange&quot;</span>),</a>
<a class="sourceLine" id="cb726-4" title="4">               <span class="dt">lower.col=</span><span class="kw">c</span>(<span class="dv">1</span>, <span class="st">&quot;orange&quot;</span>))</a>
<a class="sourceLine" id="cb726-5" title="5"><span class="kw">round</span>(<span class="kw">cor</span>(snotel2[<span class="op">-</span><span class="kw">c</span>(<span class="dv">9</span>,<span class="dv">22</span>),<span class="dv">3</span><span class="op">:</span><span class="dv">6</span>]),<span class="dv">2</span>)</a></code></pre></div>
<div class="figure"><span id="fig:Figure8-12"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-12-1.png" alt="Plot of correlation matrix in the snow depth data set with influential points removed" width="624" />
<p class="caption">
Figure 1.161: Plot of correlation matrix in the snow depth data set with influential points removed
</p>
</div>
<pre><code>##            Max.Temp Min.Temp Elevation Snow.Depth
## Max.Temp       1.00     0.77     -0.84      -0.64
## Min.Temp       0.77     1.00     -0.91      -0.79
## Elevation     -0.84    -0.91      1.00       0.90
## Snow.Depth    -0.64    -0.79      0.90       1.00</code></pre>
<p>The predictors all share at least moderately strong linear relationships. For
example, the <span class="math inline">\(\boldsymbol{r}=-0.91\)</span> between <em>Min.Temp</em> and <em>Elevation</em>
suggests 
that they contain very similar information and that extends to other pairs of
variables as well. When variables share information, their addition to models
may not improve the performance of the model and actually can make the
estimated
coefficients <strong><em>unstable</em></strong>, creating uncertainty in the correct coefficients
because of the shared information. It seems that <em>Elevation</em> is related to
<em>Snow Depth</em> but maybe it is because it has lower <em>Minimum Temperatures</em>? So
you might wonder how we can find the “correct” slopes when they are sharing
information in the response variable. The short answer is that we can’t. But
we
do use <strong><em>Least Squares</em></strong> to find coefficient estimates as we did before –
except that we have to remember that these <strong>estimates are conditional on
other
variables in the model</strong> for our interpretation since they impact one another
within the model. It ends up that the uncertainty
of pinning those variables down in the presence of shared information leads to
larger SEs for all the slopes. And that we can actually measure <strong>how much
each of the SEs are inflated</strong> because of multicollinearity with other
variables
in the model using what are called <strong><em>Variance Inflation Factors</em></strong> (or
<strong><em>VIFs</em></strong>).</p></li>
</ul>
<p><strong><em>VIFs</em></strong> provide a way to assess the multicollinearity in the MLR model that
is caused by including specific variables.  The amount of information that is
shared between a single explanatory variable and the others can be found by
regressing that variable on the others and calculating <strong><em>R</em></strong><sup>2</sup>
for that model. The code for this regression is something like:
<code>lm(X1~X2+X3+...+XK)</code>, which regresses <em>X1</em>on <em>X2</em> through <em>XK</em>.

The
<span class="math inline">\(1-\boldsymbol{R}^2\)</span> from this regression is the amount of independent
information in <em>X1</em> that is not explained by the other variables in the model. 
The VIF for each variable is defined using this quantity as
<span class="math inline">\(\textbf{VIF}_{\boldsymbol{k}}\boldsymbol{=1/(1-R^2_k)}\)</span> for variable <span class="math inline">\(k\)</span>.
If there is no shared information <span class="math inline">\((\boldsymbol{R}^2=0)\)</span>, then the VIF will be
1. But if the information is completely shared with other variables
<span class="math inline">\((\boldsymbol{R}^2=1)\)</span>, then the VIF goes to infinity (1/0). Basically, large
VIFs are bad, with the rule of thumb that values over 5 or 10 are considered
“large” values indicating high multicollinearity in the model for that particular
variable. We use this scale to determine if multicollinearity is a problem for a
variable of interest. Additionally, the <span class="math inline">\(\boldsymbol{\sqrt{\textbf{VIF}_k}}\)</span> is
also very interesting as it is the number of times larger than the SE for the
slope for variable <span class="math inline">\(k\)</span> is due to collinearity with other variables in the model.
This is the most useful scale to understand VIFs even though the rules of thumb
are on the original scale. An example will show how to easily get these results
and where the results come from.</p>
<p>In general, the easy way to obtain VIFs is using the <code>vif</code> function from the
<code>car</code> package (<span class="citation">Fox, Weisberg, and Price (<a href="#ref-R-carData" role="doc-biblioref">2018</a>)</span>, <span class="citation">Fox (<a href="#ref-Fox2003" role="doc-biblioref">2003</a>)</span>).
 
It has the advantage of also providing a reasonable
result when we include categorical variables in models
(Sections <a href="7-9-section8-9.html#section8-9">7.9</a> and <a href="7-11-section8-11.html#section8-11">7.11</a>) over some other sources of this information in R. We apply the <code>vif</code>
function directly to a model of interest and it generates values for each explanatory variable.</p>
<div class="sourceCode" id="cb728"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb728-1" title="1"><span class="kw">library</span>(car)</a>
<a class="sourceLine" id="cb728-2" title="2"><span class="kw">vif</span>(m6)</a></code></pre></div>
<pre><code>## Elevation  Min.Temp  Max.Temp 
##  8.164201  5.995301  3.350914</code></pre>
<p>Not surprisingly, there is an indication of problems with multicollinearity in
two of the three variables in the model with the largest issues identified for
<em>Elevation</em> and <em>Min.Temp</em>. Both of their VIFs exceed 5 indicating large
multicollinearity problems. On the square-root scale, the VIFs show more
interpretation utility.</p>
<div class="sourceCode" id="cb730"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb730-1" title="1"><span class="kw">sqrt</span>(<span class="kw">vif</span>(m6))</a></code></pre></div>
<pre><code>## Elevation  Min.Temp  Max.Temp 
##  2.857307  2.448530  1.830550</code></pre>
<p>The result for <em>Elevation</em> of 2.86 suggests that the SE for <em>Elevation</em> is 2.86
times larger than it should be because of multicollinearity with other variables
in the model. Similarly, the <em>Min.Temp</em> SE is 2.45 times larger and the
<em>Max.Temp</em> SE is 1.83 times larger. All of this generally suggests issues with
multicollinearity in the model and that we need to be cautious in interpreting
any slope coefficients from this model because they are all being impacted by shared information in the predictor variables.</p>
<p>In order to see how the VIF is calculated for <em>Elevation</em>, we need to
regress <em>Elevation</em> on <em>Min.Temp</em> and <em>Max.Temp</em>. Note that this model is only
fit to find the percentage of variation in elevation explained by the temperature
variables. It ends up being 0.8775 – so a high percentage of <em>Elevation</em> can be
explained by the linear model using min and max temperatures.</p>

<div class="sourceCode" id="cb732"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb732-1" title="1"><span class="co">#VIF calc:</span></a>
<a class="sourceLine" id="cb732-2" title="2">elev1 &lt;-<span class="st"> </span><span class="kw">lm</span>(Elevation<span class="op">~</span>Min.Temp<span class="op">+</span>Max.Temp, <span class="dt">data=</span>snotel2[<span class="op">-</span><span class="kw">c</span>(<span class="dv">9</span>,<span class="dv">22</span>),])</a>
<a class="sourceLine" id="cb732-3" title="3"><span class="kw">summary</span>(elev1)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Elevation ~ Min.Temp + Max.Temp, data = snotel2[-c(9, 
##     22), ])
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1120.05  -142.99    14.45   186.73   624.61 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 14593.21     699.77  20.854 4.85e-15
## Min.Temp     -208.82      38.94  -5.363 3.00e-05
## Max.Temp      -56.28      20.90  -2.693    0.014
## 
## Residual standard error: 395.2 on 20 degrees of freedom
## Multiple R-squared:  0.8775, Adjusted R-squared:  0.8653 
## F-statistic: 71.64 on 2 and 20 DF,  p-value: 7.601e-10</code></pre>

<p>Using this result, we can calculate</p>
<p><span class="math display">\[\text{VIF}_{\text{elevation}} = \dfrac{1}{1-R^2_{\text{elevation}}} = \dfrac{1}{1-0.8775} = \dfrac{1}{0.1225} = 8.16\]</span></p>
<div class="sourceCode" id="cb734"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb734-1" title="1"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.8775</span></a></code></pre></div>
<pre><code>## [1] 0.1225</code></pre>
<div class="sourceCode" id="cb736"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb736-1" title="1"><span class="dv">1</span><span class="op">/</span><span class="fl">0.1225</span></a></code></pre></div>
<pre><code>## [1] 8.163265</code></pre>
<p>Note that when we observe small VIFs, that provides us with confidence that
multicollinearity is not causing problems under the surface of
a particular MLR model. And that we can’t use the VIFs to do anything about
multicollinearity in the models – it is just a diagnostic to understand the
magnitude of the problem.</p>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Fox2003">
<p>Fox, John. 2003. “Effect Displays in R for Generalised Linear Models.” <em>Journal of Statistical Software</em> 8 (15): 1–27. <a href="http://www.jstatsoft.org/v08/i15/">http://www.jstatsoft.org/v08/i15/</a>.</p>
</div>
<div id="ref-R-carData">
<p>Fox, John, Sanford Weisberg, and Brad Price. 2018. <em>CarData: Companion to Applied Regression Data Sets</em>. <a href="https://CRAN.R-project.org/package=carData">https://CRAN.R-project.org/package=carData</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="119">
<li id="fn119"><p>This section was inspired by a
similar section from <span class="citation">De Veaux, Velleman, and Bock (<a href="#ref-DeVeaux2011" role="doc-biblioref">2011</a>)</span>.<a href="7-5-section8-5.html#fnref119" class="footnote-back">↩</a></p></li>
</ol>
</div>
<p style="text-align: center;">
<a href="7-4-section8-4.html"><button class="btn btn-default">Previous</button></a>
<a href="7-6-section8-6.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
