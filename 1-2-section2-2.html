<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="1.2 Pirate-plots | Intermediate Statistics with R" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="gpeterson406/Greenwood_Book" />

<meta name="author" content="Mark C Greenwood" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="1.2 Pirate-plots | Intermediate Statistics with R">

<title>1.2 Pirate-plots | Intermediate Statistics with R</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#cover">Cover</a></li>
<li class="has-sub"><a href="acknowledgments.html#acknowledgments">Acknowledgments</a><ul>
<li><a href="0-1-section1-5.html#section1-5"><span class="toc-section-number">0.1</span> Summary of important R code</a></li>
</ul></li>
<li class="has-sub"><a href="1-chapter2.html#chapter2"><span class="toc-section-number">1</span> (R)e-Introduction to statistics</a><ul>
<li><a href="1-1-section2-1.html#section2-1"><span class="toc-section-number">1.1</span> Histograms, boxplots, and density curves</a></li>
<li><a href="1-2-section2-2.html#section2-2"><span class="toc-section-number">1.2</span> Pirate-plots</a></li>
<li><a href="1-3-section2-3.html#section2-3"><span class="toc-section-number">1.3</span> Models, hypotheses, and permutations for the two sample mean situation</a></li>
<li><a href="1-4-section2-4.html#section2-4"><span class="toc-section-number">1.4</span> Permutation testing for the two sample mean situation</a></li>
<li><a href="1-5-section2-5.html#section2-5"><span class="toc-section-number">1.5</span> Hypothesis testing (general)</a></li>
<li><a href="1-6-section2-6.html#section2-6"><span class="toc-section-number">1.6</span> Connecting randomization (nonparametric) and parametric tests</a></li>
<li><a href="1-7-section2-7.html#section2-7"><span class="toc-section-number">1.7</span> Second example of permutation tests</a></li>
<li><a href="1-8-section2-8.html#section2-8"><span class="toc-section-number">1.8</span> Reproducibility Crisis: Moving beyond p &lt; 0.05, publication bias, and multiple testing issues</a></li>
<li><a href="1-9-section2-9.html#section2-9"><span class="toc-section-number">1.9</span> Confidence intervals and bootstrapping</a></li>
<li><a href="1-10-section2-10.html#section2-10"><span class="toc-section-number">1.10</span> Bootstrap confidence intervals for difference in GPAs</a></li>
<li><a href="1-11-section2-11.html#section2-11"><span class="toc-section-number">1.11</span> Chapter summary</a></li>
<li><a href="1-12-section2-12.html#section2-12"><span class="toc-section-number">1.12</span> Summary of important R code</a></li>
<li><a href="1-13-section2-13.html#section2-13"><span class="toc-section-number">1.13</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="2-chapter3.html#chapter3"><span class="toc-section-number">2</span> One-Way ANOVA</a><ul>
<li><a href="2-1-section3-1.html#section3-1"><span class="toc-section-number">2.1</span> Situation</a></li>
<li><a href="2-2-section3-2.html#section3-2"><span class="toc-section-number">2.2</span> Linear model for One-Way ANOVA (cell-means and reference-coding)</a></li>
<li><a href="2-3-section3-3.html#section3-3"><span class="toc-section-number">2.3</span> One-Way ANOVA Sums of Squares, Mean Squares, and F-test</a></li>
<li><a href="2-4-section3-4.html#section3-4"><span class="toc-section-number">2.4</span> ANOVA model diagnostics including QQ-plots</a></li>
<li><a href="2-5-section3-5.html#section3-5"><span class="toc-section-number">2.5</span> Guinea pig tooth growth One-Way ANOVA example</a></li>
<li><a href="2-6-section3-6.html#section3-6"><span class="toc-section-number">2.6</span> Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display</a></li>
<li><a href="2-7-section3-7.html#section3-7"><span class="toc-section-number">2.7</span> Pair-wise comparisons for the Overtake data</a></li>
<li><a href="2-8-section3-8.html#section3-8"><span class="toc-section-number">2.8</span> Chapter summary</a></li>
<li><a href="2-9-section3-9.html#section3-9"><span class="toc-section-number">2.9</span> Summary of important R code</a></li>
<li><a href="2-10-section3-10.html#section3-10"><span class="toc-section-number">2.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="3-chapter4.html#chapter4"><span class="toc-section-number">3</span> Two-Way ANOVA</a><ul>
<li><a href="3-1-section4-1.html#section4-1"><span class="toc-section-number">3.1</span> Situation</a></li>
<li><a href="3-2-section4-2.html#section4-2"><span class="toc-section-number">3.2</span> Designing a two-way experiment and visualizing results</a></li>
<li><a href="3-3-section4-3.html#section4-3"><span class="toc-section-number">3.3</span> Two-Way ANOVA models and hypothesis tests</a></li>
<li><a href="3-4-section4-4.html#section4-4"><span class="toc-section-number">3.4</span> Guinea pig tooth growth analysis with Two-Way ANOVA</a></li>
<li><a href="3-5-section4-5.html#section4-5"><span class="toc-section-number">3.5</span> Observational study example: The Psychology of Debt</a></li>
<li><a href="3-6-section4-6.html#section4-6"><span class="toc-section-number">3.6</span> Pushing Two-Way ANOVA to the limit: Un-replicated designs and Estimability</a></li>
<li><a href="3-7-section4-7.html#section4-7"><span class="toc-section-number">3.7</span> Chapter summary</a></li>
<li><a href="3-8-section4-8.html#section4-8"><span class="toc-section-number">3.8</span> Summary of important R code</a></li>
<li><a href="3-9-section4-9.html#section4-9"><span class="toc-section-number">3.9</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="4-chapter5.html#chapter5"><span class="toc-section-number">4</span> Chi-square tests</a><ul>
<li><a href="4-1-section5-1.html#section5-1"><span class="toc-section-number">4.1</span> Situation, contingency tables, and tableplots</a></li>
<li><a href="4-2-section5-2.html#section5-2"><span class="toc-section-number">4.2</span> Homogeneity test hypotheses</a></li>
<li><a href="4-3-section5-3.html#section5-3"><span class="toc-section-number">4.3</span> Independence test hypotheses</a></li>
<li><a href="4-4-section5-4.html#section5-4"><span class="toc-section-number">4.4</span> Models for R by C tables</a></li>
<li><a href="4-5-section5-5.html#section5-5"><span class="toc-section-number">4.5</span> Permutation tests for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="4-6-section5-6.html#section5-6"><span class="toc-section-number">4.6</span> Chi-square distribution for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="4-7-section5-7.html#section5-7"><span class="toc-section-number">4.7</span> Examining residuals for the source of differences</a></li>
<li><a href="4-8-section5-8.html#section5-8"><span class="toc-section-number">4.8</span> General protocol for <span class="math inline">\(X^2\)</span> tests</a></li>
<li><a href="4-9-section5-9.html#section5-9"><span class="toc-section-number">4.9</span> Political party and voting results: Complete analysis</a></li>
<li><a href="4-10-section5-10.html#section5-10"><span class="toc-section-number">4.10</span> Is cheating and lying related in students?</a></li>
<li><a href="4-11-section5-11.html#section5-11"><span class="toc-section-number">4.11</span> Analyzing a stratified random sample of California schools</a></li>
<li><a href="4-12-section5-12.html#section5-12"><span class="toc-section-number">4.12</span> Chapter summary</a></li>
<li><a href="4-13-section5-13.html#section5-13"><span class="toc-section-number">4.13</span> Summary of important R commands</a></li>
<li><a href="4-14-section5-14.html#section5-14"><span class="toc-section-number">4.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="5-chapter6.html#chapter6"><span class="toc-section-number">5</span> Correlation and Simple Linear Regression</a><ul>
<li><a href="5-1-section6-1.html#section6-1"><span class="toc-section-number">5.1</span> Relationships between two quantitative variables</a></li>
<li><a href="5-2-section6-2.html#section6-2"><span class="toc-section-number">5.2</span> Estimating the correlation coefficient</a></li>
<li><a href="5-3-section6-3.html#section6-3"><span class="toc-section-number">5.3</span> Relationships between variables by groups</a></li>
<li><a href="5-4-section6-4.html#section6-4"><span class="toc-section-number">5.4</span> Inference for the correlation coefficient</a></li>
<li><a href="5-5-section6-5.html#section6-5"><span class="toc-section-number">5.5</span> Are tree diameters related to tree heights?</a></li>
<li><a href="5-6-section6-6.html#section6-6"><span class="toc-section-number">5.6</span> Describing relationships with a regression model</a></li>
<li><a href="5-7-section6-7.html#section6-7"><span class="toc-section-number">5.7</span> Least Squares Estimation</a></li>
<li><a href="5-8-section6-8.html#section6-8"><span class="toc-section-number">5.8</span> Measuring the strength of regressions: R<sup>2</sup></a></li>
<li><a href="5-9-section6-9.html#section6-9"><span class="toc-section-number">5.9</span> Outliers: leverage and influence</a></li>
<li><a href="5-10-section6-10.html#section6-10"><span class="toc-section-number">5.10</span> Residual diagnostics – setting the stage for inference</a></li>
<li><a href="5-11-section6-11.html#section6-11"><span class="toc-section-number">5.11</span> Old Faithful discharge and waiting times</a></li>
<li><a href="5-12-section6-12.html#section6-12"><span class="toc-section-number">5.12</span> Chapter summary</a></li>
<li><a href="5-13-section6-13.html#section6-13"><span class="toc-section-number">5.13</span> Summary of important R code</a></li>
<li><a href="5-14-section6-14.html#section6-14"><span class="toc-section-number">5.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="6-chapter7.html#chapter7"><span class="toc-section-number">6</span> Simple linear regression inference</a><ul>
<li><a href="6-1-section7-1.html#section7-1"><span class="toc-section-number">6.1</span> Model</a></li>
<li><a href="6-2-section7-2.html#section7-2"><span class="toc-section-number">6.2</span> Confidence interval and hypothesis tests for the slope and intercept</a></li>
<li><a href="6-3-section7-3.html#section7-3"><span class="toc-section-number">6.3</span> Bozeman temperature trend</a></li>
<li><a href="6-4-section7-4.html#section7-4"><span class="toc-section-number">6.4</span> Randomization-based inferences for the slope coefficient</a></li>
<li><a href="6-5-section7-5.html#section7-5"><span class="toc-section-number">6.5</span> Transformations part I: Linearizing relationships</a></li>
<li><a href="6-6-section7-6.html#section7-6"><span class="toc-section-number">6.6</span> Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x)</a></li>
<li><a href="6-7-section7-7.html#section7-7"><span class="toc-section-number">6.7</span> Confidence interval for the mean and prediction intervals for a new observation</a></li>
<li><a href="6-8-section7-8.html#section7-8"><span class="toc-section-number">6.8</span> Chapter summary</a></li>
<li><a href="6-9-section7-9.html#section7-9"><span class="toc-section-number">6.9</span> Summary of important R code</a></li>
<li><a href="6-10-section7-10.html#section7-10"><span class="toc-section-number">6.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="7-chapter8.html#chapter8"><span class="toc-section-number">7</span> Multiple linear regression</a><ul>
<li><a href="7-1-section8-1.html#section8-1"><span class="toc-section-number">7.1</span> Going from SLR to MLR</a></li>
<li><a href="7-2-section8-2.html#section8-2"><span class="toc-section-number">7.2</span> Validity conditions in MLR</a></li>
<li><a href="7-3-section8-3.html#section8-3"><span class="toc-section-number">7.3</span> Interpretation of MLR terms</a></li>
<li><a href="7-4-section8-4.html#section8-4"><span class="toc-section-number">7.4</span> Comparing multiple regression models</a></li>
<li><a href="7-5-section8-5.html#section8-5"><span class="toc-section-number">7.5</span> General recommendations for MLR interpretations and VIFs</a></li>
<li><a href="7-6-section8-6.html#section8-6"><span class="toc-section-number">7.6</span> MLR inference: Parameter inferences using the t-distribution</a></li>
<li><a href="7-7-section8-7.html#section8-7"><span class="toc-section-number">7.7</span> Overall F-test in multiple linear regression</a></li>
<li><a href="7-8-section8-8.html#section8-8"><span class="toc-section-number">7.8</span> Case study: First year college GPA and SATs</a></li>
<li><a href="7-9-section8-9.html#section8-9"><span class="toc-section-number">7.9</span> Different intercepts for different groups: MLR with indicator variables</a></li>
<li><a href="7-10-section8-10.html#section8-10"><span class="toc-section-number">7.10</span> Additive MLR with more than two groups: Headache example</a></li>
<li><a href="7-11-section8-11.html#section8-11"><span class="toc-section-number">7.11</span> Different slopes and different intercepts</a></li>
<li><a href="7-12-section8-12.html#section8-12"><span class="toc-section-number">7.12</span> F-tests for MLR models with quantitative and categorical variables and interactions</a></li>
<li><a href="7-13-section8-13.html#section8-13"><span class="toc-section-number">7.13</span> AICs for model selection</a></li>
<li><a href="7-14-section8-14.html#section8-14"><span class="toc-section-number">7.14</span> Case study: Forced expiratory volume model selection using AICs</a></li>
<li><a href="7-15-section8-15.html#section8-15"><span class="toc-section-number">7.15</span> Chapter summary</a></li>
<li><a href="7-16-section8-16.html#section8-16"><span class="toc-section-number">7.16</span> Summary of important R code</a></li>
<li><a href="7-17-section8-17.html#section8-17"><span class="toc-section-number">7.17</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="8-chapter9.html#chapter9"><span class="toc-section-number">8</span> Case studies</a><ul>
<li><a href="8-1-section9-1.html#section9-1"><span class="toc-section-number">8.1</span> Overview of material covered</a></li>
<li><a href="8-2-section9-2.html#section9-2"><span class="toc-section-number">8.2</span> The impact of simulated chronic nitrogen deposition on the biomass and N2-fixation activity of two boreal feather moss–cyanobacteria associations</a></li>
<li><a href="8-3-section9-3.html#section9-3"><span class="toc-section-number">8.3</span> Ants learn to rely on more informative attributes during decision-making</a></li>
<li><a href="8-4-section9-4.html#section9-4"><span class="toc-section-number">8.4</span> Multi-variate models are essential for understanding vertebrate diversification in deep time</a></li>
<li><a href="8-5-section9-5.html#section9-5"><span class="toc-section-number">8.5</span> What do didgeridoos really do about sleepiness?</a></li>
<li><a href="8-6-section9-6.html#section9-6"><span class="toc-section-number">8.6</span> General summary</a></li>
</ul></li>
<li><a href="references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="section2-2" class="section level2">
<h2><span class="header-section-number">1.2</span> Pirate-plots</h2>
<p>An alternative graphical display for comparing multiple groups that we will use is a display called a <strong><em>pirate-plot</em></strong> <span class="citation">(Phillips <a href="#ref-Phillips2017" role="doc-biblioref">2017</a>)</span> from the <code>yarrr</code> package<a href="#fn21" class="footnote-ref" id="fnref21"><sup>21</sup></a>.  Figure <a href="1-2-section2-2.html#fig:Figure2-5">1.5</a>
shows an example of a pirate-plot that provides a side-by-side display that
contains the density curves, the original observations that generated the
density curve as jittered points (jittered both vertically and horizontally a little), the sample mean of each group (wide bar), and a box that represents the confidence interval for the true mean of that group. For each group, the density curves
are mirrored to aid in visual assessment of the shape of the distribution. This mirroring also
creates a shape that resembles the outline of a violin with skewed distributions so versions of this
display have also been called a “violin plot” or a “bean plot”. All together this plot shows us information
on the original observations, center (mean) and its confidence interval, spread, and shape of the distributions of the responses. Our inferences typically focus on the means of the groups and this plot allows
us to compare those across the groups while gaining information on the shapes
of the distributions of responses in each group.</p>
<p>To use the <code>pirateplot</code> function  we need to install and then load the <code>yarrr</code>
package <span class="citation">(<span class="citeproc-not-found" data-reference-id="R-yarrr"><strong>???</strong></span>)</span>.

The function works like the boxplot used previously
except that options
for the type of confidence interval needs to be specified with <code>inf.method="ci</code> - otherwise you will get a different kind of interval than you learned in introductory statistics and we don’t want to get caught up in trying to understand the kind of interval it makes by default. There are many other options in the function that might be useful in certain situations, but that is the only one that is really needed to get started with pirate-plots.</p>
<p>(ref:fig2-5) Pirate-plot of distances by outfit group. Bold horizontal lines correspond
to sample mean of each group, boxes around lines (here they are very narrow here) are the 95% confidence intervals.</p>
<div class="figure"><span id="fig:Figure2-5"></span>
<img src="02-reintroductionToStatistics_files/figure-html/Figure2-5-1.png" alt="(ref:fig2-5)" width="480" />
<p class="caption">
Figure 1.5: (ref:fig2-5)
</p>
</div>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb44-1" title="1"><span class="kw">library</span>(yarrr)</a>
<a class="sourceLine" id="cb44-2" title="2"><span class="kw">pirateplot</span>(Distance<span class="op">~</span>Condition,<span class="dt">data=</span>dd,<span class="dt">inf.method=</span><span class="st">&quot;ci&quot;</span>)</a></code></pre></div>
<p>Because of the relatively symmetric nature of the distributions, the means and medians are similar, as shown in Figure <a href="1-2-section2-2.html#fig:Figure2-5">1.5</a>. In this display, none of the observations are flagged as outliers (it is not a part of this display). It is up to the consumer of the graphic to decide if observations look to be outside of the overall pattern of the rest of the observations. By plotting the observations by groups, we can also explore the narrowest (and likely most scary) overtakes in the data set. The <em>police</em> and <em>racer</em> conditions seem to have all observations over 25 cm and the most close passes were in the <em>novice</em> and <em>polite</em> outfits, including the two 2 cm passes. By displaying the original observations, we are able to explore and identify features that aggregation and summarization in plots can sometimes obfuscate. But the pirate-plots also allow up to compare the shape of the distributions (relatively symmetric and somewhat bell-shaped), variability (they look to have relatively similar variability) and the means of the groups. Our inferences are going to focus on the means but those inferences are only valid if the distributions are either approximately normal or at least similar shapes and spreads (more on this soon).</p>
<p>It appears that the mean for <em>police</em> is higher than the other groups but that the others are not too different. But is this difference real? We will never
know the answer to that question, but we
can assess how likely we are to have seen a result as extreme or more
extreme than our result, assuming that there is no difference in the
means of the groups. And if the observed result is
(extremely) unlikely to occur, then we can reject the hypothesis that the
groups have the same mean and conclude that there is evidence of a real
difference. After that, we will want to carefully explore how big the estimated differences in the means are - is this enough of a difference to matter to you or the subject in the study? To accompany the pirate-plot, we
need to have numerical values to compare. We can get means and standard
deviations by groups easily using the same formula notation as for the plots with the <code>mean</code>
and <code>sd</code> functions, if the <code>mosaic</code> package is loaded.</p>

<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb45-1" title="1"><span class="kw">library</span>(mosaic)</a>
<a class="sourceLine" id="cb45-2" title="2"><span class="kw">mean</span>(Distance<span class="op">~</span>Condition, <span class="dt">data=</span>dd)</a></code></pre></div>
<pre><code>##   casual  commute    hiviz   novice   police   polite    racer 
## 117.6110 114.6079 118.4383 116.9405 122.1215 114.0518 116.7559</code></pre>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb47-1" title="1"><span class="kw">sd</span>(Distance<span class="op">~</span>Condition, <span class="dt">data=</span>dd)</a></code></pre></div>
<pre><code>##   casual  commute    hiviz   novice   police   polite    racer 
## 29.86954 29.63166 29.03384 29.03812 29.73662 31.23684 30.60059</code></pre>
<p>We can also use the <code>favstats</code> function to get those summaries and others by groups.</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb49-1" title="1"><span class="kw">favstats</span>(Distance<span class="op">~</span>Condition, <span class="dt">data=</span>dd)</a></code></pre></div>
<pre><code>##   Condition min    Q1 median  Q3 max     mean       sd   n missing
## 1    casual  17 100.0    117 134 245 117.6110 29.86954 779       0
## 2   commute   8  98.0    116 132 222 114.6079 29.63166 857       0
## 3     hiviz  12 101.0    117 134 237 118.4383 29.03384 737       0
## 4    novice   2 100.5    118 133 274 116.9405 29.03812 807       0
## 5    police  34 104.0    119 138 253 122.1215 29.73662 790       0
## 6    polite   2  95.0    114 133 225 114.0518 31.23684 868       0
## 7     racer  28  98.0    117 135 231 116.7559 30.60059 852       0</code></pre>
<p>Based on these results, we can see that there is an estimated difference of over 8 cm between the smallest mean (<em>polite</em> at 114.05 cm) and the largest mean (<em>police</em> at 122.12 cm). The differences among some of the other groups are much smaller, such as between <em>casual</em> and <em>commute</em> with sample means of 117.611 and 114.608 cm, respectively. Because there are seven groups being compared in this study, we will have to
wait until Chapter 3 and the One-Way ANOVA test to fully assess evidence
related to some difference among the seven groups. For now, we are going to
focus on comparing the mean <em>Distance</em> between <em>casual</em> and <em>commute</em> groups
– which is a <strong><em>two independent sample mean</em></strong> situation and something you
should have seen before. Remember that the “independent” sample part of
this refers to observations that are independently observed for the two
groups as opposed to the paired sample situation that you may have
explored where one observation from the first group is related to an
observation in the second group (the same person with one measurement in each group (we
generically call this “repeated measures”)
or the famous “twin” studies with one twin assigned to each group).  This study has some potential violations of the “independent” sample situation (for example, repeated measurements made during a single ride), but those do not clearly fit into the matched pairs situation, so we will note this potential issue and proceed with exploring the method that assumes that we have independent samples, even though this is not true here. In Chapter 9, methods for more complex study designs like this one will be discussed briefly, but mostly this is beyond the scope of this material.</p>
<p>Here we are going to use the “simple” two independent group scenario to
review some basic statistical concepts and connect two different
frameworks for conducting statistical inference: randomization and
parametric  inference techniques. <strong><em>Parametric</em></strong> statistical methods
involve making assumptions

about the distribution of the
responses and obtaining confidence intervals and/or p-values using a
<em>named</em> distribution (like the <span class="math inline">\(z\)</span> or <span class="math inline">\(t\)</span>-distributions). Typically these
results are generated using formulas and looking up areas under curves or
cutoffs using a table or a computer. <strong><em>Randomization</em></strong>-based statistical
methods use a computer to shuffle, sample, or simulate observations in ways
that allow you to obtain distributions of possible results to find areas and
cutoffs without resorting to using tables and named distributions.
Randomization methods are what are called <strong><em>nonparametric</em></strong> methods

that often make fewer assumptions (they are <strong><em>not free of assumptions</em></strong>!)
and so can handle a larger set of problems more easily than parametric
methods.

When the assumptions involved in the parametric procedures are
met by a data set, the randomization methods often provide very similar
results to those provided by the parametric techniques. To be a more
sophisticated statistical consumer, it is useful to have some knowledge
of both of these techniques for performing statistical inference and the fact that they can provide similar results might deepen your understanding of both
approaches.</p>
<p>To be able to work just with the observations from two of the conditions (<em>casual</em> and <em>commute</em>) we could remove all the other observations in a spreadsheet program and read that new data set
back into R, but it is actually pretty easy to use R to do data
management once the data set is loaded. It is also a better scientific process to do as much of your data management within R as possible so that your steps in managing the data are fully documented and reproducible. Highlighting and clicking in spreadsheet programs is a dangerous way to work and can be impossible to recreate steps that were taken from initial data set to the version that was analyzed. In R, we could identify the rows that contain the observations we want to retain and just extract those rows, but this is hard with over five thousand observations. The <code>subset</code> function (also an option in some functions) is the best way to be able to focus on observations that meet a particular condition, we can “subset” the data set to retain those rows. The <code>subset</code> function takes the data set as its first argument and then in the “subset” option, we need to define the condition we want to meet to retain those rows. Specifically, we need to define the variable we want to work with, <code>Condition</code> and then request rows that meet a condition (are <code>%in%</code>) and the aspects that meet that condition (here by concatenating “casual” and “commute”), leading to code of:</p>
<pre><code>subset(dd, Condition %in% c(&quot;casual&quot;, &quot;commute&quot;))</code></pre>
<p>We would actually want to save that new subsetted data set into a new tibble for future work, so we can use the following to save the reduced data set into <code>ddsub</code>:</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb52-1" title="1">ddsub &lt;-<span class="st"> </span><span class="kw">subset</span>(dd, Condition <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;casual&quot;</span>, <span class="st">&quot;commute&quot;</span>))</a></code></pre></div>
<p>There is also a “select” option that we could also use to just focus on certain columns in the data set and we can use that just to focus on the <code>Condition</code> and <code>Distance</code> variables using:</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb53-1" title="1">ddsub &lt;-<span class="st"> </span><span class="kw">subset</span>(dd, Condition <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;casual&quot;</span>, <span class="st">&quot;commute&quot;</span>), <span class="dt">select=</span><span class="kw">c</span>(<span class="st">&quot;Distance&quot;</span>, <span class="st">&quot;Condition&quot;</span>))</a></code></pre></div>
<p>You will always want to check that the correct observations were dropped
either using <code>View(ddsub)</code> or by doing a quick summary of the
<code>Condition</code> variable in the new tibble.</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb54-1" title="1"><span class="kw">summary</span>(ddsub<span class="op">$</span>Condition)</a></code></pre></div>
<pre><code>##  casual commute   hiviz  novice  police  polite   racer 
##     779     857       0       0       0       0       0</code></pre>
<p>It ends up that R remembers the other categories even though there are
0 observations in them now and that can cause us some problems. When we remove a
group of observations, we sometimes need to clean up categorical variables to
just reflect the categories that are present. The <code>factor</code>

function
creates categorical variables based on the levels of the variables that are
observed and is useful to run here to clean up <code>Condition</code> to just reflect the categories that are now present.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb56-1" title="1">ddsub<span class="op">$</span>Condition &lt;-<span class="st"> </span><span class="kw">factor</span>(ddsub<span class="op">$</span>Condition)</a>
<a class="sourceLine" id="cb56-2" title="2"><span class="kw">summary</span>(ddsub<span class="op">$</span>Condition)</a></code></pre></div>
<pre><code>##  casual commute 
##     779     857</code></pre>
<p>The two categories of interest now were selected because neither looks particularly “racey” or has high visibility but could present a common choice between getting fully “geared up” for the commute or just jumping on a bike to go to work. Now if we remake the boxplots and pirate-plots, they only contain results for
the two groups of interest here as seen in Figure <a href="1-2-section2-2.html#fig:Figure2-6">1.6</a>. Note that these are available in the previous version of the plots, but now we will just focus on these two groups.</p>

<div class="figure"><span id="fig:Figure2-6"></span>
<img src="02-reintroductionToStatistics_files/figure-html/Figure2-6-1.png" alt="Boxplot and pirate-plot of the Distance responses on the reduced ddsub data set." width="552" />
<p class="caption">
Figure 1.6: Boxplot and pirate-plot of the <em>Distance</em> responses on the reduced <code>ddsub</code> data set.
</p>
</div>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb58-1" title="1"><span class="kw">boxplot</span>(Distance<span class="op">~</span>Condition,<span class="dt">data=</span>ddsub) </a>
<a class="sourceLine" id="cb58-2" title="2"><span class="kw">pirateplot</span>(Distance<span class="op">~</span>Condition,<span class="dt">data=</span>ddsub,<span class="dt">inf.method=</span><span class="st">&quot;ci&quot;</span>)</a></code></pre></div>
<p>The two-sample mean techniques you learned in your previous course all
start with comparing the means the two groups. We can obtain the two
means using the <code>mean</code> function or directly obtain the difference
in the means using the <code>diffmean</code> function (both require the <code>mosaic</code>
package). The <code>diffmean</code> function provides
<span class="math inline">\(\bar{x}_\text{commute} - \bar{x}_\text{casual}\)</span> where <span class="math inline">\(\bar{x}\)</span>
(read as “x-bar”) is the sample mean of observations in the subscripted
group. Note that there are two directions that you could compare the
means and this function chooses to take the mean from the second group
name <em>alphabetically</em> and subtract the mean from the first alphabetical group
name. It is always good to check the direction of this calculation as
having a difference of <span class="math inline">\(-3.003\)</span> cm versus <span class="math inline">\(3.003\)</span> cm could be important.</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb59-1" title="1"><span class="kw">mean</span>(Distance<span class="op">~</span>Condition,<span class="dt">data=</span>ddsub)</a></code></pre></div>
<pre><code>##   casual  commute 
## 117.6110 114.6079</code></pre>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb61-1" title="1"><span class="kw">diffmean</span>(Distance<span class="op">~</span>Condition,<span class="dt">data=</span>ddsub)</a></code></pre></div>
<pre><code>##  diffmean 
## -3.003105</code></pre>

</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Phillips2017">
<p>Phillips, Nathaniel. 2017. <em>Yarrr: A Companion to the E-Book "Yarrr!: The Pirate’s Guide to R"</em>. <a href="https://CRAN.R-project.org/package=yarrr">https://CRAN.R-project.org/package=yarrr</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="21">
<li id="fn21"><p>The package and function are intentionally amusingly titled but are based on ideas in the beanplot <span class="citation">Kampstra (<a href="#ref-Kampstra2008" role="doc-biblioref">2008</a>)</span> and provide what they call an <strong><em>RDI graphic</em></strong> - <strong><em>R</em></strong>aw data, <strong><em>D</em></strong>escriptive and <strong><em>I</em></strong>nferential statistic in the same display.<a href="1-2-section2-2.html#fnref21" class="footnote-back">↩</a></p></li>
</ol>
</div>
<p style="text-align: center;">
<a href="1-1-section2-1.html"><button class="btn btn-default">Previous</button></a>
<a href="1-3-section2-3.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
