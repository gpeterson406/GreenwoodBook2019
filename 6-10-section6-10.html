<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="6.10 Residual diagnostics – setting the stage for inference | Intermediate Statistics with R" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="gpeterson406/Greenwood_Book" />

<meta name="author" content="Mark C Greenwood" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="6.10 Residual diagnostics – setting the stage for inference | Intermediate Statistics with R">

<title>6.10 Residual diagnostics – setting the stage for inference | Intermediate Statistics with R</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#cover">Cover</a></li>
<li><a href="acknowledgments.html#acknowledgments">Acknowledgments</a></li>
<li class="has-sub"><a href="1-chapter1.html#chapter1"><span class="toc-section-number">1</span> Preface</a><ul>
<li><a href="1-1-section1-1.html#section1-1"><span class="toc-section-number">1.1</span> Overview of methods</a></li>
<li><a href="1-2-section1-2.html#section1-2"><span class="toc-section-number">1.2</span> Getting started in R</a></li>
<li><a href="1-3-section1-3.html#section1-3"><span class="toc-section-number">1.3</span> Basic summary statistics, histograms, and boxplots using R</a></li>
<li><a href="1-4-section1-4.html#section1-4"><span class="toc-section-number">1.4</span> Chapter summary</a></li>
<li><a href="1-5-section1-5.html#section1-5"><span class="toc-section-number">1.5</span> Summary of important R code</a></li>
<li><a href="1-6-section1-6.html#section1-6"><span class="toc-section-number">1.6</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="2-chapter2.html#chapter2"><span class="toc-section-number">2</span> (R)e-Introduction to statistics</a><ul>
<li><a href="2-1-section2-1.html#section2-1"><span class="toc-section-number">2.1</span> Histograms, boxplots, and density curves</a></li>
<li><a href="2-2-section2-2.html#section2-2"><span class="toc-section-number">2.2</span> Pirate-plots</a></li>
<li><a href="2-3-section2-3.html#section2-3"><span class="toc-section-number">2.3</span> Models, hypotheses, and permutations for the two sample mean situation</a></li>
<li><a href="2-4-section2-4.html#section2-4"><span class="toc-section-number">2.4</span> Permutation testing for the two sample mean situation</a></li>
<li><a href="2-5-section2-5.html#section2-5"><span class="toc-section-number">2.5</span> Hypothesis testing (general)</a></li>
<li><a href="2-6-section2-6.html#section2-6"><span class="toc-section-number">2.6</span> Connecting randomization (nonparametric) and parametric tests</a></li>
<li><a href="2-7-section2-7.html#section2-7"><span class="toc-section-number">2.7</span> Second example of permutation tests</a></li>
<li><a href="2-8-section2-8.html#section2-8"><span class="toc-section-number">2.8</span> Reproducibility Crisis: Moving beyond p &lt; 0.05, publication bias, and multiple testing issues</a></li>
<li><a href="2-9-section2-9.html#section2-9"><span class="toc-section-number">2.9</span> Confidence intervals and bootstrapping</a></li>
<li><a href="2-10-section2-10.html#section2-10"><span class="toc-section-number">2.10</span> Bootstrap confidence intervals for difference in GPAs</a></li>
<li><a href="2-11-section2-11.html#section2-11"><span class="toc-section-number">2.11</span> Chapter summary</a></li>
<li><a href="2-12-section2-12.html#section2-12"><span class="toc-section-number">2.12</span> Summary of important R code</a></li>
<li><a href="2-13-section2-13.html#section2-13"><span class="toc-section-number">2.13</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="3-chapter3.html#chapter3"><span class="toc-section-number">3</span> One-Way ANOVA</a><ul>
<li><a href="3-1-section3-1.html#section3-1"><span class="toc-section-number">3.1</span> Situation</a></li>
<li><a href="3-2-section3-2.html#section3-2"><span class="toc-section-number">3.2</span> Linear model for One-Way ANOVA (cell-means and reference-coding)</a></li>
<li><a href="3-3-section3-3.html#section3-3"><span class="toc-section-number">3.3</span> One-Way ANOVA Sums of Squares, Mean Squares, and F-test</a></li>
<li><a href="3-4-section3-4.html#section3-4"><span class="toc-section-number">3.4</span> ANOVA model diagnostics including QQ-plots</a></li>
<li><a href="3-5-section3-5.html#section3-5"><span class="toc-section-number">3.5</span> Guinea pig tooth growth One-Way ANOVA example</a></li>
<li><a href="3-6-section3-6.html#section3-6"><span class="toc-section-number">3.6</span> Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display</a></li>
<li><a href="3-7-section3-7.html#section3-7"><span class="toc-section-number">3.7</span> Pair-wise comparisons for the Overtake data</a></li>
<li><a href="3-8-section3-8.html#section3-8"><span class="toc-section-number">3.8</span> Chapter summary</a></li>
<li><a href="3-9-section3-9.html#section3-9"><span class="toc-section-number">3.9</span> Summary of important R code</a></li>
<li><a href="3-10-section3-10.html#section3-10"><span class="toc-section-number">3.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="4-chapter4.html#chapter4"><span class="toc-section-number">4</span> Two-Way ANOVA</a><ul>
<li><a href="4-1-section4-1.html#section4-1"><span class="toc-section-number">4.1</span> Situation</a></li>
<li><a href="4-2-section4-2.html#section4-2"><span class="toc-section-number">4.2</span> Designing a two-way experiment and visualizing results</a></li>
<li><a href="4-3-section4-3.html#section4-3"><span class="toc-section-number">4.3</span> Two-Way ANOVA models and hypothesis tests</a></li>
<li><a href="4-4-section4-4.html#section4-4"><span class="toc-section-number">4.4</span> Guinea pig tooth growth analysis with Two-Way ANOVA</a></li>
<li><a href="4-5-section4-5.html#section4-5"><span class="toc-section-number">4.5</span> Observational study example: The Psychology of Debt</a></li>
<li><a href="4-6-section4-6.html#section4-6"><span class="toc-section-number">4.6</span> Pushing Two-Way ANOVA to the limit: Un-replicated designs and Estimability</a></li>
<li><a href="4-7-section4-7.html#section4-7"><span class="toc-section-number">4.7</span> Chapter summary</a></li>
<li><a href="4-8-section4-8.html#section4-8"><span class="toc-section-number">4.8</span> Summary of important R code</a></li>
<li><a href="4-9-section4-9.html#section4-9"><span class="toc-section-number">4.9</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="5-chapter5.html#chapter5"><span class="toc-section-number">5</span> Chi-square tests</a><ul>
<li><a href="5-1-section5-1.html#section5-1"><span class="toc-section-number">5.1</span> Situation, contingency tables, and tableplots</a></li>
<li><a href="5-2-section5-2.html#section5-2"><span class="toc-section-number">5.2</span> Homogeneity test hypotheses</a></li>
<li><a href="5-3-section5-3.html#section5-3"><span class="toc-section-number">5.3</span> Independence test hypotheses</a></li>
<li><a href="5-4-section5-4.html#section5-4"><span class="toc-section-number">5.4</span> Models for R by C tables</a></li>
<li><a href="5-5-section5-5.html#section5-5"><span class="toc-section-number">5.5</span> Permutation tests for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="5-6-section5-6.html#section5-6"><span class="toc-section-number">5.6</span> Chi-square distribution for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="5-7-section5-7.html#section5-7"><span class="toc-section-number">5.7</span> Examining residuals for the source of differences</a></li>
<li><a href="5-8-section5-8.html#section5-8"><span class="toc-section-number">5.8</span> General protocol for <span class="math inline">\(X^2\)</span> tests</a></li>
<li><a href="5-9-section5-9.html#section5-9"><span class="toc-section-number">5.9</span> Political party and voting results: Complete analysis</a></li>
<li><a href="5-10-section5-10.html#section5-10"><span class="toc-section-number">5.10</span> Is cheating and lying related in students?</a></li>
<li><a href="5-11-section5-11.html#section5-11"><span class="toc-section-number">5.11</span> Analyzing a stratified random sample of California schools</a></li>
<li><a href="5-12-section5-12.html#section5-12"><span class="toc-section-number">5.12</span> Chapter summary</a></li>
<li><a href="5-13-section5-13.html#section5-13"><span class="toc-section-number">5.13</span> Summary of important R commands</a></li>
<li><a href="5-14-section5-14.html#section5-14"><span class="toc-section-number">5.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="6-chapter6.html#chapter6"><span class="toc-section-number">6</span> Correlation and Simple Linear Regression</a><ul>
<li><a href="6-1-section6-1.html#section6-1"><span class="toc-section-number">6.1</span> Relationships between two quantitative variables</a></li>
<li><a href="6-2-section6-2.html#section6-2"><span class="toc-section-number">6.2</span> Estimating the correlation coefficient</a></li>
<li><a href="6-3-section6-3.html#section6-3"><span class="toc-section-number">6.3</span> Relationships between variables by groups</a></li>
<li><a href="6-4-section6-4.html#section6-4"><span class="toc-section-number">6.4</span> Inference for the correlation coefficient</a></li>
<li><a href="6-5-section6-5.html#section6-5"><span class="toc-section-number">6.5</span> Are tree diameters related to tree heights?</a></li>
<li><a href="6-6-section6-6.html#section6-6"><span class="toc-section-number">6.6</span> Describing relationships with a regression model</a></li>
<li><a href="6-7-section6-7.html#section6-7"><span class="toc-section-number">6.7</span> Least Squares Estimation</a></li>
<li><a href="6-8-section6-8.html#section6-8"><span class="toc-section-number">6.8</span> Measuring the strength of regressions: R<sup>2</sup></a></li>
<li><a href="6-9-section6-9.html#section6-9"><span class="toc-section-number">6.9</span> Outliers: leverage and influence</a></li>
<li><a href="6-10-section6-10.html#section6-10"><span class="toc-section-number">6.10</span> Residual diagnostics – setting the stage for inference</a></li>
<li><a href="6-11-section6-11.html#section6-11"><span class="toc-section-number">6.11</span> Old Faithful discharge and waiting times</a></li>
<li><a href="6-12-section6-12.html#section6-12"><span class="toc-section-number">6.12</span> Chapter summary</a></li>
<li><a href="6-13-section6-13.html#section6-13"><span class="toc-section-number">6.13</span> Summary of important R code</a></li>
<li><a href="6-14-section6-14.html#section6-14"><span class="toc-section-number">6.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="7-chapter7.html#chapter7"><span class="toc-section-number">7</span> Simple linear regression inference</a><ul>
<li><a href="7-1-section7-1.html#section7-1"><span class="toc-section-number">7.1</span> Model</a></li>
<li><a href="7-2-section7-2.html#section7-2"><span class="toc-section-number">7.2</span> Confidence interval and hypothesis tests for the slope and intercept</a></li>
<li><a href="7-3-section7-3.html#section7-3"><span class="toc-section-number">7.3</span> Bozeman temperature trend</a></li>
<li><a href="7-4-section7-4.html#section7-4"><span class="toc-section-number">7.4</span> Randomization-based inferences for the slope coefficient</a></li>
<li><a href="7-5-section7-5.html#section7-5"><span class="toc-section-number">7.5</span> Transformations part I: Linearizing relationships</a></li>
<li><a href="7-6-section7-6.html#section7-6"><span class="toc-section-number">7.6</span> Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x)</a></li>
<li><a href="7-7-section7-7.html#section7-7"><span class="toc-section-number">7.7</span> Confidence interval for the mean and prediction intervals for a new observation</a></li>
<li><a href="7-8-section7-8.html#section7-8"><span class="toc-section-number">7.8</span> Chapter summary</a></li>
<li><a href="7-9-section7-9.html#section7-9"><span class="toc-section-number">7.9</span> Summary of important R code</a></li>
<li><a href="7-10-section7-10.html#section7-10"><span class="toc-section-number">7.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="8-chapter8.html#chapter8"><span class="toc-section-number">8</span> Multiple linear regression</a><ul>
<li><a href="8-1-section8-1.html#section8-1"><span class="toc-section-number">8.1</span> Going from SLR to MLR</a></li>
<li><a href="8-2-section8-2.html#section8-2"><span class="toc-section-number">8.2</span> Validity conditions in MLR</a></li>
<li><a href="8-3-section8-3.html#section8-3"><span class="toc-section-number">8.3</span> Interpretation of MLR terms</a></li>
<li><a href="8-4-section8-4.html#section8-4"><span class="toc-section-number">8.4</span> Comparing multiple regression models</a></li>
<li><a href="8-5-section8-5.html#section8-5"><span class="toc-section-number">8.5</span> General recommendations for MLR interpretations and VIFs</a></li>
<li><a href="8-6-section8-6.html#section8-6"><span class="toc-section-number">8.6</span> MLR inference: Parameter inferences using the t-distribution</a></li>
<li><a href="8-7-section8-7.html#section8-7"><span class="toc-section-number">8.7</span> Overall F-test in multiple linear regression</a></li>
<li><a href="8-8-section8-8.html#section8-8"><span class="toc-section-number">8.8</span> Case study: First year college GPA and SATs</a></li>
<li><a href="8-9-section8-9.html#section8-9"><span class="toc-section-number">8.9</span> Different intercepts for different groups: MLR with indicator variables</a></li>
<li><a href="8-10-section8-10.html#section8-10"><span class="toc-section-number">8.10</span> Additive MLR with more than two groups: Headache example</a></li>
<li><a href="8-11-section8-11.html#section8-11"><span class="toc-section-number">8.11</span> Different slopes and different intercepts</a></li>
<li><a href="8-12-section8-12.html#section8-12"><span class="toc-section-number">8.12</span> F-tests for MLR models with quantitative and categorical variables and interactions</a></li>
<li><a href="8-13-section8-13.html#section8-13"><span class="toc-section-number">8.13</span> AICs for model selection</a></li>
<li><a href="8-14-section8-14.html#section8-14"><span class="toc-section-number">8.14</span> Case study: Forced expiratory volume model selection using AICs</a></li>
<li><a href="8-15-section8-15.html#section8-15"><span class="toc-section-number">8.15</span> Chapter summary</a></li>
<li><a href="8-16-section8-16.html#section8-16"><span class="toc-section-number">8.16</span> Summary of important R code</a></li>
<li><a href="8-17-section8-17.html#section8-17"><span class="toc-section-number">8.17</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="9-chapter9.html#chapter9"><span class="toc-section-number">9</span> Case studies</a><ul>
<li><a href="9-1-section9-1.html#section9-1"><span class="toc-section-number">9.1</span> Overview of material covered</a></li>
<li><a href="9-2-section9-2.html#section9-2"><span class="toc-section-number">9.2</span> The impact of simulated chronic nitrogen deposition on the biomass and N2-fixation activity of two boreal feather moss–cyanobacteria associations</a></li>
<li><a href="9-3-section9-3.html#section9-3"><span class="toc-section-number">9.3</span> Ants learn to rely on more informative attributes during decision-making</a></li>
<li><a href="9-4-section9-4.html#section9-4"><span class="toc-section-number">9.4</span> Multi-variate models are essential for understanding vertebrate diversification in deep time</a></li>
<li><a href="9-5-section9-5.html#section9-5"><span class="toc-section-number">9.5</span> What do didgeridoos really do about sleepiness?</a></li>
<li><a href="9-6-section9-6.html#section9-6"><span class="toc-section-number">9.6</span> General summary</a></li>
</ul></li>
<li><a href="references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="section6-10" class="section level2">
<h2><span class="header-section-number">6.10</span> Residual diagnostics – setting the stage for inference</h2>
<p>Influential points are not the
only potential issue that can cause us to have concerns about our regression
model. There are two levels to these considerations. The first is related to
issues that directly impact the least squares regression line and cause
concerns about whether a line is a reasonable representation of the
relationship between the two variables. These issues for regression model
estimation have been discussed previously (the same concerns in estimating
correlation apply to regression models). The second level is whether the line
we have will be useful for making inferences for the population that our data
were collected from and whether the data follow our assumed model. Our window
into problems of both types is the residuals <span class="math inline">\((e_i = y_i - \hat{y}_i)\)</span>.

By exploring patterns in how the line “misses” the responses we can gain
information about the reasonableness of using the estimated regression line and
sometimes information about how we might fix problems. The validity conditions
for doing inference in a regression setting (Chapter <a href="7-chapter7.html#chapter7"><strong>??</strong></a>)
involve two sets of considerations,
those that are assessed based on the data collection and measurement process
and those that can be assessed using diagnostic plots.


The first set is:</p>
<ul>
<li><p><strong>Quantitative variables condition</strong></p>
<ul>
<li>We’ll discuss using categorical predictor variables later – to
use simple linear regression both the explanatory and response
variables need to quantitative.</li>
</ul></li>
<li><p><strong>Independence of observations</strong> </p>
<ul>
<li><p>As in the ANOVA models, linear regression models assume that
the observations are collected in a fashion that makes them
independent.</p></li>
<li><p>This will be based on the “story” of the data. Consult a
statistician if your data violate this assumption as there
are more advanced methods that adjust for dependency in
observations but they are beyond the scope of this material.</p></li>
</ul></li>
</ul>
<p>The remaining assumptions for getting valid inferences from
regression models can be assessed using diagnostic plots:</p>
<ul>
<li><p><strong>Linearity of relationship</strong></p>
<ul>
<li><p>We should not report a linear regression model if the data
show a curve (curvilinear relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>).</p></li>
<li><p>Examine the initial scatterplot to assess the potential for a curving relationship.</p></li>
<li><p>Examine the Residuals vs Fitted (top left panel of diagnostic plot display) plot:
</p>
<ul>
<li><p>If the model missed a curve in the relationship, the residuals
often will highlight that missed pattern and a curve will show
up in this plot.</p></li>
<li><p>Try to explain or understand the pattern in what is left over.
If we have a good model, there shouldn’t be much left to
“explain” in the residuals (i.e., no patterns left over after
accounting for <span class="math inline">\(x\)</span>).</p></li>
</ul></li>
</ul></li>
<li><p><strong>Equal (constant) variance</strong></p>
<ul>
<li><p>We assume that the variation is the same for all the observations
and especially that the variability does not change in the responses
as a function of our predictor variables or the fitted values.</p></li>
<li><p>There are three plots to help with this:</p>
<ul>
<li><p>Examine the original scatterplot and look at the variation around the line and whether it looks constant across values of <span class="math inline">\(x\)</span>.</p></li>
<li><p>Examine the Residuals vs Fitted plot and look for evidence of
changing spread in the residuals, being careful to try to
separate curving patterns from non-constant variance (and look
for situations where both are present as you can violate both
conditions simultaneously).
</p></li>
<li><p>Examine the “Scale-Location” plot and look for changing spread
as a function of the fitted values.
</p>
<ul>
<li><p>The y-axis in this plot is the square-root of the absolute
value of the standardized residual. This scale flips the
negative residuals on top of the positive ones to help you
better assess changing variability without being distracted
by whether the residuals are above or below 0.</p></li>
<li><p>Because of the absolute value, curves in the Residuals vs
Fitted plot can present as sort of looking like non-constant
variance in the Scale-Location plot – check for nonlinearity in the residuals vs fitted values
before using this plot. If nonlinearity is present, just use
the Residuals vs Fitted and original scatterplot for assessing constant variance around
the curving pattern.</p></li>
</ul></li>
</ul></li>
<li><p>If there are patterns of increasing or decreasing variation (often
described as funnel or cone shapes), then it might be possible to use a
transformation to fix this problem (more later). It is possible to have
decreasing and then increasing variability and this also is
a violation of this condition.
 </p></li>
</ul></li>
<li><p><strong>Normality of residuals</strong></p>
<ul>
<li><p>Examine the Normal QQ-plot for violations of the normality assumption
as in Chapters <a href="3-chapter3.html#chapter3"><strong>??</strong></a> and <a href="4-chapter4.html#chapter4"><strong>??</strong></a>.
</p>
<ul>
<li><p>Specifically review the discussion of identifying skews in
different directions and heavy vs light tailed distributions.</p></li>
<li><p>Skewed and heavy-tailed distributions are the main problems
for our inferences, especially since both kinds of distributions
can contain outliers that can wreak havoc on the estimated
regression line.</p></li>
<li><p>Light-tailed distributions cause us no real inference issues
except that the results are conservative so you should note when
you observe these situations but feel free to proceed with using
your model results.</p></li>
<li><p>Remember that clear outliers are an example of a violation of
the normality assumption but some outliers may just influence
the regression line and make it fit poorly and this issue will be more clearly observed in the
residuals vs fitted than in the QQ-plot.</p></li>
</ul></li>
</ul></li>
<li><p><strong>No influential points</strong></p>
<ul>
<li><p>Examine the Residuals vs Leverage plot as discussed in the previous
section.   </p></li>
<li><p>Consider removing influential points (one at a time) and focusing on results without
those points in the data set.</p></li>
</ul></li>
</ul>
<p>To assess these later assumptions, we will use the four residual diagnostic
plots that R provides from <code>lm</code> fitted models. They are similar to the
results from ANOVA models but the Residuals vs Leverage plot is
now interesting as was discussed in Section <a href="6-9-section6-9.html#section6-9">6.9</a>.

Now we can
fully assess the
potential for trusting the estimated regression models in a couple of our
examples:</p>
<ul>
<li><p><strong>Beers vs BAC:</strong></p>
<ul>
<li><p>Quantitative variables condition:</p>
<ul>
<li>Both variables are quantitative.</li>
</ul></li>
<li><p>Independence of observations:</p>
<ul>
<li>We can assume that all the subjects are independent of each
other. There is only one measurement per student and it is
unlikely that one subject’s beer consumption would impact
another’s BAC. Unless the students were trading blood it
isn’t possible for one person’s beer consumption to change
someone else’s BAC.</li>
</ul>
<div class="sourceCode" id="cb565"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb565-1" title="1">m1 &lt;-<span class="st"> </span><span class="kw">lm</span>(BAC<span class="op">~</span>Beers, <span class="dt">data=</span>BB)</a>
<a class="sourceLine" id="cb565-2" title="2"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb565-3" title="3"><span class="kw">plot</span>(m1, <span class="dt">add.smooth=</span>F, <span class="dt">main=</span><span class="st">&quot;Beers vs BAC&quot;</span>, <span class="dt">pch=</span><span class="dv">16</span>)</a></code></pre></div>
<div class="figure"><span id="fig:Figure6-22"></span>
<img src="06-correlationAndSimpleLinearRegression_files/figure-html/Figure6-22-1.png" alt="Full suite of diagnostics plots for *Beer* vs *BAC* data." width="960" />
<p class="caption">
Figure 2.121: Full suite of diagnostics plots for <em>Beer</em> vs <em>BAC</em> data.
</p>
</div></li>
<li><p>Linearity, constant variance from Residuals vs Fitted:</p>
<ul>
<li>We previously have identified a potentially influential
outlier point in these data. Consulting the Residuals vs
Fitted plot in Figure <a href="6-10-section6-10.html#fig:Figure6-22">2.121</a>, if you trust
that influential point, shows some curvature with a pattern of
decreasing residuals as a function of the fitted values and then an increase at the right. Or, if
you do not trust that highest BAC observation, then there is
a mostly linear relationship with an outlier identified. We
would probably suggest that it is an outlier, should be removed
from the analysis, and inferences constrained to the region of
beer consumption from 1 to 8 beers since we
don’t know what might happen at higher values.</li>
</ul></li>
<li><p>Constant variance from Scale-Location:</p>
<ul>
<li>There is some evidence of increasing variability in this
plot as the spread of the results increases from left to
right, however this is just an artifact
of the pattern in the original residuals and not real evidence of
non-constant variance. Note that there is little to no evidence of non-constant variance in the Residuals vs Fitted.</li>
</ul></li>
<li><p>Normality from Normal QQ Plot:</p>
<ul>
<li>The left tail is a little short and the right tail is a
little long, suggesting a slightly right
skewed distribution in the residuals. This also corresponds to
having a large positive outlying value. But we would conclude that there is a minor issue with normality in the residuals here.</li>
</ul></li>
<li><p>Influential points from Residuals vs Leverage:</p>
<ul>
<li>Previously discussed, this plot shows one influential point
with a Cook’s D value over 1 that is distorting the fitted model and is likely the biggest issue here.</li>
</ul></li>
</ul></li>
<li><p><strong>Tree height and tree diameter</strong> (suspicious observation already removed):</p>
<ul>
<li><p>Quantitative variables: Met</p></li>
<li><p>Independence of observations:</p>
<ul>
<li>There are multiple trees that were measured in each plot.
One problem might be that once a tree is established in an
area, the other trees might not grow as tall. The other problem
is that some sites might have better soil conditions
than others. Then, all the trees in those rich soil areas might be
systematically taller than the trees in other areas. Again, there are
statistical methods to account for this sort of “clustering” of
measurements but this technically violates the assumption that the
trees are independent of each other. So this assumption is violated, but
we will proceed with that caveat on our results – the precision of our
inferences might be slightly over-stated due to some potential
dependency in the measurements.</li>
</ul></li>
<li><p>Linearity, constant variance from Residuals vs Fitted in
Figure <a href="6-10-section6-10.html#fig:Figure6-23">2.122</a>.</p>
<ul>
<li><p>There is evidence of a curve that was missed by the linear model.</p></li>
<li><p>There is also evidence of increasing variability AROUND the curve
in the residuals.</p></li>
</ul></li>
<li><p>Constant variance from Scale-Location:</p>
<ul>
<li>This plot actually shows relatively constant variance but
this plot is misleading when curves are
present in the data set. <strong>Focus on the Residuals vs Fitted to
diagnose non-constant variance in situations where a curve was
missed.</strong></li>
</ul></li>
<li><p>Normality in Normal QQ plot:</p>
<ul>
<li>There is no indication of any problem with the normality
assumption.</li>
</ul></li>
<li><p>Influential points?</p>
<ul>
<li>The Cook’s D contours do not show up in this plot so none of
the points are influential.</li>
</ul></li>
</ul></li>
</ul>
<p>So the main issues with this model are the curving relationship and
non-constant variance. We’ll revisit this example later to see if we can
find a model on transformed variables that has better diagnostics. Reporting the following regression model that has a decent <span class="math inline">\(R^2\)</span> of 62.6%
would be misleading since it does not accurately represent the relationship
between tree diameter and tree height.</p>
<div class="sourceCode" id="cb566"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb566-1" title="1">tree1 &lt;-<span class="st"> </span><span class="kw">lm</span>(height.m<span class="op">~</span>dbh.cm, <span class="dt">data=</span>ufc[<span class="op">-</span><span class="dv">168</span>,])</a>
<a class="sourceLine" id="cb566-2" title="2"><span class="kw">summary</span>(tree1)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = height.m ~ dbh.cm, data = ufc[-168, ])
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -12.1333  -3.1154   0.0711   2.7548  12.3076 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 11.98364    0.57422   20.87   &lt;2e-16
## dbh.cm       0.32939    0.01395   23.61   &lt;2e-16
## 
## Residual standard error: 4.413 on 333 degrees of freedom
## Multiple R-squared:  0.626,  Adjusted R-squared:  0.6249 
## F-statistic: 557.4 on 1 and 333 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>(ref:fig6-23) Diagnostics plots for tree height and diameter simple
linear regression model.</p>
<div class="sourceCode" id="cb568"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb568-1" title="1"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb568-2" title="2"><span class="kw">plot</span>(tree1, <span class="dt">add.smooth=</span>F)</a></code></pre></div>
<div class="figure"><span id="fig:Figure6-23"></span>
<img src="06-correlationAndSimpleLinearRegression_files/figure-html/Figure6-23-1.png" alt="(ref:fig6-23)" width="960" />
<p class="caption">
Figure 2.122: (ref:fig6-23)
</p>
</div>
</div>
<p style="text-align: center;">
<a href="6-9-section6-9.html"><button class="btn btn-default">Previous</button></a>
<a href="6-11-section6-11.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
