<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="8.9 Different intercepts for different groups: MLR with indicator variables | Intermediate Statistics with R" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="gpeterson406/Greenwood_Book" />

<meta name="author" content="Mark C Greenwood" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="8.9 Different intercepts for different groups: MLR with indicator variables | Intermediate Statistics with R">

<title>8.9 Different intercepts for different groups: MLR with indicator variables | Intermediate Statistics with R</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#cover">Cover</a></li>
<li><a href="acknowledgments.html#acknowledgments">Acknowledgments</a></li>
<li class="has-sub"><a href="1-chapter1.html#chapter1"><span class="toc-section-number">1</span> Preface</a><ul>
<li><a href="1-1-section1-1.html#section1-1"><span class="toc-section-number">1.1</span> Overview of methods</a></li>
<li><a href="1-2-section1-2.html#section1-2"><span class="toc-section-number">1.2</span> Getting started in R</a></li>
<li><a href="1-3-section1-3.html#section1-3"><span class="toc-section-number">1.3</span> Basic summary statistics, histograms, and boxplots using R</a></li>
<li><a href="1-4-section1-4.html#section1-4"><span class="toc-section-number">1.4</span> Chapter summary</a></li>
<li><a href="1-5-section1-5.html#section1-5"><span class="toc-section-number">1.5</span> Summary of important R code</a></li>
<li><a href="1-6-section1-6.html#section1-6"><span class="toc-section-number">1.6</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="2-chapter2.html#chapter2"><span class="toc-section-number">2</span> (R)e-Introduction to statistics</a><ul>
<li><a href="2-1-section2-1.html#section2-1"><span class="toc-section-number">2.1</span> Histograms, boxplots, and density curves</a></li>
<li><a href="2-2-section2-2.html#section2-2"><span class="toc-section-number">2.2</span> Pirate-plots</a></li>
<li><a href="2-3-section2-3.html#section2-3"><span class="toc-section-number">2.3</span> Models, hypotheses, and permutations for the two sample mean situation</a></li>
<li><a href="2-4-section2-4.html#section2-4"><span class="toc-section-number">2.4</span> Permutation testing for the two sample mean situation</a></li>
<li><a href="2-5-section2-5.html#section2-5"><span class="toc-section-number">2.5</span> Hypothesis testing (general)</a></li>
<li><a href="2-6-section2-6.html#section2-6"><span class="toc-section-number">2.6</span> Connecting randomization (nonparametric) and parametric tests</a></li>
<li><a href="2-7-section2-7.html#section2-7"><span class="toc-section-number">2.7</span> Second example of permutation tests</a></li>
<li><a href="2-8-section2-8.html#section2-8"><span class="toc-section-number">2.8</span> Reproducibility Crisis: Moving beyond p &lt; 0.05, publication bias, and multiple testing issues</a></li>
<li><a href="2-9-section2-9.html#section2-9"><span class="toc-section-number">2.9</span> Confidence intervals and bootstrapping</a></li>
<li><a href="2-10-section2-10.html#section2-10"><span class="toc-section-number">2.10</span> Bootstrap confidence intervals for difference in GPAs</a></li>
<li><a href="2-11-section2-11.html#section2-11"><span class="toc-section-number">2.11</span> Chapter summary</a></li>
<li><a href="2-12-section2-12.html#section2-12"><span class="toc-section-number">2.12</span> Summary of important R code</a></li>
<li><a href="2-13-section2-13.html#section2-13"><span class="toc-section-number">2.13</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="3-chapter3.html#chapter3"><span class="toc-section-number">3</span> One-Way ANOVA</a><ul>
<li><a href="3-1-section3-1.html#section3-1"><span class="toc-section-number">3.1</span> Situation</a></li>
<li><a href="3-2-section3-2.html#section3-2"><span class="toc-section-number">3.2</span> Linear model for One-Way ANOVA (cell-means and reference-coding)</a></li>
<li><a href="3-3-section3-3.html#section3-3"><span class="toc-section-number">3.3</span> One-Way ANOVA Sums of Squares, Mean Squares, and F-test</a></li>
<li><a href="3-4-section3-4.html#section3-4"><span class="toc-section-number">3.4</span> ANOVA model diagnostics including QQ-plots</a></li>
<li><a href="3-5-section3-5.html#section3-5"><span class="toc-section-number">3.5</span> Guinea pig tooth growth One-Way ANOVA example</a></li>
<li><a href="3-6-section3-6.html#section3-6"><span class="toc-section-number">3.6</span> Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display</a></li>
<li><a href="3-7-section3-7.html#section3-7"><span class="toc-section-number">3.7</span> Pair-wise comparisons for the Overtake data</a></li>
<li><a href="3-8-section3-8.html#section3-8"><span class="toc-section-number">3.8</span> Chapter summary</a></li>
<li><a href="3-9-section3-9.html#section3-9"><span class="toc-section-number">3.9</span> Summary of important R code</a></li>
<li><a href="3-10-section3-10.html#section3-10"><span class="toc-section-number">3.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="4-chapter4.html#chapter4"><span class="toc-section-number">4</span> Two-Way ANOVA</a><ul>
<li><a href="4-1-section4-1.html#section4-1"><span class="toc-section-number">4.1</span> Situation</a></li>
<li><a href="4-2-section4-2.html#section4-2"><span class="toc-section-number">4.2</span> Designing a two-way experiment and visualizing results</a></li>
<li><a href="4-3-section4-3.html#section4-3"><span class="toc-section-number">4.3</span> Two-Way ANOVA models and hypothesis tests</a></li>
<li><a href="4-4-section4-4.html#section4-4"><span class="toc-section-number">4.4</span> Guinea pig tooth growth analysis with Two-Way ANOVA</a></li>
<li><a href="4-5-section4-5.html#section4-5"><span class="toc-section-number">4.5</span> Observational study example: The Psychology of Debt</a></li>
<li><a href="4-6-section4-6.html#section4-6"><span class="toc-section-number">4.6</span> Pushing Two-Way ANOVA to the limit: Un-replicated designs and Estimability</a></li>
<li><a href="4-7-section4-7.html#section4-7"><span class="toc-section-number">4.7</span> Chapter summary</a></li>
<li><a href="4-8-section4-8.html#section4-8"><span class="toc-section-number">4.8</span> Summary of important R code</a></li>
<li><a href="4-9-section4-9.html#section4-9"><span class="toc-section-number">4.9</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="5-chapter5.html#chapter5"><span class="toc-section-number">5</span> Chi-square tests</a><ul>
<li><a href="5-1-section5-1.html#section5-1"><span class="toc-section-number">5.1</span> Situation, contingency tables, and tableplots</a></li>
<li><a href="5-2-section5-2.html#section5-2"><span class="toc-section-number">5.2</span> Homogeneity test hypotheses</a></li>
<li><a href="5-3-section5-3.html#section5-3"><span class="toc-section-number">5.3</span> Independence test hypotheses</a></li>
<li><a href="5-4-section5-4.html#section5-4"><span class="toc-section-number">5.4</span> Models for R by C tables</a></li>
<li><a href="5-5-section5-5.html#section5-5"><span class="toc-section-number">5.5</span> Permutation tests for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="5-6-section5-6.html#section5-6"><span class="toc-section-number">5.6</span> Chi-square distribution for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="5-7-section5-7.html#section5-7"><span class="toc-section-number">5.7</span> Examining residuals for the source of differences</a></li>
<li><a href="5-8-section5-8.html#section5-8"><span class="toc-section-number">5.8</span> General protocol for <span class="math inline">\(X^2\)</span> tests</a></li>
<li><a href="5-9-section5-9.html#section5-9"><span class="toc-section-number">5.9</span> Political party and voting results: Complete analysis</a></li>
<li><a href="5-10-section5-10.html#section5-10"><span class="toc-section-number">5.10</span> Is cheating and lying related in students?</a></li>
<li><a href="5-11-section5-11.html#section5-11"><span class="toc-section-number">5.11</span> Analyzing a stratified random sample of California schools</a></li>
<li><a href="5-12-section5-12.html#section5-12"><span class="toc-section-number">5.12</span> Chapter summary</a></li>
<li><a href="5-13-section5-13.html#section5-13"><span class="toc-section-number">5.13</span> Summary of important R commands</a></li>
<li><a href="5-14-section5-14.html#section5-14"><span class="toc-section-number">5.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="6-chapter6.html#chapter6"><span class="toc-section-number">6</span> Correlation and Simple Linear Regression</a><ul>
<li><a href="6-1-section6-1.html#section6-1"><span class="toc-section-number">6.1</span> Relationships between two quantitative variables</a></li>
<li><a href="6-2-section6-2.html#section6-2"><span class="toc-section-number">6.2</span> Estimating the correlation coefficient</a></li>
<li><a href="6-3-section6-3.html#section6-3"><span class="toc-section-number">6.3</span> Relationships between variables by groups</a></li>
<li><a href="6-4-section6-4.html#section6-4"><span class="toc-section-number">6.4</span> Inference for the correlation coefficient</a></li>
<li><a href="6-5-section6-5.html#section6-5"><span class="toc-section-number">6.5</span> Are tree diameters related to tree heights?</a></li>
<li><a href="6-6-section6-6.html#section6-6"><span class="toc-section-number">6.6</span> Describing relationships with a regression model</a></li>
<li><a href="6-7-section6-7.html#section6-7"><span class="toc-section-number">6.7</span> Least Squares Estimation</a></li>
<li><a href="6-8-section6-8.html#section6-8"><span class="toc-section-number">6.8</span> Measuring the strength of regressions: R<sup>2</sup></a></li>
<li><a href="6-9-section6-9.html#section6-9"><span class="toc-section-number">6.9</span> Outliers: leverage and influence</a></li>
<li><a href="6-10-section6-10.html#section6-10"><span class="toc-section-number">6.10</span> Residual diagnostics – setting the stage for inference</a></li>
<li><a href="6-11-section6-11.html#section6-11"><span class="toc-section-number">6.11</span> Old Faithful discharge and waiting times</a></li>
<li><a href="6-12-section6-12.html#section6-12"><span class="toc-section-number">6.12</span> Chapter summary</a></li>
<li><a href="6-13-section6-13.html#section6-13"><span class="toc-section-number">6.13</span> Summary of important R code</a></li>
<li><a href="6-14-section6-14.html#section6-14"><span class="toc-section-number">6.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="7-chapter7.html#chapter7"><span class="toc-section-number">7</span> Simple linear regression inference</a><ul>
<li><a href="7-1-section7-1.html#section7-1"><span class="toc-section-number">7.1</span> Model</a></li>
<li><a href="7-2-section7-2.html#section7-2"><span class="toc-section-number">7.2</span> Confidence interval and hypothesis tests for the slope and intercept</a></li>
<li><a href="7-3-section7-3.html#section7-3"><span class="toc-section-number">7.3</span> Bozeman temperature trend</a></li>
<li><a href="7-4-section7-4.html#section7-4"><span class="toc-section-number">7.4</span> Randomization-based inferences for the slope coefficient</a></li>
<li><a href="7-5-section7-5.html#section7-5"><span class="toc-section-number">7.5</span> Transformations part I: Linearizing relationships</a></li>
<li><a href="7-6-section7-6.html#section7-6"><span class="toc-section-number">7.6</span> Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x)</a></li>
<li><a href="7-7-section7-7.html#section7-7"><span class="toc-section-number">7.7</span> Confidence interval for the mean and prediction intervals for a new observation</a></li>
<li><a href="7-8-section7-8.html#section7-8"><span class="toc-section-number">7.8</span> Chapter summary</a></li>
<li><a href="7-9-section7-9.html#section7-9"><span class="toc-section-number">7.9</span> Summary of important R code</a></li>
<li><a href="7-10-section7-10.html#section7-10"><span class="toc-section-number">7.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="8-chapter8.html#chapter8"><span class="toc-section-number">8</span> Multiple linear regression</a><ul>
<li><a href="8-1-section8-1.html#section8-1"><span class="toc-section-number">8.1</span> Going from SLR to MLR</a></li>
<li><a href="8-2-section8-2.html#section8-2"><span class="toc-section-number">8.2</span> Validity conditions in MLR</a></li>
<li><a href="8-3-section8-3.html#section8-3"><span class="toc-section-number">8.3</span> Interpretation of MLR terms</a></li>
<li><a href="8-4-section8-4.html#section8-4"><span class="toc-section-number">8.4</span> Comparing multiple regression models</a></li>
<li><a href="8-5-section8-5.html#section8-5"><span class="toc-section-number">8.5</span> General recommendations for MLR interpretations and VIFs</a></li>
<li><a href="8-6-section8-6.html#section8-6"><span class="toc-section-number">8.6</span> MLR inference: Parameter inferences using the t-distribution</a></li>
<li><a href="8-7-section8-7.html#section8-7"><span class="toc-section-number">8.7</span> Overall F-test in multiple linear regression</a></li>
<li><a href="8-8-section8-8.html#section8-8"><span class="toc-section-number">8.8</span> Case study: First year college GPA and SATs</a></li>
<li><a href="8-9-section8-9.html#section8-9"><span class="toc-section-number">8.9</span> Different intercepts for different groups: MLR with indicator variables</a></li>
<li><a href="8-10-section8-10.html#section8-10"><span class="toc-section-number">8.10</span> Additive MLR with more than two groups: Headache example</a></li>
<li><a href="8-11-section8-11.html#section8-11"><span class="toc-section-number">8.11</span> Different slopes and different intercepts</a></li>
<li><a href="8-12-section8-12.html#section8-12"><span class="toc-section-number">8.12</span> F-tests for MLR models with quantitative and categorical variables and interactions</a></li>
<li><a href="8-13-section8-13.html#section8-13"><span class="toc-section-number">8.13</span> AICs for model selection</a></li>
<li><a href="8-14-section8-14.html#section8-14"><span class="toc-section-number">8.14</span> Case study: Forced expiratory volume model selection using AICs</a></li>
<li><a href="8-15-section8-15.html#section8-15"><span class="toc-section-number">8.15</span> Chapter summary</a></li>
<li><a href="8-16-section8-16.html#section8-16"><span class="toc-section-number">8.16</span> Summary of important R code</a></li>
<li><a href="8-17-section8-17.html#section8-17"><span class="toc-section-number">8.17</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="9-chapter9.html#chapter9"><span class="toc-section-number">9</span> Case studies</a><ul>
<li><a href="9-1-section9-1.html#section9-1"><span class="toc-section-number">9.1</span> Overview of material covered</a></li>
<li><a href="9-2-section9-2.html#section9-2"><span class="toc-section-number">9.2</span> The impact of simulated chronic nitrogen deposition on the biomass and N2-fixation activity of two boreal feather moss–cyanobacteria associations</a></li>
<li><a href="9-3-section9-3.html#section9-3"><span class="toc-section-number">9.3</span> Ants learn to rely on more informative attributes during decision-making</a></li>
<li><a href="9-4-section9-4.html#section9-4"><span class="toc-section-number">9.4</span> Multi-variate models are essential for understanding vertebrate diversification in deep time</a></li>
<li><a href="9-5-section9-5.html#section9-5"><span class="toc-section-number">9.5</span> What do didgeridoos really do about sleepiness?</a></li>
<li><a href="9-6-section9-6.html#section9-6"><span class="toc-section-number">9.6</span> General summary</a></li>
</ul></li>
<li><a href="references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="section8-9" class="section level2">
<h2><span class="header-section-number">8.9</span> Different intercepts for different groups: MLR with indicator variables</h2>

<p>One of the implicit assumptions up to this point was that the models were being
applied to a single homogeneous population.
 
In many cases, we take a sample
from a population but that overall group is likely a combination of individuals from
different sub-populations. For example, the SAT study was interested in all
students at the university but that contains the obvious sub-populations based
on the gender of the students. It is dangerous to fit MLR models across
subpopulations but we can also use MLR models to address more sophisticated
research questions by comparing groups. We will be able to compare the
intercepts (mean levels) and the slopes to see if they differ between the
groups. For example, does the relationship between the <em>SATV</em> and <em>FYGPA</em>
differ for male and female students? We can add the grouping information to
the scatterplot of <em>FYGPA</em> vs <em>SATV</em> (Figure <a href="8-9-section8-9.html#fig:Figure8-17">2.167</a>) and
consider whether there is visual evidence of a difference in the slope and/or
intercept between the two groups, with men coded<a href="#fn126" class="footnote-ref" id="fnref126"><sup>126</sup></a> as 1 and women coded as 2. Code below changes this variable to <code>GENDER</code> with more explicit labels, even though they might not be correct and the students were likely forced to choose one or the other.
</p>
<p>It appears that the slope for females might be larger (steeper) in this
relationship than it is for
males. So increases in SAT Verbal percentiles for females might have more of an
impact on the average first year GPA. We’ll handle this sort of situation in
Section <a href="8-11-section8-11.html#section8-11">8.11</a>, where we will formally consider how to change the
slopes for different groups. In this section, we develop new methods needed to
begin to handle these situations and explore creating models that assume the same
slope coefficient for all groups but allow for different y-intercepts. This material
ends up resembling what we did for the Two-Way ANOVA additive model.</p>
<p>The results for <em>SATV</em> contrast with Figure <a href="8-9-section8-9.html#fig:Figure8-18">2.168</a> for the relationship
between first year college <em>GPA</em> and <em>SATM</em>
percentile by gender of the students. The lines for the two groups appear to be
mostly parallel and just seem to have different y-intercepts. In this section, we will learn how we can use our
MLR techniques to fit a model to the entire data set that allows for different
y-intercepts. The real power of this idea is that we can then also test whether
the different groups have different y-intercepts – whether the shift between
the groups is “real”. In this example, it appears to suggest that females
generally have slightly higher GPAs than males, on average, but that an
increase in SATM has about the same impact on GPA for both groups. If this difference in
y-intercepts is not “real”, then there appears to be no difference between the
sexes in their relationship between SATM and GPA and we can safely continue
using a model that does not differentiate the two groups. We could also just
subset the data set and do two analyses, but that approach will not allow us
to assess whether things are “really” different between the two groups.</p>
<div class="sourceCode" id="cb766"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb766-1" title="1">satGPA<span class="op">$</span>GENDER &lt;-<span class="st"> </span><span class="kw">factor</span>(satGPA<span class="op">$</span>sex) <span class="co">#Make 1,2 coded sex into factor GENDER</span></a>
<a class="sourceLine" id="cb766-2" title="2"><span class="kw">levels</span>(satGPA<span class="op">$</span>GENDER) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;MALE&quot;</span>, <span class="st">&quot;FEMALE&quot;</span>) <span class="co">#Make category names clear but names might be wrong</span></a>
<a class="sourceLine" id="cb766-3" title="3"><span class="kw">scatterplot</span>(FYGPA<span class="op">~</span>SATV<span class="op">|</span>GENDER, <span class="dt">lwd=</span><span class="dv">3</span>, <span class="dt">data=</span>satGPA, <span class="dt">smooth=</span>F,</a>
<a class="sourceLine" id="cb766-4" title="4">            <span class="dt">main=</span><span class="st">&quot;Scatterplot of GPA vs SATV by Sex&quot;</span>)</a>
<a class="sourceLine" id="cb766-5" title="5"><span class="kw">scatterplot</span>(FYGPA<span class="op">~</span>SATM<span class="op">|</span>GENDER, <span class="dt">lwd=</span><span class="dv">3</span>, <span class="dt">data=</span>satGPA, <span class="dt">smooth=</span>F,</a>
<a class="sourceLine" id="cb766-6" title="6">            <span class="dt">main=</span><span class="st">&quot;Scatterplot of GPA vs SATM by Sex&quot;</span>)</a></code></pre></div>
<p>To fit one model to a data set that contains multiple groups, we need a way of
entering categorical variable information in an MLR model. Regression models
require quantitative predictor variables for the <span class="math inline">\(x\text{&#39;s}\)</span> so we can’t
directly enter the text coded information on the gender of the students into the regression model since it
contains “words” and how can multiply a word times a slope coefficient. To be able to
put in “numbers” as predictors, we create what are called
<strong><em>indicator variables</em></strong><a href="#fn127" class="footnote-ref" id="fnref127"><sup>127</sup></a>
that are made up of 0s and 1s, with the 0 reflecting one category and 1 the
other, changing depending on the category of the individual in that row of the data set. The
<code>lm</code> function does this whenever a
factor variable is used as an explanatory variable.  

It sets up the indicator
variables using a baseline category (which gets coded as a 0) and the deviation
category for the other level of the variable (which gets coded as a 1). We can see how this works by
exploring what happens when we put <code>GENDER</code> into our <code>lm</code> with <code>SATM</code>, after first making sure it is categorical using
the <code>factor</code> function and making the factor <code>levels</code> explicit instead of 1s
and 2s.

</p>
<div class="sourceCode" id="cb767"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb767-1" title="1">satGPA<span class="op">$</span>GENDER &lt;-<span class="st"> </span><span class="kw">factor</span>(satGPA<span class="op">$</span>sex) <span class="co">#Make 1,2 coded sex into factor GENDER</span></a>
<a class="sourceLine" id="cb767-2" title="2"><span class="kw">levels</span>(satGPA<span class="op">$</span>GENDER) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;MALE&quot;</span>, <span class="st">&quot;FEMALE&quot;</span>) <span class="co">#Make category names clear but names might be wrong</span></a>
<a class="sourceLine" id="cb767-3" title="3">SATGENDER1 &lt;-<span class="st"> </span><span class="kw">lm</span>(FYGPA<span class="op">~</span>SATM<span class="op">+</span>GENDER, <span class="dt">data=</span>satGPA) <span class="co">#Fit lm with SATM and SEX</span></a>
<a class="sourceLine" id="cb767-4" title="4"><span class="kw">summary</span>(SATGENDER1)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = FYGPA ~ SATM + GENDER, data = satGPA)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.42124 -0.42363  0.01868  0.46540  1.66397 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)   0.21589    0.14858   1.453    0.147
## SATM          0.03861    0.00258  14.969  &lt; 2e-16
## GENDERFEMALE  0.31322    0.04360   7.184 1.32e-12
## 
## Residual standard error: 0.6667 on 997 degrees of freedom
## Multiple R-squared:  0.1917, Adjusted R-squared:  0.1901 
## F-statistic: 118.2 on 2 and 997 DF,  p-value: &lt; 2.2e-16</code></pre>

<div class="figure"><span id="fig:Figure8-17"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-17-1.png" alt="Plot of FYGPA vs SATV by Sex of students." width="960" />
<p class="caption">
Figure 2.167: Plot of FYGPA vs SATV by Sex of students.
</p>
</div>

<div class="figure"><span id="fig:Figure8-18"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-18-1.png" alt="Plot of FYGPA vs SATM by Sex of students." width="960" />
<p class="caption">
Figure 2.168: Plot of FYGPA vs SATM by Sex of students.
</p>
</div>
<p>The <code>GENDER</code> row contains information that the linear model chose <em>MALE</em> as
the baseline category and <em>FEMALE</em> as the deviation category since <em>MALE</em> does
not show up in the output. To see what <code>lm</code> is doing for us when we give it a
two-level categorical variable, we can create our own “numerical” predictor that
is 0 for <em>males</em> and 1 for <em>females</em> that we called <code>GENDERINDICATOR</code>, displayed
for the first 10 observations:</p>
<div class="sourceCode" id="cb769"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb769-1" title="1"><span class="co"># Convert logical to 0 for male, 1 for female</span></a>
<a class="sourceLine" id="cb769-2" title="2">satGPA<span class="op">$</span>GENDERINDICATOR &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(satGPA<span class="op">$</span>GENDER<span class="op">==</span><span class="st">&quot;FEMALE&quot;</span>) </a>
<a class="sourceLine" id="cb769-3" title="3"><span class="co"># Explore first few observations</span></a>
<a class="sourceLine" id="cb769-4" title="4"><span class="kw">head</span>(<span class="kw">tibble</span>(<span class="dt">GENDER=</span>satGPA<span class="op">$</span>GENDER, <span class="dt">GENDERINDICATOR=</span>satGPA<span class="op">$</span>GENDERINDICATOR), <span class="dv">10</span>) </a></code></pre></div>
<pre><code>## # A tibble: 10 x 2
##    GENDER GENDERINDICATOR
##    &lt;fct&gt;            &lt;dbl&gt;
##  1 MALE                 0
##  2 FEMALE               1
##  3 FEMALE               1
##  4 MALE                 0
##  5 MALE                 0
##  6 FEMALE               1
##  7 MALE                 0
##  8 MALE                 0
##  9 FEMALE               1
## 10 MALE                 0</code></pre>
<p>We can define the indicator variable more generally by calling it
<span class="math inline">\(I_{\text{Female},i}\)</span> to denote that it is an indicator
<span class="math inline">\((I)\)</span> that takes on a value of 1 for
observations in the category <em>Female</em> and 0 otherwise (<em>Male</em>) – changing based
on the observation (<span class="math inline">\(i\)</span>). Indicator variables, once created,
are quantitative variables that take on values of 0 or 1 and we can put them
directly
into linear models with other <span class="math inline">\(x\text{&#39;s}\)</span> (quantitative or categorical). If we
replace the categorical <code>GENDER</code> variable with our quantitative <code>GENDERINDICATOR</code>
and re-fit the model, we get:</p>
<div class="sourceCode" id="cb771"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb771-1" title="1">SATGENDER2 &lt;-<span class="st"> </span><span class="kw">lm</span>(FYGPA<span class="op">~</span>SATM<span class="op">+</span>GENDERINDICATOR, <span class="dt">data=</span>satGPA)</a>
<a class="sourceLine" id="cb771-2" title="2"><span class="kw">summary</span>(SATGENDER2)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = FYGPA ~ SATM + GENDERINDICATOR, data = satGPA)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.42124 -0.42363  0.01868  0.46540  1.66397 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)      0.21589    0.14858   1.453    0.147
## SATM             0.03861    0.00258  14.969  &lt; 2e-16
## GENDERINDICATOR  0.31322    0.04360   7.184 1.32e-12
## 
## Residual standard error: 0.6667 on 997 degrees of freedom
## Multiple R-squared:  0.1917, Adjusted R-squared:  0.1901 
## F-statistic: 118.2 on 2 and 997 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>This matches all the previous <code>lm</code> output except that we didn’t get any
information on the categories used since <code>lm</code> didn’t know that GENDERINDICATOR
was anything different from other quantitative predictors.</p>
<p>Now we want to think about what this model means. We can write the estimated
model as</p>
<p><span class="math display">\[\widehat{\text{FYGPA}}_i = 0.216 + 0.0386\cdot\text{SATM}_i +
0.313I_{\text{Female},i}\ .\]</span></p>
<p>When we have a <em>male</em> observation, the indicator takes on a value of 0 so the
0.313 drops out of the model, leaving an SLR just in terms of <em>SATM</em>. For a
<em>female</em> student, the indicator is 1 and we add 0.313 to the previous
y-intercept. The following
works this out step-by-step, simplifying the MLR into two SLRs:</p>
<ul>
<li><p>Simplified model for <em>Males</em> (plug in a 0 for <span class="math inline">\(I_{\text{Female},i}\)</span>):</p>
<ul>
<li><span class="math inline">\(\widehat{\text{FYGPA}}_i = 0.216 + 0.0386\cdot\text{SATM}_i +  0.313*0 = 0.216 + 0.0386\cdot\text{SATM}_i\)</span></li>
</ul></li>
<li><p>Simplified model for <em>Females</em> (plug in a 1 for <span class="math inline">\(I_{\text{Female},i}\)</span>):</p>
<ul>
<li><p><span class="math inline">\(\widehat{\text{FYGPA}}_i = 0.216 + 0.0386\cdot\text{SATM}_i + 0.313*1\)</span></p></li>
<li><p><span class="math inline">\(= 0.216 + 0.0386\cdot\text{SATM}_i + 0.313\)</span> (combine “like” terms to
simplify the equation)</p></li>
<li><p><span class="math inline">\(= 0.529 + 0.0386\cdot\text{SATM}_i\)</span> </p></li>
</ul></li>
</ul>
<p>In this situation, we then end up with two SLR models that relate <em>SATM</em> to
<em>GPA</em>, one model for <em>males</em>
<span class="math inline">\((\widehat{\text{FYGPA}}_i= 0.216 + 0.0386\cdot\text{SATM}_i)\)</span> and one for <em>females</em>
<span class="math inline">\((\widehat{\text{FYGPA}}_i= 0.529 + 0.0386\cdot\text{SATM}_i)\)</span>. The only difference
between these two models is in the y-intercept, with the <em>female</em> model’s
y-intercept shifted up from the <em>male</em> y-intercept by 0.313. And that is what
adding indicator variables into models does in general<a href="#fn128" class="footnote-ref" id="fnref128"><sup>128</sup></a> – it shifts the intercept up or down from
the baseline group (here selected as <em>males</em>) to get a new intercept for the
deviation group (here <em>females</em>).</p>
<p>To make this visually clearer, Figure <a href="8-9-section8-9.html#fig:Figure8-19">2.169</a> contains the
regression lines that were estimated for each
group. For any <em>SATM</em>, the difference in the groups is the 0.313 coefficient from
the <code>GENDERFEMALE</code> or <code>GENDERINDICATOR</code> row of the model summaries. For example,
at <em>SATM</em>=50, the difference in terms of predicted average first year GPAs
between males and females is displayed as a difference between 2.15 and 2.46.
This model assumes that the slope on <em>SATM</em> is the same for both groups except
that they are allowed to have different y-intercepts, which is reasonable here
because we saw approximately parallel relationships for the two groups in
Figure <a href="8-9-section8-9.html#fig:Figure8-18">2.168</a>.</p>
<p>(ref:fig8-19) Plot of estimated model for <em>FYGPA</em> vs <em>SATM</em> by <em>GENDER</em> of
students (female line is thicker dark line). Dashed lines aid in seeing the consistent vertical difference of 0.313 in the two estimated lines based on the model containing a different intercept for each group.</p>
<div class="figure"><span id="fig:Figure8-19"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-19-1.png" alt="(ref:fig8-19)" width="576" />
<p class="caption">
Figure 2.169: (ref:fig8-19)
</p>
</div>
<p>Remember that <code>lm</code> selects baseline categories typically based on the
alphabetical order of the levels of the categorical variable when it is created unless the <code>reorder</code> function is used to change the order. Here, the <code>GENDER</code>
variable started with a coding of 1 and 2 and retained that
order even with the recoding of levels that we created to give it more explicit
names. Because we allow <code>lm</code> to create indicator variables for us, the main
thing you need to do is explore the model summary and look for the hint at the
baseline level that is not displayed after the name of the categorical variable. </p>
<p>We can also work out the impacts of adding an indicator variable to the model
in general in the theoretical model with a single quantitative predictor <span class="math inline">\(x_i\)</span>
and indicator <span class="math inline">\(I_i\)</span>. The model starts as</p>
<p><span class="math display">\[y_i=\beta_0+\beta_1x_i + \beta_2I_i + \varepsilon_i\ .\]</span></p>
<p>Again, there are two versions:</p>
<ul>
<li><p>For any observation <span class="math inline">\(i\)</span> in the <strong>baseline</strong> category, <span class="math inline">\(I_i=0\)</span> and the model
is <span class="math inline">\(y_i=\beta_0+\beta_1x_i + \varepsilon_i\)</span>.</p></li>
<li><p>For any observation <span class="math inline">\(i\)</span> in the <strong>non-baseline (deviation)</strong> category, <span class="math inline">\(I_i=1\)</span>
and the model simplifies to <span class="math inline">\(y_i=(\beta_0+\beta_2)+\beta_1x_i + \varepsilon_i\)</span>.</p>
<ul>
<li>This model has a y-intercept of <span class="math inline">\(\beta_0+\beta_2\)</span>.</li>
</ul></li>
</ul>
<p>The interpretation and inferences for <span class="math inline">\(\beta_1\)</span> resemble the work with any
MLR model, noting that these results are “controlled for”, “adjusted for”, or
“allowing for differences based on” the categorical variable in the model. The
interpretation of <span class="math inline">\(\beta_2\)</span> is as a shift up or down in the y-intercept for
the model that includes <span class="math inline">\(x_i\)</span>. When we make term-plots in a model with
a quantitative and additive categorical variable, the two reported model
components match with the previous discussion – the same estimated term from
the quantitative variable for all observations and a shift to reflect the
different y-intercepts in the two groups. In Figure <a href="8-9-section8-9.html#fig:Figure8-20">2.170</a>, the
females are estimated to be that same 0.313 points higher on first year GPA.
The males have a mean GPA slightly above 2.3 which is the predicted GPA for the
average SATM percentile for a male (remember that we have to hold the other variable at
its mean to make each term-plot). When making the SATM term-plot, the
categorical variable is held at the most
frequently occurring value (modal category) in the data set, which is for males in this data set.</p>
<p>(ref:fig8-20) Term-plots for the estimated model for
<span class="math inline">\(\text{FYGPA}\sim\text{SATM} + \text{GENDER}\)</span>.</p>
<div class="sourceCode" id="cb773"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb773-1" title="1"><span class="kw">tally</span>(GENDER<span class="op">~</span><span class="dv">1</span>, <span class="dt">data=</span>satGPA)</a></code></pre></div>
<pre><code>##         1
## GENDER     1
##   MALE   516
##   FEMALE 484</code></pre>
<div class="sourceCode" id="cb775"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb775-1" title="1"><span class="kw">plot</span>(<span class="kw">allEffects</span>(SATGENDER1))</a></code></pre></div>
<div class="figure"><span id="fig:Figure8-20"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-20-1.png" alt="(ref:fig8-20)" width="576" />
<p class="caption">
Figure 2.170: (ref:fig8-20)
</p>
</div>
<p>The model summary and confidence intervals provide some potential interesting
inferences in these models. Again, these are just applications of MLR methods
we have already seen except that the definition of one of the variables is
“different” using the indicator coding idea.  For the same model, the <code>GENDER</code>
coefficient can be used to generate inferences for differences in the mean the
groups, controlling for their <em>SATM</em> scores.</p>
<pre><code>##                Estimate Std. Error t value Pr(&gt;|t|)
## GENDERFEMALE    0.31322    0.04360   7.184 1.32e-12</code></pre>
<p>Testing the null hypothesis that <span class="math inline">\(H_0: \beta_2=0\)</span> vs <span class="math inline">\(H_A: \beta_2\ne 0\)</span> using
our regular <span class="math inline">\(t\)</span>-test provides the opportunity to test for a difference in
intercepts between the groups. In this situation, the test
statistic is <span class="math inline">\(t=7.184\)</span> and, based on a <span class="math inline">\(t_{997}\)</span>-distribution
if the null is true, the p-value is <span class="math inline">\(&lt;0.0001\)</span>. We have very strong evidence against the null hypothesis that there is no difference in the true
y-intercept in a <em>SATM</em> model for first year college GPA between <em>males</em> and <em>females</em>, so we would conclude that there is difference in their true mean GPA levels controlled for <em>SATM</em>. The confidence
interval is also informative:</p>

<div class="sourceCode" id="cb777"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb777-1" title="1"><span class="kw">confint</span>(SATGENDER1)</a></code></pre></div>
<pre><code>##                    2.5 %     97.5 %
## (Intercept)  -0.07566665 0.50744709
## SATM          0.03355273 0.04367726
## GENDERFEMALE  0.22766284 0.39877160</code></pre>
<p>We are 95% confident that the true mean GPA for females is between 0.228 and
0.399 points higher than for males, after adjusting for the <em>SATM</em> in the
population of students. If we had subset the data set and fit two SLRs, we
could have obtained the same simplified regression models but we never could
have performed inferences for the differences between the two groups without
putting all the observations together in one model and then assessing those
differences with targeted coefficients. We also would not be able to get an
estimate of their common slope for <em>SATM</em>, after adjusting for differences
in the intercept for each group.</p>
</div>
<div class="footnotes">
<hr />
<ol start="126">
<li id="fn126"><p>We
are actually making an educated guess about what these codes mean. Other
similar data sets used 1 for males but the documentation on these data is a bit
sparse. We proceed with a small potential that the conclusions regarding
differences in gender are in the wrong direction.<a href="8-9-section8-9.html#fnref126" class="footnote-back">↩</a></p></li>
<li id="fn127"><p>Some people also call them <strong><em>dummy variables</em></strong> to reflect that they are stand-ins for dealing with the categorical information. But it seems like a harsh anthropomorphism so I prefer “indicators”.<a href="8-9-section8-9.html#fnref127" class="footnote-back">↩</a></p></li>
<li id="fn128"><p>This is true for
additive uses of indicator variables. In Section <a href="8-11-section8-11.html#section8-11">8.11</a>, we
consider interactions between quantitative and categorical variables which has
the effect of changing slopes and intercepts. The simplification ideas to
produce estimated equations for each group are used there but we have to account
for changing slopes by group too.<a href="8-9-section8-9.html#fnref128" class="footnote-back">↩</a></p></li>
</ol>
</div>
<p style="text-align: center;">
<a href="8-8-section8-8.html"><button class="btn btn-default">Previous</button></a>
<a href="8-10-section8-10.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
